{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Segmentation App with MONAI Deploy App SDK\n",
    "\n",
    "This tutorial shows how to create an organ segmentation application for a PyTorch model that has been trained with MONAI. Please note that this one does not require the model be a MONAI Bundle.\n",
    "\n",
    "Deploying AI models requires the integration with clinical imaging network, even if just in a for-research-use setting. This means that the AI deploy application will need to support standards-based imaging protocols, and specifically for Radiological imaging, DICOM protocol.\n",
    "\n",
    "Typically, DICOM network communication, either in DICOM TCP/IP network protocol or DICOMWeb, would be handled by DICOM devices or services, e.g. MONAI Deploy Informatics Gateway, so the deploy application itself would only need to use DICOM Part 10 files as input and save the AI result in DICOM Part10 file(s). For segmentation use cases, the DICOM instance file for AI results could be a DICOM Segmentation object or a DICOM RT Structure Set, and for classification, DICOM Structure Report and/or DICOM Encapsulated PDF.\n",
    "\n",
    "During model training, input and label images are typically in non-DICOM volumetric image format, e.g., NIfTI and PNG, converted from a specific DICOM study series. Furthermore, the voxel spacings most likely have been re-sampled to be uniform for all images. When integrated with imaging networks and receiving DICOM instances from modalities and Picture Archiving and Communications System, PACS, an AI deploy application has to deal with a whole DICOM study with multiple series, whose images' spacing may not be the same as expected by the trained model. To address these cases consistently and efficiently, MONAI Deploy Application SDK provides classes, called operators, to parse DICOM studies, select specific series with application-defined rules, and convert the selected DICOM series into domain-specific image format along with meta-data representing the pertinent DICOM attributes. The image is then further processed in the pre-processing stage to normalize spacing, orientation, intensity, etc., before pixel data as Tensors are used for inference.\n",
    "\n",
    "In the following sections, we will demonstrate how to create a MONAI Deploy application package using the MONAI Deploy App SDK.\n",
    "\n",
    ":::{note}\n",
    "For local testing, if there is a lack of DICOM Part 10 files, one can use open source programs, e.g. 3D Slicer, to convert NIfTI to DICOM files.\n",
    "\n",
    ":::\n",
    "\n",
    "## Creating Operators and connecting them in Application class\n",
    "\n",
    "We will implement an application that consists of five Operators:\n",
    "\n",
    "- **DICOMDataLoaderOperator**:\n",
    "    - **Input(dicom_files)**: a folder path (`Path`)\n",
    "    - **Output(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "- **DICOMSeriesSelectorOperator**:\n",
    "    - **Input(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "    - **Input(selection_rules)**: a selection rule (Dict)\n",
    "    - **Output(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "- **DICOMSeriesToVolumeOperator**:\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **SpleenSegOperator**:\n",
    "    - **Input(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output(seg_image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **DICOMSegmentationWriterOperator**:\n",
    "    - **Input(seg_image)**: a segmentation image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(dicom_seg_instance)**: a file path (`Path`)\n",
    "\n",
    "\n",
    ":::{note}\n",
    "The `DICOMSegmentationWriterOperator` needs both the segmentation image as well as the original DICOM series meta-data in order to use the patient demographics and the DICOM Study level attributes.\n",
    ":::\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "```{mermaid}\n",
    "%%{init: {\"theme\": \"base\", \"themeVariables\": { \"fontSize\": \"16px\"}} }%%\n",
    "\n",
    "classDiagram\n",
    "    direction TB\n",
    "\n",
    "    DICOMDataLoaderOperator --|> DICOMSeriesSelectorOperator : dicom_study_list...dicom_study_list\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSeriesToVolumeOperator : study_selected_series_list...study_selected_series_list\n",
    "    DICOMSeriesToVolumeOperator --|> SpleenSegOperator : image...image\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSegmentationWriterOperator : study_selected_series_list...study_selected_series_list\n",
    "    SpleenSegOperator --|> DICOMSegmentationWriterOperator : seg_image...seg_image\n",
    "\n",
    "\n",
    "    class DICOMDataLoaderOperator {\n",
    "        <in>dicom_files : DISK\n",
    "        dicom_study_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesSelectorOperator {\n",
    "        <in>dicom_study_list : IN_MEMORY\n",
    "        <in>selection_rules : IN_MEMORY\n",
    "        study_selected_series_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesToVolumeOperator {\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        image(out) IN_MEMORY\n",
    "    }\n",
    "    class SpleenSegOperator {\n",
    "        <in>image : IN_MEMORY\n",
    "        seg_image(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSegmentationWriterOperator {\n",
    "        <in>seg_image : IN_MEMORY\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        dicom_seg_instance(out) DISK\n",
    "    }\n",
    "```\n",
    "\n",
    "### Setup environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/deploy/utils/importutil.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/deploy/utils/importutil.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# Install MONAI and other necessary image processing packages for the application\n",
    "!python -c \"import monai\" || pip install --upgrade -q \"monai\"\n",
    "!python -c \"import torch\" || pip install -q \"torch>=1.10.2\"\n",
    "!python -c \"import numpy\" || pip install -q \"numpy>=1.21\"\n",
    "!python -c \"import nibabel\" || pip install -q \"nibabel>=3.2.1\"\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=1.4.2\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\"\n",
    "!python -c \"import SimpleITK\" || pip install -q \"SimpleITK>=2.0.0\"\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!python -c \"import monai.deploy\" || pip install --upgrade \"monai-deploy-app-sdk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you may need to restart the Jupyter kernel to use the updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download/Extract ai_spleen_bundle_data from Google Drive\n",
    "\n",
    "**_Note:_** Data files are now access controlled. Please first request permission to access the [shared folder on Google Drive](https://drive.google.com/drive/folders/1EONJsrwbGsS30td0hs8zl4WKjihew1Z3?usp=sharing). Please download zip file, `ai_spleen_seg_bundle_data.zip` in the `ai_spleen_seg_app` folder, to the same folder as the notebook example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ai_spleen_seg_bundle_data.zip\n",
      "  inflating: dcm/1-001.dcm           \n",
      "  inflating: dcm/1-002.dcm           \n",
      "  inflating: dcm/1-003.dcm           \n",
      "  inflating: dcm/1-004.dcm           \n",
      "  inflating: dcm/1-005.dcm           \n",
      "  inflating: dcm/1-006.dcm           \n",
      "  inflating: dcm/1-007.dcm           \n",
      "  inflating: dcm/1-008.dcm           \n",
      "  inflating: dcm/1-009.dcm           \n",
      "  inflating: dcm/1-010.dcm           \n",
      "  inflating: dcm/1-011.dcm           \n",
      "  inflating: dcm/1-012.dcm           \n",
      "  inflating: dcm/1-013.dcm           \n",
      "  inflating: dcm/1-014.dcm           \n",
      "  inflating: dcm/1-015.dcm           \n",
      "  inflating: dcm/1-016.dcm           \n",
      "  inflating: dcm/1-017.dcm           \n",
      "  inflating: dcm/1-018.dcm           \n",
      "  inflating: dcm/1-019.dcm           \n",
      "  inflating: dcm/1-020.dcm           \n",
      "  inflating: dcm/1-021.dcm           \n",
      "  inflating: dcm/1-022.dcm           \n",
      "  inflating: dcm/1-023.dcm           \n",
      "  inflating: dcm/1-024.dcm           \n",
      "  inflating: dcm/1-025.dcm           \n",
      "  inflating: dcm/1-026.dcm           \n",
      "  inflating: dcm/1-027.dcm           \n",
      "  inflating: dcm/1-028.dcm           \n",
      "  inflating: dcm/1-029.dcm           \n",
      "  inflating: dcm/1-030.dcm           \n",
      "  inflating: dcm/1-031.dcm           \n",
      "  inflating: dcm/1-032.dcm           \n",
      "  inflating: dcm/1-033.dcm           \n",
      "  inflating: dcm/1-034.dcm           \n",
      "  inflating: dcm/1-035.dcm           \n",
      "  inflating: dcm/1-036.dcm           \n",
      "  inflating: dcm/1-037.dcm           \n",
      "  inflating: dcm/1-038.dcm           \n",
      "  inflating: dcm/1-039.dcm           \n",
      "  inflating: dcm/1-040.dcm           \n",
      "  inflating: dcm/1-041.dcm           \n",
      "  inflating: dcm/1-042.dcm           \n",
      "  inflating: dcm/1-043.dcm           \n",
      "  inflating: dcm/1-044.dcm           \n",
      "  inflating: dcm/1-045.dcm           \n",
      "  inflating: dcm/1-046.dcm           \n",
      "  inflating: dcm/1-047.dcm           \n",
      "  inflating: dcm/1-048.dcm           \n",
      "  inflating: dcm/1-049.dcm           \n",
      "  inflating: dcm/1-050.dcm           \n",
      "  inflating: dcm/1-051.dcm           \n",
      "  inflating: dcm/1-052.dcm           \n",
      "  inflating: dcm/1-053.dcm           \n",
      "  inflating: dcm/1-054.dcm           \n",
      "  inflating: dcm/1-055.dcm           \n",
      "  inflating: dcm/1-056.dcm           \n",
      "  inflating: dcm/1-057.dcm           \n",
      "  inflating: dcm/1-058.dcm           \n",
      "  inflating: dcm/1-059.dcm           \n",
      "  inflating: dcm/1-060.dcm           \n",
      "  inflating: dcm/1-061.dcm           \n",
      "  inflating: dcm/1-062.dcm           \n",
      "  inflating: dcm/1-063.dcm           \n",
      "  inflating: dcm/1-064.dcm           \n",
      "  inflating: dcm/1-065.dcm           \n",
      "  inflating: dcm/1-066.dcm           \n",
      "  inflating: dcm/1-067.dcm           \n",
      "  inflating: dcm/1-068.dcm           \n",
      "  inflating: dcm/1-069.dcm           \n",
      "  inflating: dcm/1-070.dcm           \n",
      "  inflating: dcm/1-071.dcm           \n",
      "  inflating: dcm/1-072.dcm           \n",
      "  inflating: dcm/1-073.dcm           \n",
      "  inflating: dcm/1-074.dcm           \n",
      "  inflating: dcm/1-075.dcm           \n",
      "  inflating: dcm/1-076.dcm           \n",
      "  inflating: dcm/1-077.dcm           \n",
      "  inflating: dcm/1-078.dcm           \n",
      "  inflating: dcm/1-079.dcm           \n",
      "  inflating: dcm/1-080.dcm           \n",
      "  inflating: dcm/1-081.dcm           \n",
      "  inflating: dcm/1-082.dcm           \n",
      "  inflating: dcm/1-083.dcm           \n",
      "  inflating: dcm/1-084.dcm           \n",
      "  inflating: dcm/1-085.dcm           \n",
      "  inflating: dcm/1-086.dcm           \n",
      "  inflating: dcm/1-087.dcm           \n",
      "  inflating: dcm/1-088.dcm           \n",
      "  inflating: dcm/1-089.dcm           \n",
      "  inflating: dcm/1-090.dcm           \n",
      "  inflating: dcm/1-091.dcm           \n",
      "  inflating: dcm/1-092.dcm           \n",
      "  inflating: dcm/1-093.dcm           \n",
      "  inflating: dcm/1-094.dcm           \n",
      "  inflating: dcm/1-095.dcm           \n",
      "  inflating: dcm/1-096.dcm           \n",
      "  inflating: dcm/1-097.dcm           \n",
      "  inflating: dcm/1-098.dcm           \n",
      "  inflating: dcm/1-099.dcm           \n",
      "  inflating: dcm/1-100.dcm           \n",
      "  inflating: dcm/1-101.dcm           \n",
      "  inflating: dcm/1-102.dcm           \n",
      "  inflating: dcm/1-103.dcm           \n",
      "  inflating: dcm/1-104.dcm           \n",
      "  inflating: dcm/1-105.dcm           \n",
      "  inflating: dcm/1-106.dcm           \n",
      "  inflating: dcm/1-107.dcm           \n",
      "  inflating: dcm/1-108.dcm           \n",
      "  inflating: dcm/1-109.dcm           \n",
      "  inflating: dcm/1-110.dcm           \n",
      "  inflating: dcm/1-111.dcm           \n",
      "  inflating: dcm/1-112.dcm           \n",
      "  inflating: dcm/1-113.dcm           \n",
      "  inflating: dcm/1-114.dcm           \n",
      "  inflating: dcm/1-115.dcm           \n",
      "  inflating: dcm/1-116.dcm           \n",
      "  inflating: dcm/1-117.dcm           \n",
      "  inflating: dcm/1-118.dcm           \n",
      "  inflating: dcm/1-119.dcm           \n",
      "  inflating: dcm/1-120.dcm           \n",
      "  inflating: dcm/1-121.dcm           \n",
      "  inflating: dcm/1-122.dcm           \n",
      "  inflating: dcm/1-123.dcm           \n",
      "  inflating: dcm/1-124.dcm           \n",
      "  inflating: dcm/1-125.dcm           \n",
      "  inflating: dcm/1-126.dcm           \n",
      "  inflating: dcm/1-127.dcm           \n",
      "  inflating: dcm/1-128.dcm           \n",
      "  inflating: dcm/1-129.dcm           \n",
      "  inflating: dcm/1-130.dcm           \n",
      "  inflating: dcm/1-131.dcm           \n",
      "  inflating: dcm/1-132.dcm           \n",
      "  inflating: dcm/1-133.dcm           \n",
      "  inflating: dcm/1-134.dcm           \n",
      "  inflating: dcm/1-135.dcm           \n",
      "  inflating: dcm/1-136.dcm           \n",
      "  inflating: dcm/1-137.dcm           \n",
      "  inflating: dcm/1-138.dcm           \n",
      "  inflating: dcm/1-139.dcm           \n",
      "  inflating: dcm/1-140.dcm           \n",
      "  inflating: dcm/1-141.dcm           \n",
      "  inflating: dcm/1-142.dcm           \n",
      "  inflating: dcm/1-143.dcm           \n",
      "  inflating: dcm/1-144.dcm           \n",
      "  inflating: dcm/1-145.dcm           \n",
      "  inflating: dcm/1-146.dcm           \n",
      "  inflating: dcm/1-147.dcm           \n",
      "  inflating: dcm/1-148.dcm           \n",
      "  inflating: dcm/1-149.dcm           \n",
      "  inflating: dcm/1-150.dcm           \n",
      "  inflating: dcm/1-151.dcm           \n",
      "  inflating: dcm/1-152.dcm           \n",
      "  inflating: dcm/1-153.dcm           \n",
      "  inflating: dcm/1-154.dcm           \n",
      "  inflating: dcm/1-155.dcm           \n",
      "  inflating: dcm/1-156.dcm           \n",
      "  inflating: dcm/1-157.dcm           \n",
      "  inflating: dcm/1-158.dcm           \n",
      "  inflating: dcm/1-159.dcm           \n",
      "  inflating: dcm/1-160.dcm           \n",
      "  inflating: dcm/1-161.dcm           \n",
      "  inflating: dcm/1-162.dcm           \n",
      "  inflating: dcm/1-163.dcm           \n",
      "  inflating: dcm/1-164.dcm           \n",
      "  inflating: dcm/1-165.dcm           \n",
      "  inflating: dcm/1-166.dcm           \n",
      "  inflating: dcm/1-167.dcm           \n",
      "  inflating: dcm/1-168.dcm           \n",
      "  inflating: dcm/1-169.dcm           \n",
      "  inflating: dcm/1-170.dcm           \n",
      "  inflating: dcm/1-171.dcm           \n",
      "  inflating: dcm/1-172.dcm           \n",
      "  inflating: dcm/1-173.dcm           \n",
      "  inflating: dcm/1-174.dcm           \n",
      "  inflating: dcm/1-175.dcm           \n",
      "  inflating: dcm/1-176.dcm           \n",
      "  inflating: dcm/1-177.dcm           \n",
      "  inflating: dcm/1-178.dcm           \n",
      "  inflating: dcm/1-179.dcm           \n",
      "  inflating: dcm/1-180.dcm           \n",
      "  inflating: dcm/1-181.dcm           \n",
      "  inflating: dcm/1-182.dcm           \n",
      "  inflating: dcm/1-183.dcm           \n",
      "  inflating: dcm/1-184.dcm           \n",
      "  inflating: dcm/1-185.dcm           \n",
      "  inflating: dcm/1-186.dcm           \n",
      "  inflating: dcm/1-187.dcm           \n",
      "  inflating: dcm/1-188.dcm           \n",
      "  inflating: dcm/1-189.dcm           \n",
      "  inflating: dcm/1-190.dcm           \n",
      "  inflating: dcm/1-191.dcm           \n",
      "  inflating: dcm/1-192.dcm           \n",
      "  inflating: dcm/1-193.dcm           \n",
      "  inflating: dcm/1-194.dcm           \n",
      "  inflating: dcm/1-195.dcm           \n",
      "  inflating: dcm/1-196.dcm           \n",
      "  inflating: dcm/1-197.dcm           \n",
      "  inflating: dcm/1-198.dcm           \n",
      "  inflating: dcm/1-199.dcm           \n",
      "  inflating: dcm/1-200.dcm           \n",
      "  inflating: dcm/1-201.dcm           \n",
      "  inflating: dcm/1-202.dcm           \n",
      "  inflating: dcm/1-203.dcm           \n",
      "  inflating: dcm/1-204.dcm           \n",
      "  inflating: model.ts                \n",
      "model.ts\n"
     ]
    }
   ],
   "source": [
    "# Download ai_spleen_bundle_data test data zip file. Please request access and download manually.\n",
    "# !pip install gdown\n",
    "# !gdown \"https://drive.google.com/uc?id=1IwWMpbo2fd38fKIqeIdL8SKTGvkn31tK\"\n",
    "\n",
    "# After downloading ai_spleen_bundle_data zip file from the web browser or using gdown,\n",
    "!unzip -o \"ai_spleen_seg_bundle_data.zip\"\n",
    "\n",
    "# Need to copy the model.ts file to its own clean subfolder for packaging, to work around an issue in the Packager\n",
    "models_folder = \"models\"\n",
    "!rm -rf {models_folder} && mkdir -p {models_folder}/model && cp model.ts {models_folder}/model && ls {models_folder}/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=dcm\n",
      "env: HOLOSCAN_MODEL_PATH=models\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH dcm\n",
    "%env HOLOSCAN_MODEL_PATH {models_folder}\n",
    "%env HOLOSCAN_OUTPUT_PATH output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators to define Application and Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/deploy/utils/importutil.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from numpy import uint8  # Needed if SaveImaged is enabled\n",
    "from pathlib import Path\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Operator, OperatorSpec\n",
    "from monai.deploy.core.domain import Image\n",
    "from monai.deploy.core.io_type import IOType\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.monai_seg_inference_operator import InfererType, InMemImageReader, MonaiSegInferenceOperator\n",
    "\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model Specific Inference Operator classes\n",
    "\n",
    "Each Operator class inherits the base `Operator` class. The input/output properties are specified by implementing the `setup()` method, and the business logic implemented in the `compute()` method.\n",
    "\n",
    "The App SDK provides a `MonaiSegInferenceOperator` class to perform segmentation prediction with a Torch Script model. For consistency, this class uses MONAI dictionary-based transforms, as `Compose` object, for pre and post transforms. The model-specific inference operator will then only need to create the pre and post transform `Compose` based on what has been used in the model during training and validation. Note that for deploy application, `ignite` is not needed nor supported.\n",
    "\n",
    "#### SpleenSegOperator\n",
    "\n",
    "The `SpleenSegOperator` gets as input an in-memory [Image](/modules/_autosummary/monai.deploy.core.domain.Image) object that has been converted from a DICOM CT series by the preceding `DICOMSeriesToVolumeOperator`, and as output in-memory segmentation [Image](/modules/_autosummary/monai.deploy.core.domain.Image) object.\n",
    "\n",
    "The `pre_process` function creates the pre-transforms `Compose` object. For `LoadImage`, a specialized `InMemImageReader`, derived from MONAI `ImageReader`, is used to convert the in-memory pixel data and return the `numpy` array as well as the meta-data. Also, the DICOM input pixel spacings are often not the same as expected by the model, so the `Spacingd` transform must be used to re-sample the image with the expected spacing.\n",
    "\n",
    "The `post_process` function creates the post-transform `Compose` object. The `SaveImageD` transform class is used to save the segmentation mask as NIfTI image file, which is optional as the in-memory mask image will be passed down to the DICOM Segmentation writer for creating a DICOM Segmentation instance. The `Invertd` must also be used to revert the segmentation image's orientation and spacing to be the same as the input.\n",
    "\n",
    "When the `MonaiSegInferenceOperator` object is created, the `ROI` size is specified, as well as the transform `Compose` objects. Furthermore, the dataset image key names are set accordingly.\n",
    "\n",
    "Loading of the model and performing the prediction are encapsulated in the `MonaiSegInferenceOperator` and other SDK classes. Once the inference is completed, the segmentation [Image](/modules/_autosummary/monai.deploy.core.domain.Image) object is created and set to the output by the `SpleenSegOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpleenSegOperator(Operator):\n",
    "    \"\"\"Performs Spleen segmentation with a 3D image converted from a DICOM CT series.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"output/saved_images_folder\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_path: Path,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.output_folder = output_folder\n",
    "        self.output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        self.app_context = app_context\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_seg = \"seg_image\"\n",
    "        self.output_name_saved_images_folder = \"saved_images_folder\"\n",
    "\n",
    "        # The base class has an attribute called fragment to hold the reference to the fragment object\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.output(self.output_name_seg)\n",
    "        spec.output(self.output_name_saved_images_folder).condition(\n",
    "            ConditionType.NONE\n",
    "        )  # Output not requiring a receiver\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        input_image = op_input.receive(self.input_name_image)\n",
    "        if not input_image:\n",
    "            raise ValueError(\"Input image is not found.\")\n",
    "\n",
    "        # This operator gets an in-memory Image object, so a specialized ImageReader is needed.\n",
    "        _reader = InMemImageReader(input_image)\n",
    "\n",
    "        pre_transforms = self.pre_process(_reader, str(self.output_folder))\n",
    "        post_transforms = self.post_process(pre_transforms, str(self.output_folder))\n",
    "\n",
    "        # Delegates inference and saving output to the built-in operator.\n",
    "        infer_operator = MonaiSegInferenceOperator(\n",
    "            self.fragment,\n",
    "            roi_size=(\n",
    "                96,\n",
    "                96,\n",
    "                96,\n",
    "            ),\n",
    "            pre_transforms=pre_transforms,\n",
    "            post_transforms=post_transforms,\n",
    "            overlap=0.6,\n",
    "            app_context=self.app_context,\n",
    "            model_name=\"\",\n",
    "            inferer=InfererType.SLIDING_WINDOW,\n",
    "            sw_batch_size=4,\n",
    "            model_path=self.model_path,\n",
    "            name=\"monai_seg_inference_op\",\n",
    "        )\n",
    "\n",
    "        # Setting the keys used in the dictionary based transforms may change.\n",
    "        infer_operator.input_dataset_key = self._input_dataset_key\n",
    "        infer_operator.pred_dataset_key = self._pred_dataset_key\n",
    "\n",
    "        # Now emit data to the output ports of this operator\n",
    "        op_output.emit(infer_operator.compute_impl(input_image, context), self.output_name_seg)\n",
    "        op_output.emit(self.output_folder, self.output_name_saved_images_folder)\n",
    "\n",
    "    def pre_process(self, img_reader, out_dir: str = \"./input_images\") -> Compose:\n",
    "        \"\"\"Composes transforms for preprocessing input before predicting on a model.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        my_key = self._input_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                LoadImaged(keys=my_key, reader=img_reader),\n",
    "                EnsureChannelFirstd(keys=my_key),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=my_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"\",\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "                Orientationd(keys=my_key, axcodes=\"RAS\"),\n",
    "                Spacingd(keys=my_key, pixdim=[1.5, 1.5, 2.9], mode=[\"bilinear\"]),\n",
    "                ScaleIntensityRanged(keys=my_key, a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                EnsureTyped(keys=my_key),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process(self, pre_transforms: Compose, out_dir: str = \"./prediction_output\") -> Compose:\n",
    "        \"\"\"Composes transforms for postprocessing the prediction results.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        pred_key = self._pred_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                Activationsd(keys=pred_key, softmax=True),\n",
    "                Invertd(\n",
    "                    keys=pred_key,\n",
    "                    transform=pre_transforms,\n",
    "                    orig_keys=self._input_dataset_key,\n",
    "                    nearest_interp=False,\n",
    "                    to_tensor=True,\n",
    "                ),\n",
    "                AsDiscreted(keys=pred_key, argmax=True),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=pred_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"seg\",\n",
    "                    output_dtype=uint8,\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class, inheriting the base `Application` class.\n",
    "\n",
    "The base class method, `compose`, is overridden. Objects required for DICOM parsing, series selection, pixel data conversion to volume image, and segmentation instance creation are created, so is the model-specific `SpleenSegOperator`. The execution pipeline, as a Directed Acyclic Graph (DAG), is created by connecting these objects through the `add_flow` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AISpleenSegApp(Application):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        self._logger.debug(f\"Begin {self.compose.__name__}\")\n",
    "        app_context = Application.init_app_context({})  # Do not pass argv in Jupyter Notebook\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        self._logger.info(f\"App input and output path: {app_input_path}, {app_output_path}\")\n",
    "\n",
    "        # instantiates the SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"dcm_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Model specific inference operator, supporting MONAI transforms.\n",
    "        spleen_seg_op = SpleenSegOperator(self, app_context=app_context, model_path=model_path, name=\"seg_op\")\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue.\n",
    "        # The segment_label, algorithm_name, and algorithm_version are limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        # User can Look up SNOMED CT codes at, e.g.\n",
    "        # https://bioportal.bioontology.org/ontologies/SNOMEDCT\n",
    "\n",
    "        _algorithm_name = \"3D segmentation of the Spleen from a CT series\"\n",
    "        _algorithm_family = codes.DCM.ArtificialIntelligence\n",
    "        _algorithm_version = \"0.1.0\"\n",
    "\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=_algorithm_name,\n",
    "                algorithm_family=_algorithm_family,\n",
    "                algorithm_version=_algorithm_version,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dcm_seg_writer_op\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, spleen_seg_op, {(\"image\", \"image\")})\n",
    "\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(spleen_seg_op, dicom_seg_writer, {(\"seg_image\", \"seg_image\")})\n",
    "\n",
    "        self._logger.debug(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "# For list of string values, e.g. \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"], it is a match if all elements\n",
    "# are all in the multi-value attribute of the DICOM series.\n",
    "\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\",\n",
    "                \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing app locally\n",
    "\n",
    "We can execute the app in Jupyter notebook. Note that the DICOM files of the CT Abdomen series must be present in the `dcm` folder and the TorchScript, `model.ts`, in the folder pointed to by the environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] [fragment.cpp:969] Loading extensions from configs...\n",
      "[2025-10-29 15:07:35,494] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, triton_server_netloc=None, argv=[])\n",
      "[2025-10-29 15:07:35,504] [INFO] (root) - AppContext object: AppContext(input_path=dcm, output_path=output, model_path=models, workdir=), triton_server_netloc=\n",
      "[2025-10-29 15:07:35,506] [INFO] (__main__.AISpleenSegApp) - App input and output path: dcm, output\n",
      "[info] [gxf_executor.cpp:344] Creating context\n",
      "[info] [gxf_executor.cpp:2508] Activating Graph...\n",
      "[info] [gxf_executor.cpp:2579] Running Graph...\n",
      "[info] [gxf_executor.cpp:2581] Waiting for completion...\n",
      "[info] [greedy_scheduler.cpp:191] Scheduling 5 entities\n",
      "[2025-10-29 15:07:35,774] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "[2025-10-29 15:07:36,061] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "[2025-10-29 15:07:36,062] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "[2025-10-29 15:07:36,063] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2025-10-29 15:07:36,064] [INFO] (root) -     On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "[2025-10-29 15:07:36,065] [INFO] (root) -         Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "[2025-10-29 15:07:36,066] [INFO] (root) -     On attribute: 'Modality' to match value: '(?i)CT'\n",
      "[2025-10-29 15:07:36,067] [INFO] (root) -         Series attribute Modality value: CT\n",
      "[2025-10-29 15:07:36,067] [INFO] (root) -     On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "[2025-10-29 15:07:36,068] [INFO] (root) -         Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "[2025-10-29 15:07:36,069] [INFO] (root) -     On attribute: 'ImageType' to match value: ['PRIMARY', 'ORIGINAL']\n",
      "[2025-10-29 15:07:36,070] [INFO] (root) -         Series attribute ImageType value: None\n",
      "[2025-10-29 15:07:36,071] [INFO] (root) -         Instance level attribute ImageType value: [\"['ORIGINAL', 'PRIMARY', 'AXIAL', 'CT_SOM5 SPI']\"]\n",
      "[2025-10-29 15:07:36,072] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2025-10-29 15:07:36,073] [INFO] (root) - Series Selection finalized\n",
      "[2025-10-29 15:07:36,074] [INFO] (root) - Series Description of selected DICOM Series for inference: ABD/PANC 3.0 B31f\n",
      "[2025-10-29 15:07:36,076] [INFO] (root) - Series Instance UID of selected DICOM Series for inference: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "[2025-10-29 15:07:36,443] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Converted Image object metadata:\n",
      "[2025-10-29 15:07:36,444] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239, type <class 'str'>\n",
      "[2025-10-29 15:07:36,444] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDate: 20090831, type <class 'str'>\n",
      "[2025-10-29 15:07:36,445] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesTime: 101721.452, type <class 'str'>\n",
      "[2025-10-29 15:07:36,446] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Modality: CT, type <class 'str'>\n",
      "[2025-10-29 15:07:36,446] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDescription: ABD/PANC 3.0 B31f, type <class 'str'>\n",
      "[2025-10-29 15:07:36,447] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - PatientPosition: HFS, type <class 'str'>\n",
      "[2025-10-29 15:07:36,448] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesNumber: 8, type <class 'int'>\n",
      "[2025-10-29 15:07:36,448] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2025-10-29 15:07:36,449] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2025-10-29 15:07:36,450] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_pixel_spacing: 1.5, type <class 'float'>\n",
      "[2025-10-29 15:07:36,451] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_direction_cosine: [1.0, 0.0, 0.0], type <class 'list'>\n",
      "[2025-10-29 15:07:36,452] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_direction_cosine: [0.0, 1.0, 0.0], type <class 'list'>\n",
      "[2025-10-29 15:07:36,453] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_direction_cosine: [0.0, 0.0, 1.0], type <class 'list'>\n",
      "[2025-10-29 15:07:36,455] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - dicom_affine_transform: [[   0.7890625    0.           0.        -197.60547  ]\n",
      " [   0.           0.7890625    0.        -398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2025-10-29 15:07:36,456] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - nifti_affine_transform: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2025-10-29 15:07:36,457] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291, type <class 'str'>\n",
      "[2025-10-29 15:07:36,458] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyID: , type <class 'str'>\n",
      "[2025-10-29 15:07:36,459] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDate: 20090831, type <class 'str'>\n",
      "[2025-10-29 15:07:36,460] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyTime: 095948.599, type <class 'str'>\n",
      "[2025-10-29 15:07:36,461] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDescription: CT ABDOMEN W IV CONTRAST, type <class 'str'>\n",
      "[2025-10-29 15:07:36,462] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - AccessionNumber: 5471978513296937, type <class 'str'>\n",
      "[2025-10-29 15:07:36,463] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - selection_name: CT Series, type <class 'str'>\n",
      "[2025-10-29 15:07:36,465] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - affine: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2025-10-29 15:07:36,466] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - space: RAS, type <class 'str'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:07:37,127 INFO image_writer.py:197 - writing: /home/mqin/src/md-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-29 15:07:38,807] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Input of <class 'monai.data.meta_tensor.MetaTensor'> shape: torch.Size([1, 1, 270, 270, 106])\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/inferers/utils.py:226: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  win_data = torch.cat([inputs[win_slice] for win_slice in unravel_slice]).to(sw_device)\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/inferers/utils.py:370: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  out[idx_zm] += p\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-29 15:07:39,889 INFO image_writer.py:197 - writing: /home/mqin/src/md-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-29 15:07:41,361] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform length/batch size of output: 1\n",
      "[2025-10-29 15:07:41,368] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform pixel spacings for pred: tensor([0.7891, 0.7891, 1.5000], dtype=torch.float64)\n",
      "[2025-10-29 15:07:41,501] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform pred of <class 'numpy.ndarray'> shape: (1, 512, 512, 204)\n",
      "[2025-10-29 15:07:41,540] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image numpy array of type <class 'numpy.ndarray'> shape: (204, 512, 512)\n",
      "[2025-10-29 15:07:41,546] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image pixel max value: 1\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/highdicom/base.py:165: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  check_person_name(patient_name)\n",
      "[2025-10-29 15:07:43,065] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2025-10-29 15:07:43,066] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "[2025-10-29 15:07:43,067] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2025-10-29 15:07:43,068] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "[2025-10-29 15:07:43,070] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "[2025-10-29 15:07:43,072] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2025-10-29 15:07:43,074] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "[2025-10-29 15:07:43,076] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "[2025-10-29 15:07:43,078] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "[info] [greedy_scheduler.cpp:372] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[info] [greedy_scheduler.cpp:401] Scheduler finished.\n",
      "[info] [gxf_executor.cpp:2588] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:2597] Graph execution finished.\n",
      "[2025-10-29 15:07:43,199] [INFO] (__main__.AISpleenSegApp) - End run\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "app = AISpleenSegApp()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the above Python code into Python files in an application folder.\n",
    "\n",
    "The application folder structure would look like below:\n",
    "\n",
    "```bash\n",
    "my_app\n",
    " __main__.py\n",
    " app.py\n",
    " spleen_seg_operator.py\n",
    "```\n",
    "\n",
    ":::{note}\n",
    "We can create a single application Python file (such as `spleen_app.py`) that includes the content of the files, instead of creating multiple files.\n",
    "You will see such an example in <a href=\"./02_mednist_app.html#executing-app-locally\">MedNist Classifier Tutorial</a>.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p my_app && rm -rf my_app/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spleen_seg_operator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/spleen_seg_operator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/spleen_seg_operator.py\n",
    "import logging\n",
    "\n",
    "from numpy import uint8\n",
    "from pathlib import Path\n",
    "\n",
    "from monai.deploy.core import AppContext, ConditionType, Fragment, Operator, OperatorSpec\n",
    "from monai.deploy.operators.monai_seg_inference_operator import InfererType, InMemImageReader, MonaiSegInferenceOperator\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n",
    "\n",
    "class SpleenSegOperator(Operator):\n",
    "    \"\"\"Performs Spleen segmentation with a 3D image converted from a DICOM CT series.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"output/saved_images_folder\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_path: Path,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.output_folder = output_folder\n",
    "        self.output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        self.app_context = app_context\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_seg = \"seg_image\"\n",
    "        self.output_name_saved_images_folder = \"saved_images_folder\"\n",
    "\n",
    "        # The base class has an attribute called fragment to hold the reference to the fragment object\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.output(self.output_name_seg)\n",
    "        spec.output(self.output_name_saved_images_folder).condition(\n",
    "            ConditionType.NONE\n",
    "        )  # Output not requiring a receiver\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        input_image = op_input.receive(self.input_name_image)\n",
    "        if not input_image:\n",
    "            raise ValueError(\"Input image is not found.\")\n",
    "\n",
    "        # This operator gets an in-memory Image object, so a specialized ImageReader is needed.\n",
    "        _reader = InMemImageReader(input_image)\n",
    "\n",
    "        pre_transforms = self.pre_process(_reader, str(self.output_folder))\n",
    "        post_transforms = self.post_process(pre_transforms, str(self.output_folder))\n",
    "\n",
    "        # Delegates inference and saving output to the built-in operator.\n",
    "        infer_operator = MonaiSegInferenceOperator(\n",
    "            self.fragment,\n",
    "            roi_size=(\n",
    "                96,\n",
    "                96,\n",
    "                96,\n",
    "            ),\n",
    "            pre_transforms=pre_transforms,\n",
    "            post_transforms=post_transforms,\n",
    "            overlap=0.6,\n",
    "            app_context=self.app_context,\n",
    "            model_name=\"\",\n",
    "            inferer=InfererType.SLIDING_WINDOW,\n",
    "            sw_batch_size=4,\n",
    "            model_path=self.model_path,\n",
    "            name=\"monai_seg_inference_op\",\n",
    "        )\n",
    "\n",
    "        # Setting the keys used in the dictionary based transforms may change.\n",
    "        infer_operator.input_dataset_key = self._input_dataset_key\n",
    "        infer_operator.pred_dataset_key = self._pred_dataset_key\n",
    "\n",
    "        # Now emit data to the output ports of this operator\n",
    "        op_output.emit(infer_operator.compute_impl(input_image, context), self.output_name_seg)\n",
    "        op_output.emit(self.output_folder, self.output_name_saved_images_folder)\n",
    "\n",
    "    def pre_process(self, img_reader, out_dir: str = \"./input_images\") -> Compose:\n",
    "        \"\"\"Composes transforms for preprocessing input before predicting on a model.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        my_key = self._input_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                LoadImaged(keys=my_key, reader=img_reader),\n",
    "                EnsureChannelFirstd(keys=my_key),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=my_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"\",\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "                Orientationd(keys=my_key, axcodes=\"RAS\"),\n",
    "                Spacingd(keys=my_key, pixdim=[1.5, 1.5, 2.9], mode=[\"bilinear\"]),\n",
    "                ScaleIntensityRanged(keys=my_key, a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                EnsureTyped(keys=my_key),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process(self, pre_transforms: Compose, out_dir: str = \"./prediction_output\") -> Compose:\n",
    "        \"\"\"Composes transforms for postprocessing the prediction results.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        pred_key = self._pred_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                Activationsd(keys=pred_key, softmax=True),\n",
    "                Invertd(\n",
    "                    keys=pred_key,\n",
    "                    transform=pre_transforms,\n",
    "                    orig_keys=self._input_dataset_key,\n",
    "                    nearest_interp=False,\n",
    "                    to_tensor=True,\n",
    "                ),\n",
    "                AsDiscreted(keys=pred_key, argmax=True),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=pred_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"seg\",\n",
    "                    output_dtype=uint8,\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.py\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from spleen_seg_operator import SpleenSegOperator\n",
    "\n",
    "from pydicom.sr.codedict import codes  # Required for setting SegmentDescription attributes.\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n",
    "\n",
    "class AISpleenSegApp(Application):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        # Use Commandline options over environment variables to init context.\n",
    "        app_context = Application.init_app_context(self.argv)\n",
    "        self._logger.debug(f\"Begin {self.compose.__name__}\")\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        self._logger.info(f\"App input and output path: {app_input_path}, {app_output_path}\")\n",
    "\n",
    "        # instantiates the SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"dcm_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Model specific inference operator, supporting MONAI transforms.\n",
    "        spleen_seg_op = SpleenSegOperator(self, app_context=app_context, model_path=model_path, name=\"seg_op\")\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue.\n",
    "        # The segment_label, algorithm_name, and algorithm_version are limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        # User can Look up SNOMED CT codes at, e.g.\n",
    "        # https://bioportal.bioontology.org/ontologies/SNOMEDCT\n",
    "\n",
    "        _algorithm_name = \"3D segmentation of the Spleen from a CT series\"\n",
    "        _algorithm_family = codes.DCM.ArtificialIntelligence\n",
    "        _algorithm_version = \"0.1.0\"\n",
    "\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=_algorithm_name,\n",
    "                algorithm_family=_algorithm_family,\n",
    "                algorithm_version=_algorithm_version,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dcm_seg_writer_op\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, spleen_seg_op, {(\"image\", \"image\")})\n",
    "\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(spleen_seg_op, dicom_seg_writer, {(\"seg_image\", \"seg_image\")})\n",
    "\n",
    "        self._logger.debug(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "# For list of string values, e.g. \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"], it is a match if all elements\n",
    "# are all in the multi-value attribute of the DICOM series.\n",
    "\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\",\n",
    "                \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Creates the app and test it standalone.\n",
    "    AISpleenSegApp().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter.\n",
    "\n",
    "### \\_\\_main\\_\\_.py\n",
    "\n",
    "\\_\\_main\\_\\_.py is needed for <a href=\"../../developing_with_sdk/packaging_app.html#required-arguments\">MONAI Application Packager</a> to detect the main application code (`app.py`) when the application is executed with the application folder path (e.g., `python simple_imaging_app`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/__main__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/__main__.py\n",
    "from app import AISpleenSegApp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py\t__main__.py  spleen_seg_operator.py\n"
     ]
    }
   ],
   "source": [
    "!ls my_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this time, let's execute the app in the command line.\n",
    "\n",
    ":::{note}\n",
    "Since the environment variables have been set and contain the correct paths, it is not necessary to provide the command line options on running the application.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/deploy/utils/importutil.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "[\u001b[32minfo\u001b[m] [fragment.cpp:969] Loading extensions from configs...\n",
      "[2025-10-29 15:07:47,733] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, triton_server_netloc=None, argv=['my_app'])\n",
      "[2025-10-29 15:07:47,735] [INFO] (root) - AppContext object: AppContext(input_path=dcm, output_path=output, model_path=models, workdir=), triton_server_netloc=\n",
      "[2025-10-29 15:07:47,735] [INFO] (app.AISpleenSegApp) - App input and output path: dcm, output\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:344] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2508] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2579] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2581] Waiting for completion...\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:191] Scheduling 5 entities\n",
      "[2025-10-29 15:07:47,871] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "[2025-10-29 15:07:48,177] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "[2025-10-29 15:07:48,177] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "[2025-10-29 15:07:48,177] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2025-10-29 15:07:48,177] [INFO] (root) -     On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "[2025-10-29 15:07:48,177] [INFO] (root) -         Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -     On attribute: 'Modality' to match value: '(?i)CT'\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -         Series attribute Modality value: CT\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -     On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -         Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -     On attribute: 'ImageType' to match value: ['PRIMARY', 'ORIGINAL']\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -         Series attribute ImageType value: None\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) -         Instance level attribute ImageType value: [\"['ORIGINAL', 'PRIMARY', 'AXIAL', 'CT_SOM5 SPI']\"]\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) - Series Selection finalized\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) - Series Description of selected DICOM Series for inference: ABD/PANC 3.0 B31f\n",
      "[2025-10-29 15:07:48,178] [INFO] (root) - Series Instance UID of selected DICOM Series for inference: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "[2025-10-29 15:07:48,631] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Converted Image object metadata:\n",
      "[2025-10-29 15:07:48,631] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239, type <class 'str'>\n",
      "[2025-10-29 15:07:48,631] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDate: 20090831, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesTime: 101721.452, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Modality: CT, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDescription: ABD/PANC 3.0 B31f, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - PatientPosition: HFS, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesNumber: 8, type <class 'int'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_pixel_spacing: 1.5, type <class 'float'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_direction_cosine: [1.0, 0.0, 0.0], type <class 'list'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_direction_cosine: [0.0, 1.0, 0.0], type <class 'list'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_direction_cosine: [0.0, 0.0, 1.0], type <class 'list'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - dicom_affine_transform: [[   0.7890625    0.           0.        -197.60547  ]\n",
      " [   0.           0.7890625    0.        -398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - nifti_affine_transform: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyID: , type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDate: 20090831, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyTime: 095948.599, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDescription: CT ABDOMEN W IV CONTRAST, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - AccessionNumber: 5471978513296937, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - selection_name: CT Series, type <class 'str'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - affine: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2025-10-29 15:07:48,632] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - space: RAS, type <class 'str'>\n",
      "2025-10-29 15:07:49,474 INFO image_writer.py:197 - writing: /home/mqin/src/md-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "[2025-10-29 15:07:51,461] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Input of <class 'monai.data.meta_tensor.MetaTensor'> shape: torch.Size([1, 1, 270, 270, 106])\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/inferers/utils.py:226: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  win_data = torch.cat([inputs[win_slice] for win_slice in unravel_slice]).to(sw_device)\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/monai/inferers/utils.py:370: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "  out[idx_zm] += p\n",
      "2025-10-29 15:07:52,554 INFO image_writer.py:197 - writing: /home/mqin/src/md-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n",
      "[2025-10-29 15:07:54,047] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform length/batch size of output: 1\n",
      "[2025-10-29 15:07:54,048] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform pixel spacings for pred: tensor([0.7891, 0.7891, 1.5000], dtype=torch.float64)\n",
      "[2025-10-29 15:07:54,179] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform pred of <class 'numpy.ndarray'> shape: (1, 512, 512, 204)\n",
      "[2025-10-29 15:07:54,217] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image numpy array of type <class 'numpy.ndarray'> shape: (204, 512, 512)\n",
      "[2025-10-29 15:07:54,222] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image pixel max value: 1\n",
      "/home/mqin/src/md-app-sdk/.venv/lib/python3.10/site-packages/highdicom/base.py:165: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  check_person_name(patient_name)\n",
      "[2025-10-29 15:07:55,664] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2025-10-29 15:07:55,664] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "[2025-10-29 15:07:55,664] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2025-10-29 15:07:55,664] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "[2025-10-29 15:07:55,665] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "[2025-10-29 15:07:55,665] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2025-10-29 15:07:55,665] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "[2025-10-29 15:07:55,665] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "[2025-10-29 15:07:55,665] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:372] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:401] Scheduler finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2588] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2597] Graph execution finished.\n",
      "[2025-10-29 15:07:55,784] [INFO] (app.AISpleenSegApp) - End run\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:379] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!python my_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "1.2.826.0.1.3680043.10.511.3.99795707331151027360518347004084832.dcm\n",
      "saved_images_folder\n",
      "\n",
      "output/saved_images_folder:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626\n",
      "\n",
      "output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n"
     ]
    }
   ],
   "source": [
    "!ls -R $HOLOSCAN_OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's package the app with [MONAI Application Packager](/developing_with_sdk/packaging_app).\n",
    "\n",
    "In this version of the App SDK, we need to write out the configuration yaml file as well as the package requirements file, in the application folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/app.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.yaml\n",
    "%YAML 1.2\n",
    "---\n",
    "application:\n",
    "  title: MONAI Deploy App Package - MONAI Bundle AI App\n",
    "  version: 1.0\n",
    "  inputFormats: [\"file\"]\n",
    "  outputFormats: [\"file\"]\n",
    "\n",
    "resources:\n",
    "  cpu: 1\n",
    "  gpu: 1\n",
    "  memory: 1Gi\n",
    "  gpuMemory: 6Gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/requirements.txt\n",
    "highdicom>=0.18.2\n",
    "monai>=1.0\n",
    "nibabel>=3.2.1\n",
    "numpy>=1.21.6\n",
    "pydicom>=2.3.0\n",
    "setuptools>=59.5.0 # for pkg_resources\n",
    "SimpleITK>=2.0.0\n",
    "torch>=1.12.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the CLI package command to build the MONAI Application Package (MAP) container image based on a supported base image.\n",
    "\n",
    ":::{note}\n",
    "Building a MONAI Application Package (Docker image) can take time. Use `-l DEBUG` option to see the progress.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-29 15:07:57,846] [INFO] (common) - Downloading CLI manifest file...\n",
      "[2025-10-29 15:07:58,065] [DEBUG] (common) - Validating CLI manifest file...\n",
      "[2025-10-29 15:07:58,066] [INFO] (packager.parameters) - Application: /home/mqin/src/md-app-sdk/notebooks/tutorials/my_app\n",
      "[2025-10-29 15:07:58,067] [INFO] (packager.parameters) - Detected application type: Python Module\n",
      "[2025-10-29 15:07:58,067] [INFO] (packager) - Scanning for models in /home/mqin/src/md-app-sdk/notebooks/tutorials/models...\n",
      "[2025-10-29 15:07:58,068] [DEBUG] (packager) - Model model=/home/mqin/src/md-app-sdk/notebooks/tutorials/models/model added.\n",
      "[2025-10-29 15:07:58,068] [INFO] (packager) - Reading application configuration from /home/mqin/src/md-app-sdk/notebooks/tutorials/my_app/app.yaml...\n",
      "[2025-10-29 15:07:58,071] [INFO] (packager) - Generating app.json...\n",
      "[2025-10-29 15:07:58,071] [INFO] (packager) - Generating pkg.json...\n",
      "[2025-10-29 15:07:58,074] [DEBUG] (common) - \n",
      "=============== Begin app.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app\\\"]\",\n",
      "    \"environment\": {\n",
      "        \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "        \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "        \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "        \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "        \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "        \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "        \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "        \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "        \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "        \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"path\": \"input/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"liveness\": null,\n",
      "    \"output\": {\n",
      "        \"path\": \"output/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"readiness\": null,\n",
      "    \"sdk\": \"monai-deploy\",\n",
      "    \"sdkVersion\": \"1.0.0\",\n",
      "    \"timeout\": 0,\n",
      "    \"version\": 1.0,\n",
      "    \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "================ End app.json ================\n",
      "                 \n",
      "[2025-10-29 15:07:58,075] [DEBUG] (common) - \n",
      "=============== Begin pkg.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "    \"modelRoot\": \"/opt/holoscan/models\",\n",
      "    \"models\": {\n",
      "        \"model\": \"/opt/holoscan/models/model\"\n",
      "    },\n",
      "    \"resources\": {\n",
      "        \"cpu\": 1,\n",
      "        \"gpu\": 1,\n",
      "        \"memory\": \"1Gi\",\n",
      "        \"gpuMemory\": \"6Gi\"\n",
      "    },\n",
      "    \"version\": 1.0,\n",
      "    \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "================ End pkg.json ================\n",
      "                 \n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) - ================ Begin requirements.txt ================\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   highdicom>=0.18.2\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   monai>=1.0\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   nibabel>=3.2.1\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   numpy>=1.21.6\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   pydicom>=2.3.0\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   setuptools>=59.5.0 # for pkg_resources\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   SimpleITK>=2.0.0\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   torch>=1.12.0\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) -   \n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) - ================ End requirements.txt ==================\n",
      "[2025-10-29 15:07:58,098] [DEBUG] (packager.builder) - \n",
      "========== Begin Build Parameters ==========\n",
      "{'add_hosts': None,\n",
      " 'additional_lib_paths': '',\n",
      " 'app_config_file_path': PosixPath('/home/mqin/src/md-app-sdk/notebooks/tutorials/my_app/app.yaml'),\n",
      " 'app_dir': PosixPath('/opt/holoscan/app'),\n",
      " 'app_json': '/etc/holoscan/app.json',\n",
      " 'application': PosixPath('/home/mqin/src/md-app-sdk/notebooks/tutorials/my_app'),\n",
      " 'application_directory': PosixPath('/home/mqin/src/md-app-sdk/notebooks/tutorials/my_app'),\n",
      " 'application_type': 'PythonModule',\n",
      " 'build_cache': PosixPath('/home/mqin/.holoscan_build_cache'),\n",
      " 'cmake_args': '',\n",
      " 'command': '[\"python3\", \"/opt/holoscan/app\"]',\n",
      " 'command_filename': 'my_app',\n",
      " 'config_file_path': PosixPath('/var/holoscan/app.yaml'),\n",
      " 'docs_dir': PosixPath('/opt/holoscan/docs'),\n",
      " 'full_input_path': PosixPath('/var/holoscan/input'),\n",
      " 'full_output_path': PosixPath('/var/holoscan/output'),\n",
      " 'gid': 1000,\n",
      " 'holoscan_sdk_version': '3.5.0',\n",
      " 'includes': [],\n",
      " 'input_data': None,\n",
      " 'input_dir': 'input/',\n",
      " 'lib_dir': PosixPath('/opt/holoscan/lib'),\n",
      " 'logs_dir': PosixPath('/var/holoscan/logs'),\n",
      " 'models': {'model': PosixPath('/home/mqin/src/md-app-sdk/notebooks/tutorials/models/model')},\n",
      " 'models_dir': PosixPath('/opt/holoscan/models'),\n",
      " 'monai_deploy_app_sdk_version': '1.0.0',\n",
      " 'no_cache': False,\n",
      " 'output_dir': 'output/',\n",
      " 'pip_packages': None,\n",
      " 'pkg_json': '/etc/holoscan/pkg.json',\n",
      " 'requirements_file_path': PosixPath('/home/mqin/src/md-app-sdk/notebooks/tutorials/my_app/requirements.txt'),\n",
      " 'sdk': <SdkType.MonaiDeploy: 'monai-deploy'>,\n",
      " 'sdk_type': 'monai-deploy',\n",
      " 'tarball_output': None,\n",
      " 'timeout': 0,\n",
      " 'title': 'MONAI Deploy App Package - MONAI Bundle AI App',\n",
      " 'uid': 1000,\n",
      " 'username': 'holoscan',\n",
      " 'version': 1.0,\n",
      " 'working_dir': PosixPath('/var/holoscan')}\n",
      "=========== End Build Parameters ===========\n",
      "\n",
      "[2025-10-29 15:07:58,099] [DEBUG] (packager.builder) - \n",
      "========== Begin Platform Parameters ==========\n",
      "{'base_image': 'nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04',\n",
      " 'build_image': None,\n",
      " 'cuda_deb_arch': 'x86_64',\n",
      " 'custom_base_image': False,\n",
      " 'custom_holoscan_sdk': False,\n",
      " 'custom_monai_deploy_sdk': True,\n",
      " 'gpu_type': 'dgpu',\n",
      " 'holoscan_deb_arch': 'amd64',\n",
      " 'holoscan_sdk_file': '3.5.0',\n",
      " 'holoscan_sdk_filename': '3.5.0',\n",
      " 'monai_deploy_sdk_file': PosixPath('/home/mqin/src/md-app-sdk/dist/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl'),\n",
      " 'monai_deploy_sdk_filename': 'monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl',\n",
      " 'tag': 'my_app:1.0',\n",
      " 'target_arch': 'x86_64'}\n",
      "=========== End Platform Parameters ===========\n",
      "\n",
      "[2025-10-29 15:07:58,116] [DEBUG] (packager.builder) - \n",
      "========== Begin Dockerfile ==========\n",
      "\n",
      "ARG GPU_TYPE=dgpu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FROM nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04 AS base\n",
      "\n",
      "RUN apt-get update \\\n",
      "    && apt-get install -y --no-install-recommends --no-install-suggests \\\n",
      "        curl \\\n",
      "        jq \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# FROM base AS mofed-installer\n",
      "# ARG MOFED_VERSION=23.10-2.1.3.1\n",
      "\n",
      "# # In a container, we only need to install the user space libraries, though the drivers are still\n",
      "# # needed on the host.\n",
      "# # Note: MOFED's installation is not easily portable, so we can't copy the output of this stage\n",
      "# # to our final stage, but must inherit from it. For that reason, we keep track of the build/install\n",
      "# # only dependencies in the `MOFED_DEPS` variable (parsing the output of `--check-deps-only`) to\n",
      "# # remove them in that same layer, to ensure they are not propagated in the final image.\n",
      "# WORKDIR /opt/nvidia/mofed\n",
      "# ARG MOFED_INSTALL_FLAGS=\"--dpdk --with-mft --user-space-only --force --without-fw-update\"\n",
      "# RUN UBUNTU_VERSION=$(cat /etc/lsb-release | grep DISTRIB_RELEASE | cut -d= -f2) \\\n",
      "#     && OFED_PACKAGE=\"MLNX_OFED_LINUX-${MOFED_VERSION}-ubuntu${UBUNTU_VERSION}-$(uname -m)\" \\\n",
      "#     && curl -S -# -o ${OFED_PACKAGE}.tgz -L \\\n",
      "#         https://www.mellanox.com/downloads/ofed/MLNX_OFED-${MOFED_VERSION}/${OFED_PACKAGE}.tgz \\\n",
      "#     && tar xf ${OFED_PACKAGE}.tgz \\\n",
      "#     && MOFED_INSTALLER=$(find . -name mlnxofedinstall -type f -executable -print) \\\n",
      "#     && MOFED_DEPS=$(${MOFED_INSTALLER} ${MOFED_INSTALL_FLAGS} --check-deps-only 2>/dev/null | tail -n1 |  cut -d' ' -f3-) \\\n",
      "#     && apt-get update \\\n",
      "#     && apt-get install --no-install-recommends -y ${MOFED_DEPS} \\\n",
      "#     && ${MOFED_INSTALLER} ${MOFED_INSTALL_FLAGS} \\\n",
      "#     && rm -r * \\\n",
      "#     && apt-get remove -y ${MOFED_DEPS} && apt-get autoremove -y \\\n",
      "#     && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "FROM base AS release\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "ENV TERM=xterm-256color\n",
      "\n",
      "ARG GPU_TYPE\n",
      "ARG UNAME\n",
      "ARG UID\n",
      "ARG GID\n",
      "\n",
      "RUN mkdir -p /etc/holoscan/ \\\n",
      "        && mkdir -p /opt/holoscan/ \\\n",
      "        && mkdir -p /var/holoscan \\\n",
      "        && mkdir -p /opt/holoscan/app \\\n",
      "        && mkdir -p /var/holoscan/input \\\n",
      "        && mkdir -p /var/holoscan/output\n",
      "\n",
      "LABEL base=\"nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04\"\n",
      "LABEL tag=\"my_app:1.0\"\n",
      "LABEL org.opencontainers.image.title=\"MONAI Deploy App Package - MONAI Bundle AI App\"\n",
      "LABEL org.opencontainers.image.version=\"1.0\"\n",
      "LABEL org.nvidia.holoscan=\"3.5.0\"\n",
      "\n",
      "LABEL org.monai.deploy.app-sdk=\"1.0.0\"\n",
      "\n",
      "ENV HOLOSCAN_INPUT_PATH=/var/holoscan/input\n",
      "ENV HOLOSCAN_OUTPUT_PATH=/var/holoscan/output\n",
      "ENV HOLOSCAN_WORKDIR=/var/holoscan\n",
      "ENV HOLOSCAN_APPLICATION=/opt/holoscan/app\n",
      "ENV HOLOSCAN_TIMEOUT=0\n",
      "ENV HOLOSCAN_MODEL_PATH=/opt/holoscan/models\n",
      "ENV HOLOSCAN_DOCS_PATH=/opt/holoscan/docs\n",
      "ENV HOLOSCAN_CONFIG_PATH=/var/holoscan/app.yaml\n",
      "ENV HOLOSCAN_APP_MANIFEST_PATH=/etc/holoscan/app.json\n",
      "ENV HOLOSCAN_PKG_MANIFEST_PATH=/etc/holoscan/pkg.json\n",
      "ENV HOLOSCAN_LOGS_PATH=/var/holoscan/logs\n",
      "ENV HOLOSCAN_VERSION=3.5.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# If torch is installed, we can skip installing Python\n",
      "ENV PYTHON_VERSION=3.12.3-*\n",
      "ENV PYTHON_PIP_VERSION=24.0+dfsg-*\n",
      "\n",
      "RUN apt update \\\n",
      "    && apt-get install -y --no-install-recommends --no-install-suggests \\\n",
      "        python3-minimal=${PYTHON_VERSION} \\\n",
      "        libpython3-stdlib=${PYTHON_VERSION} \\\n",
      "        python3=${PYTHON_VERSION} \\\n",
      "        python3-venv=${PYTHON_VERSION} \\\n",
      "        python3-pip=${PYTHON_PIP_VERSION} \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RUN if id \"ubuntu\" >/dev/null 2>&1; then touch /var/mail/ubuntu && chown ubuntu /var/mail/ubuntu && userdel -r ubuntu; fi\n",
      "RUN groupadd -f -g $GID $UNAME\n",
      "RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME\n",
      "RUN chown -R holoscan /var/holoscan && \\\n",
      "    chown -R holoscan /var/holoscan/input && \\\n",
      "    chown -R holoscan /var/holoscan/output\n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "# Copy HAP/MAP tool script\n",
      "COPY ./tools /var/holoscan/tools\n",
      "RUN chmod +x /var/holoscan/tools\n",
      "\n",
      "# Remove EXTERNALLY-MANAGED directory\n",
      "RUN rm -rf /usr/lib/python3.12/EXTERNALLY-MANAGED\n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "USER $UNAME\n",
      "\n",
      "ENV PATH=/home/${UNAME}/.local/bin:/opt/nvidia/holoscan/bin:$PATH\n",
      "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/${UNAME}/.local/lib/python3.10/site-packages/holoscan/lib\n",
      "\n",
      "COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "\n",
      "\n",
      "# Install MONAI Deploy App SDK\n",
      "# Copy user-specified MONAI Deploy SDK file\n",
      "COPY ./monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl\n",
      "RUN pip install /tmp/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl\n",
      "\n",
      "COPY ./models  /opt/holoscan/models\n",
      "\n",
      "\n",
      "COPY ./map/app.json /etc/holoscan/app.json\n",
      "COPY ./app.config /var/holoscan/app.yaml\n",
      "COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "\n",
      "COPY ./app /opt/holoscan/app\n",
      "\n",
      "\n",
      "\n",
      "ENTRYPOINT [\"/var/holoscan/tools\"]\n",
      "=========== End Dockerfile ===========\n",
      "\n",
      "[2025-10-29 15:07:58,636] [INFO] (common) - Using existing Docker BuildKit builder `holoscan_app_builder`\n",
      "[2025-10-29 15:07:58,636] [DEBUG] (packager.builder) - Building Holoscan Application Package: tag=my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "[2025-10-29 15:07:58,636] [INFO] (packager.builder) - \n",
      "===============================================================================\n",
      "Building image for:                 x64-workstation\n",
      "    Architecture:                   linux/amd64\n",
      "    Base Image:                     nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04\n",
      "    Build Image:                    N/A\n",
      "    Cache:                          Enabled\n",
      "    Configuration:                  dgpu\n",
      "    Holoscan SDK Package:           3.5.0\n",
      "    MONAI Deploy App SDK Package:   /home/mqin/src/md-app-sdk/dist/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl\n",
      "    gRPC Health Probe:              N/A\n",
      "    SDK Version:                    3.5.0\n",
      "    SDK:                            monai-deploy\n",
      "    Tag:                            my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Included features/dependencies: N/A\n",
      "    \n",
      "#0 building with \"holoscan_app_builder\" instance using docker-container driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 4.94kB done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [auth] nvidia/cuda:pull token for nvcr.io\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04\n",
      "#3 DONE 0.8s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context:\n",
      "#4 transferring context: 1.80kB done\n",
      "#4 DONE 0.1s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 importing cache manifest from local:17937210092949024565\n",
      "#6 inferred cache manifest type: application/vnd.oci.image.index.v1+json done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [base 1/2] FROM nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04@sha256:ebef3c171eeef0298e4eb2e4be843105edf3b8b0ac45e0b43acee358e8046867\n",
      "#7 resolve nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04@sha256:ebef3c171eeef0298e4eb2e4be843105edf3b8b0ac45e0b43acee358e8046867 0.0s done\n",
      "#7 DONE 0.1s\n",
      "\n",
      "#8 importing cache manifest from nvcr.io/nvidia/cuda:12.8.1-runtime-ubuntu24.04\n",
      "#8 inferred cache manifest type: application/vnd.docker.distribution.manifest.list.v2+json done\n",
      "#8 DONE 0.3s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 19.58MB 0.1s done\n",
      "#5 DONE 0.2s\n",
      "\n",
      "#9 [release  1/21] RUN mkdir -p /etc/holoscan/         && mkdir -p /opt/holoscan/         && mkdir -p /var/holoscan         && mkdir -p /opt/holoscan/app         && mkdir -p /var/holoscan/input         && mkdir -p /var/holoscan/output\n",
      "#9 CACHED\n",
      "\n",
      "#10 [release  9/21] RUN chmod +x /var/holoscan/tools\n",
      "#10 CACHED\n",
      "\n",
      "#11 [release  4/21] RUN groupadd -f -g 1000 holoscan\n",
      "#11 CACHED\n",
      "\n",
      "#12 [base 2/2] RUN apt-get update     && apt-get install -y --no-install-recommends --no-install-suggests         curl         jq     && rm -rf /var/lib/apt/lists/*\n",
      "#12 CACHED\n",
      "\n",
      "#13 [release  7/21] WORKDIR /var/holoscan\n",
      "#13 CACHED\n",
      "\n",
      "#14 [release  8/21] COPY ./tools /var/holoscan/tools\n",
      "#14 CACHED\n",
      "\n",
      "#15 [release 12/21] COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "#15 CACHED\n",
      "\n",
      "#16 [release  3/21] RUN if id \"ubuntu\" >/dev/null 2>&1; then touch /var/mail/ubuntu && chown ubuntu /var/mail/ubuntu && userdel -r ubuntu; fi\n",
      "#16 CACHED\n",
      "\n",
      "#17 [release 10/21] RUN rm -rf /usr/lib/python3.12/EXTERNALLY-MANAGED\n",
      "#17 CACHED\n",
      "\n",
      "#18 [release  2/21] RUN apt update     && apt-get install -y --no-install-recommends --no-install-suggests         python3-minimal=3.12.3-*         libpython3-stdlib=3.12.3-*         python3=3.12.3-*         python3-venv=3.12.3-*         python3-pip=24.0+dfsg-*     && rm -rf /var/lib/apt/lists/*\n",
      "#18 CACHED\n",
      "\n",
      "#19 [release  5/21] RUN useradd -rm -d /home/holoscan -s /bin/bash -g 1000 -G sudo -u 1000 holoscan\n",
      "#19 CACHED\n",
      "\n",
      "#20 [release  6/21] RUN chown -R holoscan /var/holoscan &&     chown -R holoscan /var/holoscan/input &&     chown -R holoscan /var/holoscan/output\n",
      "#20 CACHED\n",
      "\n",
      "#21 [release 13/21] RUN pip install --upgrade pip\n",
      "#21 CACHED\n",
      "\n",
      "#22 [release 11/21] WORKDIR /var/holoscan\n",
      "#22 CACHED\n",
      "\n",
      "#23 [release 14/21] RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 7.34MB / 4.07GB 0.2s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 212.86MB / 4.07GB 3.5s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 419.43MB / 4.07GB 6.9s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 627.05MB / 4.07GB 10.4s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 834.67MB / 4.07GB 14.4s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 1.04GB / 4.07GB 19.1s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 1.25GB / 4.07GB 22.7s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 1.46GB / 4.07GB 26.0s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 1.67GB / 4.07GB 29.1s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 1.88GB / 4.07GB 32.9s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 2.09GB / 4.07GB 36.6s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 2.30GB / 4.07GB 39.8s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 2.50GB / 4.07GB 43.1s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 2.71GB / 4.07GB 46.4s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 2.92GB / 4.07GB 49.7s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 3.13GB / 4.07GB 53.0s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 3.34GB / 4.07GB 56.3s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 3.55GB / 4.07GB 59.6s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 3.75GB / 4.07GB 63.3s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 3.96GB / 4.07GB 68.1s\n",
      "#23 sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 4.07GB / 4.07GB 71.5s done\n",
      "#23 extracting sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f\n",
      "#23 extracting sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f 111.5s done\n",
      "#23 CACHED\n",
      "\n",
      "#24 [release 15/21] COPY ./monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl\n",
      "#24 DONE 4.6s\n",
      "\n",
      "#25 [release 16/21] RUN pip install /tmp/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl\n",
      "#25 0.924 Defaulting to user installation because normal site-packages is not writeable\n",
      "#25 1.015 Processing /tmp/monai_deploy_app_sdk-1.0.0+39.g4a8fba0.dirty-py3-none-any.whl\n",
      "#25 1.022 Requirement already satisfied: numpy>=1.21.6 in /home/holoscan/.local/lib/python3.12/site-packages (from monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (2.3.3)\n",
      "#25 1.223 Collecting holoscan<=3.5.0 (from monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 1.356   Downloading holoscan-3.5.0-cp312-cp312-manylinux_2_35_x86_64.whl.metadata (6.5 kB)\n",
      "#25 1.480 Collecting holoscan-cli<=3.5.0 (from monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 1.557   Downloading holoscan_cli-3.5.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "#25 1.631 Collecting colorama>=0.4.1 (from monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 1.645   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "#25 1.742 Collecting tritonclient>=2.53.0 (from tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 1.757   Downloading tritonclient-2.61.0-py3-none-manylinux1_x86_64.whl.metadata (2.9 kB)\n",
      "#25 1.848 Collecting typeguard>=3.0.0 (from monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 1.862   Downloading typeguard-4.4.4-py3-none-any.whl.metadata (3.3 kB)\n",
      "#25 1.880 Requirement already satisfied: pip>22.0.2 in /home/holoscan/.local/lib/python3.12/site-packages (from holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (25.2)\n",
      "#25 1.933 Collecting cupy-cuda12x<14.0,>=12.2 (from holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 1.947   Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
      "#25 2.015 Collecting cloudpickle<4.0,>=3.0 (from holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.030   Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "#25 2.047 Requirement already satisfied: pillow>=11.2 in /home/holoscan/.local/lib/python3.12/site-packages (from holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (11.3.0)\n",
      "#25 2.138 Collecting wheel-axle-runtime<1.0 (from holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.154   Downloading wheel_axle_runtime-0.0.7-py3-none-any.whl.metadata (8.3 kB)\n",
      "#25 2.240 Collecting fastrlock>=0.5 (from cupy-cuda12x<14.0,>=12.2->holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.254   Downloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "#25 2.274 Requirement already satisfied: Jinja2<4.0.0,>=3.1.6 in /home/holoscan/.local/lib/python3.12/site-packages (from holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (3.1.6)\n",
      "#25 2.274 Requirement already satisfied: packaging<26.0,>=25.0 in /home/holoscan/.local/lib/python3.12/site-packages (from holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (25.0)\n",
      "#25 2.410 Collecting psutil<8.0,>=7.0.0 (from holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.424   Downloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
      "#25 2.524 Collecting python-on-whales>=0.77.0 (from holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.539   Downloading python_on_whales-0.79.0-py3-none-any.whl.metadata (18 kB)\n",
      "#25 2.635 Collecting pyyaml<7.0,>=6.0 (from holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.649   Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
      "#25 2.727 Collecting requests<3.0,>=2.32 (from holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.741   Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "#25 2.762 Requirement already satisfied: MarkupSafe>=2.0 in /home/holoscan/.local/lib/python3.12/site-packages (from Jinja2<4.0.0,>=3.1.6->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (3.0.3)\n",
      "#25 2.921 Collecting charset_normalizer<4,>=2 (from requests<3.0,>=2.32->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 2.935   Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
      "#25 3.013 Collecting idna<4,>=2.5 (from requests<3.0,>=2.32->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 3.027   Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "#25 3.123 Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.32->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 3.137   Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "#25 3.229 Collecting certifi>=2017.4.17 (from requests<3.0,>=2.32->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 3.243   Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "#25 3.263 Requirement already satisfied: filelock in /home/holoscan/.local/lib/python3.12/site-packages (from wheel-axle-runtime<1.0->holoscan<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (3.19.1)\n",
      "#25 3.426 Collecting pydantic!=2.0.*,<3,>=2 (from python-on-whales>=0.77.0->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 3.440   Downloading pydantic-2.12.3-py3-none-any.whl.metadata (87 kB)\n",
      "#25 3.475 Requirement already satisfied: typing-extensions in /home/holoscan/.local/lib/python3.12/site-packages (from python-on-whales>=0.77.0->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty) (4.15.0)\n",
      "#25 3.508 Collecting annotated-types>=0.6.0 (from pydantic!=2.0.*,<3,>=2->python-on-whales>=0.77.0->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 3.522   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "#25 4.302 Collecting pydantic-core==2.41.4 (from pydantic!=2.0.*,<3,>=2->python-on-whales>=0.77.0->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 4.316   Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)\n",
      "#25 4.366 Collecting typing-inspection>=0.4.2 (from pydantic!=2.0.*,<3,>=2->python-on-whales>=0.77.0->holoscan-cli<=3.5.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 4.381   Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "#25 4.432 Collecting perf-analyzer (from tritonclient>=2.53.0->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 4.448   Downloading perf_analyzer-2.59.1-py3-none-manylinux_2_38_x86_64.whl.metadata (6.3 kB)\n",
      "#25 4.622 Collecting python-rapidjson>=0.9.1 (from tritonclient>=2.53.0->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 4.636   Downloading python_rapidjson-1.22-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (24 kB)\n",
      "#25 5.324 Collecting aiohttp<4.0.0,>=3.8.1 (from tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 5.338   Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "#25 5.429 Collecting cuda-python (from tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 5.444   Downloading cuda_python-13.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "#25 5.618 Collecting geventhttpclient>=2.3.3 (from tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 5.632   Downloading geventhttpclient-2.3.5-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (8.4 kB)\n",
      "#25 6.218 Collecting grpcio<1.68,>=1.63.0 (from tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 6.234   Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "#25 6.433 Collecting protobuf<6.0dev,>=5.26.1 (from tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 6.448   Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "#25 6.497 Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 6.511   Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "#25 6.581 Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 6.596   Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "#25 6.667 Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 6.681   Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "#25 6.806 Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 6.820   Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "#25 7.178 Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 7.192   Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "#25 7.305 Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 7.320   Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "#25 7.689 Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.1->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 7.705   Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "#25 7.925 Collecting gevent (from geventhttpclient>=2.3.3->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 7.940   Downloading gevent-25.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (14 kB)\n",
      "#25 8.041 Collecting brotli (from geventhttpclient>=2.3.3->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.055   Downloading Brotli-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "#25 8.133 Collecting cuda-bindings~=13.0.3 (from cuda-python->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.147   Downloading cuda_bindings-13.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.3 kB)\n",
      "#25 8.199 Collecting cuda-pathfinder~=1.1 (from cuda-python->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.214   Downloading cuda_pathfinder-1.3.2-py3-none-any.whl.metadata (1.9 kB)\n",
      "#25 8.411 Collecting greenlet>=3.2.2 (from gevent->geventhttpclient>=2.3.3->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.427   Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "#25 8.484 Collecting zope.event (from gevent->geventhttpclient>=2.3.3->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.501   Downloading zope_event-6.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "#25 8.792 Collecting zope.interface (from gevent->geventhttpclient>=2.3.3->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.807   Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (44 kB)\n",
      "#25 8.969 Collecting setuptools>=75.8.2 (from zope.event->gevent->geventhttpclient>=2.3.3->tritonclient[all]>=2.53.0->monai-deploy-app-sdk==1.0.0+39.g4a8fba0.dirty)\n",
      "#25 8.982   Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "#25 9.100 Downloading holoscan-3.5.0-cp312-cp312-manylinux_2_35_x86_64.whl (40.6 MB)\n",
      "#25 12.15     40.6/40.6 MB 13.3 MB/s  0:00:03\n",
      "#25 12.16 Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "#25 12.20 Downloading cupy_cuda12x-13.6.0-cp312-cp312-manylinux2014_x86_64.whl (112.9 MB)\n",
      "#25 14.23     112.9/112.9 MB 55.6 MB/s  0:00:02\n",
      "#25 14.24 Downloading holoscan_cli-3.5.0-py3-none-any.whl (73 kB)\n",
      "#25 14.27 Downloading psutil-7.1.2-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (258 kB)\n",
      "#25 14.31 Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
      "#25 14.35     807.9/807.9 kB 19.3 MB/s  0:00:00\n",
      "#25 14.36 Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "#25 14.40 Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
      "#25 14.44 Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "#25 14.47 Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "#25 14.50 Downloading wheel_axle_runtime-0.0.7-py3-none-any.whl (14 kB)\n",
      "#25 14.54 Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "#25 14.57 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#25 14.60 Downloading fastrlock-0.8.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "#25 14.64 Downloading python_on_whales-0.79.0-py3-none-any.whl (118 kB)\n",
      "#25 14.67 Downloading pydantic-2.12.3-py3-none-any.whl (462 kB)\n",
      "#25 14.71 Downloading pydantic_core-2.41.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "#25 14.77     2.1/2.1 MB 40.5 MB/s  0:00:00\n",
      "#25 14.78 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "#25 14.82 Downloading tritonclient-2.61.0-py3-none-manylinux1_x86_64.whl (111 kB)\n",
      "#25 14.85 Downloading python_rapidjson-1.22-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "#25 14.90     1.7/1.7 MB 33.1 MB/s  0:00:00\n",
      "#25 14.92 Downloading aiohttp-3.13.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "#25 14.98     1.8/1.8 MB 32.3 MB/s  0:00:00\n",
      "#25 15.00 Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "#25 15.12     5.9/5.9 MB 48.6 MB/s  0:00:00\n",
      "#25 15.14 Downloading multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
      "#25 15.18 Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "#25 15.21 Downloading yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
      "#25 15.25 Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "#25 15.29 Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "#25 15.32 Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "#25 15.36 Downloading frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
      "#25 15.39 Downloading geventhttpclient-2.3.5-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (114 kB)\n",
      "#25 15.42 Downloading propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
      "#25 15.45 Downloading typeguard-4.4.4-py3-none-any.whl (34 kB)\n",
      "#25 15.49 Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "#25 15.52 Downloading Brotli-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "#25 15.60     2.9/2.9 MB 40.0 MB/s  0:00:00\n",
      "#25 15.61 Downloading cuda_python-13.0.3-py3-none-any.whl (7.6 kB)\n",
      "#25 15.64 Downloading cuda_bindings-13.0.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.1 MB)\n",
      "#25 15.93     12.1/12.1 MB 42.4 MB/s  0:00:00\n",
      "#25 15.94 Downloading cuda_pathfinder-1.3.2-py3-none-any.whl (27 kB)\n",
      "#25 15.97 Downloading gevent-25.9.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.1 MB)\n",
      "#25 16.02     2.1/2.1 MB 38.0 MB/s  0:00:00\n",
      "#25 16.04 Downloading greenlet-3.2.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (607 kB)\n",
      "#25 16.07     607.6/607.6 kB 13.0 MB/s  0:00:00\n",
      "#25 16.09 Downloading perf_analyzer-2.59.1-py3-none-manylinux_2_38_x86_64.whl (7.2 MB)\n",
      "#25 16.24     7.2/7.2 MB 48.7 MB/s  0:00:00\n",
      "#25 16.25 Downloading zope_event-6.0-py3-none-any.whl (6.4 kB)\n",
      "#25 16.29 Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "#25 16.32     1.2/1.2 MB 29.2 MB/s  0:00:00\n",
      "#25 16.34 Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
      "#25 17.05 Installing collected packages: perf-analyzer, fastrlock, brotli, zope.interface, wheel-axle-runtime, urllib3, typing-inspection, typeguard, setuptools, pyyaml, python-rapidjson, pydantic-core, psutil, protobuf, propcache, multidict, idna, grpcio, greenlet, frozenlist, cupy-cuda12x, cuda-pathfinder, colorama, cloudpickle, charset_normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, zope.event, yarl, tritonclient, requests, pydantic, holoscan, cuda-bindings, aiosignal, python-on-whales, gevent, cuda-python, aiohttp, holoscan-cli, geventhttpclient, monai-deploy-app-sdk\n",
      "#25 24.65 \n",
      "#25 24.66 Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 annotated-types-0.7.0 attrs-25.4.0 brotli-1.1.0 certifi-2025.10.5 charset_normalizer-3.4.4 cloudpickle-3.1.1 colorama-0.4.6 cuda-bindings-13.0.3 cuda-pathfinder-1.3.2 cuda-python-13.0.3 cupy-cuda12x-13.6.0 fastrlock-0.8.3 frozenlist-1.8.0 gevent-25.9.1 geventhttpclient-2.3.5 greenlet-3.2.4 grpcio-1.67.1 holoscan-3.5.0 holoscan-cli-3.5.0 idna-3.11 monai-deploy-app-sdk-1.0.0+39.g4a8fba0.dirty multidict-6.7.0 perf-analyzer-2.59.1 propcache-0.4.1 protobuf-5.29.5 psutil-7.1.2 pydantic-2.12.3 pydantic-core-2.41.4 python-on-whales-0.79.0 python-rapidjson-1.22 pyyaml-6.0.3 requests-2.32.5 setuptools-80.9.0 tritonclient-2.61.0 typeguard-4.4.4 typing-inspection-0.4.2 urllib3-2.5.0 wheel-axle-runtime-0.0.7 yarl-1.22.0 zope.event-6.0 zope.interface-8.0.1\n",
      "#25 24.81 \n",
      "#25 24.81 [notice] A new release of pip is available: 25.2 -> 25.3\n",
      "#25 24.81 [notice] To update, run: python3 -m pip install --upgrade pip\n",
      "#25 DONE 29.6s\n",
      "\n",
      "#26 [release 17/21] COPY ./models  /opt/holoscan/models\n",
      "#26 DONE 0.4s\n",
      "\n",
      "#27 [release 18/21] COPY ./map/app.json /etc/holoscan/app.json\n",
      "#27 DONE 0.1s\n",
      "\n",
      "#28 [release 19/21] COPY ./app.config /var/holoscan/app.yaml\n",
      "#28 DONE 0.1s\n",
      "\n",
      "#29 [release 20/21] COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "#29 DONE 0.1s\n",
      "\n",
      "#30 [release 21/21] COPY ./app /opt/holoscan/app\n",
      "#30 DONE 0.1s\n",
      "\n",
      "#31 exporting to docker image format\n",
      "#31 exporting layers\n",
      "#31 exporting layers 25.0s done\n",
      "#31 exporting manifest sha256:f5f768e72145a101f736be3acc006ad94b8e444544d5cd92576fcfd9a415bc82 0.0s done\n",
      "#31 exporting config sha256:7d6ad11541dfeddf9f3aecebfd4b4d1783ff597146e19879626ba1a70d64cc0b 0.0s done\n",
      "#31 sending tarball\n",
      "#31 ...\n",
      "\n",
      "#32 importing to docker\n",
      "#32 loading layer c3aa0e2870de 32.77kB / 141.70kB\n",
      "#32 loading layer 5b5748692470 557.06kB / 405.37MB\n",
      "#32 loading layer 5b5748692470 199.98MB / 405.37MB 2.1s\n",
      "#32 loading layer 5b5748692470 230.62MB / 405.37MB 4.2s\n",
      "#32 loading layer 5b5748692470 332.01MB / 405.37MB 6.3s\n",
      "#32 loading layer 5b5748692470 381.58MB / 405.37MB 8.4s\n",
      "#32 loading layer 9b2650fa47fa 196.61kB / 17.81MB\n",
      "#32 loading layer a0bbf79e9e22 488B / 488B\n",
      "#32 loading layer 8affaa49cd0b 315B / 315B\n",
      "#32 loading layer ce99ab1b0de8 303B / 303B\n",
      "#32 loading layer 9353ca63afd4 3.91kB / 3.91kB\n",
      "#32 loading layer 9353ca63afd4 3.91kB / 3.91kB 0.9s done\n",
      "#32 loading layer c3aa0e2870de 141.70kB / 141.70kB 11.7s done\n",
      "#32 loading layer 5b5748692470 405.37MB / 405.37MB 11.4s done\n",
      "#32 loading layer 9b2650fa47fa 17.81MB / 17.81MB 1.3s done\n",
      "#32 loading layer a0bbf79e9e22 488B / 488B 1.1s done\n",
      "#32 loading layer 8affaa49cd0b 315B / 315B 1.1s done\n",
      "#32 loading layer ce99ab1b0de8 303B / 303B 1.0s done\n",
      "#32 DONE 11.7s\n",
      "\n",
      "#31 exporting to docker image format\n",
      "#31 sending tarball 91.7s done\n",
      "#31 DONE 116.8s\n",
      "\n",
      "#33 exporting cache to client directory\n",
      "#33 preparing build cache for export\n",
      "#33 writing layer sha256:02d5ae2f5caac28f80c24cb9c346b16e8ec624c2a7587bad83b5032014bc949a\n",
      "#33 writing layer sha256:02d5ae2f5caac28f80c24cb9c346b16e8ec624c2a7587bad83b5032014bc949a done\n",
      "#33 writing layer sha256:03991cb513a808619cc4e566c6beb3d2d53d0a116b73c08ef8a1d0416b68582f done\n",
      "#33 writing layer sha256:0485e1ad7d46995100cf1b77f4ca14706112dd0c6ec89a4b27417fb530d97bc1 done\n",
      "#33 writing layer sha256:05ec76e31584ec109785cc7045bd88df0240411233c2fcdad66b621c662034c0 done\n",
      "#33 writing layer sha256:071ee33ea2913f8a44d367ce1fac3948d244a01a0e58677d20e3d1b11881f63a done\n",
      "#33 writing layer sha256:14b84b8d4a6ce4be61254ca75ddf45982abb303a4d57eba8b27d7cab37a41e3c 0.1s done\n",
      "#33 writing layer sha256:3885d89be02ba72892f7e00190bbce1e182c6e227af496de120953e1ee4b5209 0.0s done\n",
      "#33 writing layer sha256:398182656c471d6ecca3c2d6d30e97193b40ffc8028a94515093960322f3d64e\n",
      "#33 writing layer sha256:398182656c471d6ecca3c2d6d30e97193b40ffc8028a94515093960322f3d64e done\n",
      "#33 writing layer sha256:3d6ab8c799cda2f4c6a6277b0e24dd2231c5de83b0316968b7cce81156bb8be0 done\n",
      "#33 writing layer sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 done\n",
      "#33 writing layer sha256:545a3ada5b6bc612a11c13a659775d67eeda5a61615e7f49c76ecd24adcad626 done\n",
      "#33 writing layer sha256:59d7c8e573228aca7825f7e4b7fa6b6bc7ed478ae59fb28bb2ac6a2ac74f694d done\n",
      "#33 writing layer sha256:5a7813e071bfadf18aaa6ca8318be4824a9b6297b3240f2cc84c1db6f4113040 done\n",
      "#33 writing layer sha256:64e15be5789bebd86903a6d310e097dbae68dc3ba03fb928be998ee4c845cbfc\n",
      "#33 writing layer sha256:64e15be5789bebd86903a6d310e097dbae68dc3ba03fb928be998ee4c845cbfc 7.9s done\n",
      "#33 writing layer sha256:69163a983a2f372a57b6f28a1f9110729939f5c6f64c8643da67bfbefea4ff37\n",
      "#33 writing layer sha256:69163a983a2f372a57b6f28a1f9110729939f5c6f64c8643da67bfbefea4ff37 done\n",
      "#33 writing layer sha256:6cbcf604db99ba3354f68ca5bc8572a0e522071618fce87e884af979913561b4 0.0s done\n",
      "#33 writing layer sha256:7209097bfb98d6f8b422984480f1fddead5ea62f8900ff6b6548e060b71aca76 done\n",
      "#33 writing layer sha256:73389fbd088f5ed5d9fd258baced59de092978b4f483920ea6d074522a105119 done\n",
      "#33 writing layer sha256:7810a059757c895060ebeed11cad61dd0c5f56d60c67337722aa591b670d0e6e\n",
      "#33 writing layer sha256:7810a059757c895060ebeed11cad61dd0c5f56d60c67337722aa591b670d0e6e 0.4s done\n",
      "#33 writing layer sha256:8338f7a2de29d9323f6b4c22114162ba1a104588383518f2de39f2b2523728a4\n",
      "#33 preparing build cache for export 8.7s done\n",
      "#33 writing layer sha256:8338f7a2de29d9323f6b4c22114162ba1a104588383518f2de39f2b2523728a4 0.0s done\n",
      "#33 writing layer sha256:882067111f43dcefcfb9978ba194a78f79bf241e8fda47517aa249574d08d23e done\n",
      "#33 writing layer sha256:998a4a013c678a23f560da30e62402d693c3f667ac211bf2fb83452345fccffd done\n",
      "#33 writing layer sha256:a102f36d092c0e9e0bef8c97854f606af9156aa36ab408e6fa4b88e27124a7e6 done\n",
      "#33 writing layer sha256:a7e0585aa1334f827ee888d93df571cf5ca476e64f9d6fc41514d685358b50a1 done\n",
      "#33 writing layer sha256:b8641f6fe7613397c5a2b24da0b0a541c2511ef1e0347be3cb2139ff622a0f2c done\n",
      "#33 writing layer sha256:bd85ec097de49728b12ba170047e56926e843cdc95b1ec174d6cbdd9a7c2c371 0.0s done\n",
      "#33 writing layer sha256:c5b0ebd4c7a351c4b972af1cfebad9e226e1f3e151dada98a607f838751c4bfa done\n",
      "#33 writing layer sha256:cbb9175a9bc5f6553f8c0c5025ea9521898b8a3956ee24798dc35c24c6185053 done\n",
      "#33 writing layer sha256:dc8ef917f4d947ac946de58bbd3e597df3eccf6d3114660dc1d10ac65d4c9292 done\n",
      "#33 writing layer sha256:e18337ee8b66601667ac278767822c927f4615f72eeb3d154a701fdee7cc3e9e done\n",
      "#33 writing config sha256:301c00d3010aec6415d9b513e1594629fd32ea497f38e397fca7c303fb688b48 0.0s done\n",
      "#33 writing cache manifest sha256:0645c18ac2521c5426db2515fff62620b9d2f5ae88ab9c726bf4a4f820075e24 0.0s done\n",
      "#33 DONE 8.7s\n",
      "[2025-10-29 15:13:45,170] [INFO] (packager) - Build Summary:\n",
      "\n",
      "Platform: x64-workstation/dgpu\n",
      "    Status:     Succeeded\n",
      "    Docker Tag: my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Tarball:    None\n"
     ]
    }
   ],
   "source": [
    "tag_prefix = \"my_app\"\n",
    "\n",
    "!monai-deploy package my_app -m {models_folder} -c my_app/app.yaml -t {tag_prefix}:1.0 --platform x86_64 -l DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MAP Docker image is created.\n",
    "\n",
    "We can choose to display and inspect the MAP manifests by running the container with the `show` command, as well as extracting the manifests and other contents in the MAP by using the `extract` command, but not demonstrated in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_app-x64-workstation-dgpu-linux-amd64                                       1.0                            7d6ad11541df   2 minutes ago   11.5GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep {tag_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing packaged app locally\n",
    "\n",
    "The packaged app can be run locally through [MONAI Application Runner](/developing_with_sdk/executing_packaged_app_locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "dcm\n",
      "[2025-10-29 15:13:47,241] [INFO] (runner) - Checking dependencies...\n",
      "[2025-10-29 15:13:47,241] [INFO] (runner) - --> Verifying if \"docker\" is installed...\n",
      "\n",
      "[2025-10-29 15:13:47,241] [INFO] (runner) - --> Verifying if \"docker-buildx\" is installed...\n",
      "\n",
      "[2025-10-29 15:13:47,241] [INFO] (runner) - --> Verifying if \"my_app-x64-workstation-dgpu-linux-amd64:1.0\" is available...\n",
      "\n",
      "[2025-10-29 15:13:47,343] [INFO] (runner) - Reading HAP/MAP manifest...\n",
      "Successfully copied 2.56kB to /tmp/tmp_2ev25k8/app.json\n",
      "Successfully copied 2.05kB to /tmp/tmp_2ev25k8/pkg.json\n",
      "5b38943859627f8ea28e84f8ee38e2d514b0af3aacf2c637bbe2cea881658388\n",
      "[2025-10-29 15:13:48,005] [INFO] (runner) - --> Verifying if \"nvidia-ctk\" is installed...\n",
      "\n",
      "[2025-10-29 15:13:48,006] [INFO] (runner) - --> Verifying \"nvidia-ctk\" version...\n",
      "\n",
      "[2025-10-29 15:13:48,619] [INFO] (common) - Launching container (de43f313e6ea) using image 'my_app-x64-workstation-dgpu-linux-amd64:1.0'...\n",
      "    container name:      cranky_cannon\n",
      "    host name:           mingq-dt\n",
      "    network:             host\n",
      "    user:                1000:1000\n",
      "    ulimits:             memlock=-1:-1, stack=67108864:67108864\n",
      "    cap_add:             CAP_SYS_PTRACE\n",
      "    ipc mode:            host\n",
      "    shared memory size:  67108864\n",
      "    devices:             \n",
      "    group_add:           44\n",
      "2025-10-29 22:13:49 [INFO] Launching application python3 /opt/holoscan/app ...\n",
      "\n",
      "/home/holoscan/.local/lib/python3.12/site-packages/monai/deploy/utils/importutil.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "\n",
      "  import pkg_resources\n",
      "\n",
      "[info] [fragment.cpp:969] Loading extensions from configs...\n",
      "\n",
      "[info] [gxf_executor.cpp:344] Creating context\n",
      "\n",
      "[2025-10-29 22:13:54,866] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, triton_server_netloc=None, argv=['/opt/holoscan/app'])\n",
      "\n",
      "[2025-10-29 22:13:54,868] [INFO] (root) - AppContext object: AppContext(input_path=/var/holoscan/input, output_path=/var/holoscan/output, model_path=/opt/holoscan/models, workdir=/var/holoscan), triton_server_netloc=\n",
      "\n",
      "[2025-10-29 22:13:54,868] [INFO] (app.AISpleenSegApp) - App input and output path: /var/holoscan/input, /var/holoscan/output\n",
      "\n",
      "[info] [gxf_executor.cpp:2508] Activating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:2579] Running Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:2581] Waiting for completion...\n",
      "\n",
      "[info] [greedy_scheduler.cpp:191] Scheduling 5 entities\n",
      "\n",
      "[2025-10-29 22:13:55,045] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "\n",
      "[2025-10-29 22:13:55,939] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "\n",
      "[2025-10-29 22:13:55,939] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "\n",
      "  # of series: 1\n",
      "\n",
      "[2025-10-29 22:13:55,939] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "[2025-10-29 22:13:55,939] [INFO] (root) -     On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "\n",
      "[2025-10-29 22:13:55,939] [INFO] (root) -         Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -     On attribute: 'Modality' to match value: '(?i)CT'\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -         Series attribute Modality value: CT\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -     On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -         Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -     On attribute: 'ImageType' to match value: ['PRIMARY', 'ORIGINAL']\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -         Series attribute ImageType value: None\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) -         Instance level attribute ImageType value: [\"['ORIGINAL', 'PRIMARY', 'AXIAL', 'CT_SOM5 SPI']\"]\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) - Series Selection finalized\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) - Series Description of selected DICOM Series for inference: ABD/PANC 3.0 B31f\n",
      "\n",
      "[2025-10-29 22:13:55,940] [INFO] (root) - Series Instance UID of selected DICOM Series for inference: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "/home/holoscan/.local/lib/python3.12/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.spatial.dictionary Orientationd.__init__:labels: Current default value of argument `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` was changed in version None from `labels=(('L', 'R'), ('P', 'A'), ('I', 'S'))` to `labels=None`. Default value changed to None meaning that the transform now uses the 'space' of a meta-tensor, if applicable, to determine appropriate axis labels.\n",
      "\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Converted Image object metadata:\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDate: 20090831, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesTime: 101721.452, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Modality: CT, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDescription: ABD/PANC 3.0 B31f, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - PatientPosition: HFS, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesNumber: 8, type <class 'int'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_pixel_spacing: 1.5, type <class 'float'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_direction_cosine: [1.0, 0.0, 0.0], type <class 'list'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_direction_cosine: [0.0, 1.0, 0.0], type <class 'list'>\n",
      "\n",
      "[2025-10-29 22:13:56,475] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_direction_cosine: [0.0, 0.0, 1.0], type <class 'list'>\n",
      "\n",
      "[2025-10-29 22:13:56,476] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - dicom_affine_transform: [[   0.7890625    0.           0.        -197.60547  ]\n",
      "\n",
      " [   0.           0.7890625    0.        -398.60547  ]\n",
      "\n",
      " [   0.           0.           1.5       -383.       ]\n",
      "\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - nifti_affine_transform: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      "\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      "\n",
      " [   0.           0.           1.5       -383.       ]\n",
      "\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyID: , type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDate: 20090831, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyTime: 095948.599, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDescription: CT ABDOMEN W IV CONTRAST, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,477] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - AccessionNumber: 5471978513296937, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,478] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - selection_name: CT Series, type <class 'str'>\n",
      "\n",
      "[2025-10-29 22:13:56,478] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - affine: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      "\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      "\n",
      " [   0.           0.           1.5       -383.       ]\n",
      "\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "\n",
      "[2025-10-29 22:13:56,479] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - space: RAS, type <class 'str'>\n",
      "\n",
      "2025-10-29 22:13:57,236 INFO image_writer.py:197 - writing: /var/holoscan/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "\n",
      "[2025-10-29 22:13:59,033] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Input of <class 'monai.data.meta_tensor.MetaTensor'> shape: torch.Size([1, 1, 270, 270, 106])\n",
      "\n",
      "/home/holoscan/.local/lib/python3.12/site-packages/monai/inferers/utils.py:226: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "\n",
      "  win_data = torch.cat([inputs[win_slice] for win_slice in unravel_slice]).to(sw_device)\n",
      "\n",
      "/home/holoscan/.local/lib/python3.12/site-packages/monai/inferers/utils.py:370: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /pytorch/torch/csrc/autograd/python_variable_indexing.cpp:306.)\n",
      "\n",
      "  out[idx_zm] += p\n",
      "\n",
      "2025-10-29 22:14:01,633 INFO image_writer.py:197 - writing: /var/holoscan/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n",
      "\n",
      "[2025-10-29 22:14:03,402] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform length/batch size of output: 1\n",
      "\n",
      "[2025-10-29 22:14:03,405] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform pixel spacings for pred: tensor([0.7891, 0.7891, 1.5000], dtype=torch.float64)\n",
      "\n",
      "[2025-10-29 22:14:03,542] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Post transform pred of <class 'numpy.ndarray'> shape: (1, 512, 512, 204)\n",
      "\n",
      "[2025-10-29 22:14:03,589] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image numpy array of type <class 'numpy.ndarray'> shape: (204, 512, 512)\n",
      "\n",
      "[2025-10-29 22:14:03,593] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image pixel max value: 1\n",
      "\n",
      "/home/holoscan/.local/lib/python3.12/site-packages/highdicom/base.py:165: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "\n",
      "  check_person_name(patient_name)\n",
      "\n",
      "[2025-10-29 22:14:04,878] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2025-10-29 22:14:04,878] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "\n",
      "[2025-10-29 22:14:04,878] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2025-10-29 22:14:04,878] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "\n",
      "[2025-10-29 22:14:04,879] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "\n",
      "[2025-10-29 22:14:04,879] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2025-10-29 22:14:04,879] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "\n",
      "[2025-10-29 22:14:04,879] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "\n",
      "[2025-10-29 22:14:04,879] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "\n",
      "[info] [greedy_scheduler.cpp:372] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "\n",
      "[info] [greedy_scheduler.cpp:401] Scheduler finished.\n",
      "\n",
      "[info] [gxf_executor.cpp:2588] Deactivating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:2597] Graph execution finished.\n",
      "\n",
      "[2025-10-29 22:14:05,033] [INFO] (app.AISpleenSegApp) - End run\n",
      "\n",
      "[info] [gxf_executor.cpp:379] Destroying context\n",
      "\n",
      "2025-10-29 22:14:07 [INFO] Application exited with 0.\n",
      "\n",
      "[2025-10-29 15:14:07,690] [INFO] (common) - Container 'cranky_cannon'(de43f313e6ea) exited with code 0.\n"
     ]
    }
   ],
   "source": [
    "# Clear the output folder and run the MAP. The input is expected to be a folder.\n",
    "!echo $HOLOSCAN_OUTPUT_PATH\n",
    "!echo $HOLOSCAN_INPUT_PATH\n",
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!monai-deploy run -i $HOLOSCAN_INPUT_PATH -o $HOLOSCAN_OUTPUT_PATH my_app-x64-workstation-dgpu-linux-amd64:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "1.2.826.0.1.3680043.10.511.3.67053691626207204392691363320846328.dcm\n",
      "saved_images_folder\n",
      "\n",
      "output/saved_images_folder:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626\n",
      "\n",
      "output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n"
     ]
    }
   ],
   "source": [
    "!ls -R $HOLOSCAN_OUTPUT_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
