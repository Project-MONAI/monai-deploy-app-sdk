{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Segmentation App with MONAI Deploy App SDK\n",
    "\n",
    "This tutorial shows how to create an organ segmentation application for a PyTorch model that has been trained with MONAI. Please note that this one does not require the model be a MONAI Bundle.\n",
    "\n",
    "Deploying AI models requires the integration with clinical imaging network, even if just in a for-research-use setting. This means that the AI deploy application will need to support standards-based imaging protocols, and specifically for Radiological imaging, DICOM protocol.\n",
    "\n",
    "Typically, DICOM network communication, either in DICOM TCP/IP network protocol or DICOMWeb, would be handled by DICOM devices or services, e.g. MONAI Deploy Informatics Gateway, so the deploy application itself would only need to use DICOM Part 10 files as input and save the AI result in DICOM Part10 file(s). For segmentation use cases, the DICOM instance file for AI results could be a DICOM Segmentation object or a DICOM RT Structure Set, and for classification, DICOM Structure Report and/or DICOM Encapsulated PDF.\n",
    "\n",
    "During model training, input and label images are typically in non-DICOM volumetric image format, e.g., NIfTI and PNG, converted from a specific DICOM study series. Furthermore, the voxel spacings most likely have been re-sampled to be uniform for all images. When integrated with imaging networks and receiving DICOM instances from modalities and Picture Archiving and Communications System, PACS, an AI deploy application has to deal with a whole DICOM study with multiple series, whose images' spacing may not be the same as expected by the trained model. To address these cases consistently and efficiently, MONAI Deploy Application SDK provides classes, called operators, to parse DICOM studies, select specific series with application-defined rules, and convert the selected DICOM series into domain-specific image format along with meta-data representing the pertinent DICOM attributes. The image is then further processed in the pre-processing stage to normalize spacing, orientation, intensity, etc., before pixel data as Tensors are used for inference.\n",
    "\n",
    "In the following sections, we will demonstrate how to create a MONAI Deploy application package using the MONAI Deploy App SDK.\n",
    "\n",
    ":::{note}\n",
    "For local testing, if there is a lack of DICOM Part 10 files, one can use open source programs, e.g. 3D Slicer, to convert NIfTI to DICOM files.\n",
    "\n",
    ":::\n",
    "\n",
    "## Creating Operators and connecting them in Application class\n",
    "\n",
    "We will implement an application that consists of five Operators:\n",
    "\n",
    "- **DICOMDataLoaderOperator**:\n",
    "    - **Input(dicom_files)**: a folder path (`Path`)\n",
    "    - **Output(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "- **DICOMSeriesSelectorOperator**:\n",
    "    - **Input(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "    - **Input(selection_rules)**: a selection rule (Dict)\n",
    "    - **Output(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "- **DICOMSeriesToVolumeOperator**:\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **SpleenSegOperator**:\n",
    "    - **Input(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output(seg_image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **DICOMSegmentationWriterOperator**:\n",
    "    - **Input(seg_image)**: a segmentation image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(dicom_seg_instance)**: a file path (`Path`)\n",
    "\n",
    "\n",
    ":::{note}\n",
    "The `DICOMSegmentationWriterOperator` needs both the segmentation image as well as the original DICOM series meta-data in order to use the patient demographics and the DICOM Study level attributes.\n",
    ":::\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "```{mermaid}\n",
    "%%{init: {\"theme\": \"base\", \"themeVariables\": { \"fontSize\": \"16px\"}} }%%\n",
    "\n",
    "classDiagram\n",
    "    direction TB\n",
    "\n",
    "    DICOMDataLoaderOperator --|> DICOMSeriesSelectorOperator : dicom_study_list...dicom_study_list\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSeriesToVolumeOperator : study_selected_series_list...study_selected_series_list\n",
    "    DICOMSeriesToVolumeOperator --|> SpleenSegOperator : image...image\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSegmentationWriterOperator : study_selected_series_list...study_selected_series_list\n",
    "    SpleenSegOperator --|> DICOMSegmentationWriterOperator : seg_image...seg_image\n",
    "\n",
    "\n",
    "    class DICOMDataLoaderOperator {\n",
    "        <in>dicom_files : DISK\n",
    "        dicom_study_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesSelectorOperator {\n",
    "        <in>dicom_study_list : IN_MEMORY\n",
    "        <in>selection_rules : IN_MEMORY\n",
    "        study_selected_series_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesToVolumeOperator {\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        image(out) IN_MEMORY\n",
    "    }\n",
    "    class SpleenSegOperator {\n",
    "        <in>image : IN_MEMORY\n",
    "        seg_image(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSegmentationWriterOperator {\n",
    "        <in>seg_image : IN_MEMORY\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        dicom_seg_instance(out) DISK\n",
    "    }\n",
    "```\n",
    "\n",
    "### Setup environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MONAI and other necessary image processing packages for the application\n",
    "!python -c \"import monai\" || pip install --upgrade -q \"monai\"\n",
    "!python -c \"import torch\" || pip install -q \"torch>=1.10.2\"\n",
    "!python -c \"import numpy\" || pip install -q \"numpy>=1.21\"\n",
    "!python -c \"import nibabel\" || pip install -q \"nibabel>=3.2.1\"\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=1.4.2\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\"\n",
    "!python -c \"import SimpleITK\" || pip install -q \"SimpleITK>=2.0.0\"\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!python -c \"import monai.deploy\" || pip install --upgrade \"monai-deploy-app-sdk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you may need to restart the Jupyter kernel to use the updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download/Extract ai_spleen_bundle_data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (3.13.4)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (4.66.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\n",
      "From (redirected): https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ&confirm=t&uuid=cec9025c-9d57-4269-b01f-503cd7daf812\n",
      "To: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/ai_spleen_seg_bundle_data.zip\n",
      "100%|███████████████████████████████████████| 79.4M/79.4M [00:00<00:00, 105MB/s]\n",
      "Archive:  ai_spleen_seg_bundle_data.zip\n",
      "  inflating: dcm/1-001.dcm           \n",
      "  inflating: dcm/1-002.dcm           \n",
      "  inflating: dcm/1-003.dcm           \n",
      "  inflating: dcm/1-004.dcm           \n",
      "  inflating: dcm/1-005.dcm           \n",
      "  inflating: dcm/1-006.dcm           \n",
      "  inflating: dcm/1-007.dcm           \n",
      "  inflating: dcm/1-008.dcm           \n",
      "  inflating: dcm/1-009.dcm           \n",
      "  inflating: dcm/1-010.dcm           \n",
      "  inflating: dcm/1-011.dcm           \n",
      "  inflating: dcm/1-012.dcm           \n",
      "  inflating: dcm/1-013.dcm           \n",
      "  inflating: dcm/1-014.dcm           \n",
      "  inflating: dcm/1-015.dcm           \n",
      "  inflating: dcm/1-016.dcm           \n",
      "  inflating: dcm/1-017.dcm           \n",
      "  inflating: dcm/1-018.dcm           \n",
      "  inflating: dcm/1-019.dcm           \n",
      "  inflating: dcm/1-020.dcm           \n",
      "  inflating: dcm/1-021.dcm           \n",
      "  inflating: dcm/1-022.dcm           \n",
      "  inflating: dcm/1-023.dcm           \n",
      "  inflating: dcm/1-024.dcm           \n",
      "  inflating: dcm/1-025.dcm           \n",
      "  inflating: dcm/1-026.dcm           \n",
      "  inflating: dcm/1-027.dcm           \n",
      "  inflating: dcm/1-028.dcm           \n",
      "  inflating: dcm/1-029.dcm           \n",
      "  inflating: dcm/1-030.dcm           \n",
      "  inflating: dcm/1-031.dcm           \n",
      "  inflating: dcm/1-032.dcm           \n",
      "  inflating: dcm/1-033.dcm           \n",
      "  inflating: dcm/1-034.dcm           \n",
      "  inflating: dcm/1-035.dcm           \n",
      "  inflating: dcm/1-036.dcm           \n",
      "  inflating: dcm/1-037.dcm           \n",
      "  inflating: dcm/1-038.dcm           \n",
      "  inflating: dcm/1-039.dcm           \n",
      "  inflating: dcm/1-040.dcm           \n",
      "  inflating: dcm/1-041.dcm           \n",
      "  inflating: dcm/1-042.dcm           \n",
      "  inflating: dcm/1-043.dcm           \n",
      "  inflating: dcm/1-044.dcm           \n",
      "  inflating: dcm/1-045.dcm           \n",
      "  inflating: dcm/1-046.dcm           \n",
      "  inflating: dcm/1-047.dcm           \n",
      "  inflating: dcm/1-048.dcm           \n",
      "  inflating: dcm/1-049.dcm           \n",
      "  inflating: dcm/1-050.dcm           \n",
      "  inflating: dcm/1-051.dcm           \n",
      "  inflating: dcm/1-052.dcm           \n",
      "  inflating: dcm/1-053.dcm           \n",
      "  inflating: dcm/1-054.dcm           \n",
      "  inflating: dcm/1-055.dcm           \n",
      "  inflating: dcm/1-056.dcm           \n",
      "  inflating: dcm/1-057.dcm           \n",
      "  inflating: dcm/1-058.dcm           \n",
      "  inflating: dcm/1-059.dcm           \n",
      "  inflating: dcm/1-060.dcm           \n",
      "  inflating: dcm/1-061.dcm           \n",
      "  inflating: dcm/1-062.dcm           \n",
      "  inflating: dcm/1-063.dcm           \n",
      "  inflating: dcm/1-064.dcm           \n",
      "  inflating: dcm/1-065.dcm           \n",
      "  inflating: dcm/1-066.dcm           \n",
      "  inflating: dcm/1-067.dcm           \n",
      "  inflating: dcm/1-068.dcm           \n",
      "  inflating: dcm/1-069.dcm           \n",
      "  inflating: dcm/1-070.dcm           \n",
      "  inflating: dcm/1-071.dcm           \n",
      "  inflating: dcm/1-072.dcm           \n",
      "  inflating: dcm/1-073.dcm           \n",
      "  inflating: dcm/1-074.dcm           \n",
      "  inflating: dcm/1-075.dcm           \n",
      "  inflating: dcm/1-076.dcm           \n",
      "  inflating: dcm/1-077.dcm           \n",
      "  inflating: dcm/1-078.dcm           \n",
      "  inflating: dcm/1-079.dcm           \n",
      "  inflating: dcm/1-080.dcm           \n",
      "  inflating: dcm/1-081.dcm           \n",
      "  inflating: dcm/1-082.dcm           \n",
      "  inflating: dcm/1-083.dcm           \n",
      "  inflating: dcm/1-084.dcm           \n",
      "  inflating: dcm/1-085.dcm           \n",
      "  inflating: dcm/1-086.dcm           \n",
      "  inflating: dcm/1-087.dcm           \n",
      "  inflating: dcm/1-088.dcm           \n",
      "  inflating: dcm/1-089.dcm           \n",
      "  inflating: dcm/1-090.dcm           \n",
      "  inflating: dcm/1-091.dcm           \n",
      "  inflating: dcm/1-092.dcm           \n",
      "  inflating: dcm/1-093.dcm           \n",
      "  inflating: dcm/1-094.dcm           \n",
      "  inflating: dcm/1-095.dcm           \n",
      "  inflating: dcm/1-096.dcm           \n",
      "  inflating: dcm/1-097.dcm           \n",
      "  inflating: dcm/1-098.dcm           \n",
      "  inflating: dcm/1-099.dcm           \n",
      "  inflating: dcm/1-100.dcm           \n",
      "  inflating: dcm/1-101.dcm           \n",
      "  inflating: dcm/1-102.dcm           \n",
      "  inflating: dcm/1-103.dcm           \n",
      "  inflating: dcm/1-104.dcm           \n",
      "  inflating: dcm/1-105.dcm           \n",
      "  inflating: dcm/1-106.dcm           \n",
      "  inflating: dcm/1-107.dcm           \n",
      "  inflating: dcm/1-108.dcm           \n",
      "  inflating: dcm/1-109.dcm           \n",
      "  inflating: dcm/1-110.dcm           \n",
      "  inflating: dcm/1-111.dcm           \n",
      "  inflating: dcm/1-112.dcm           \n",
      "  inflating: dcm/1-113.dcm           \n",
      "  inflating: dcm/1-114.dcm           \n",
      "  inflating: dcm/1-115.dcm           \n",
      "  inflating: dcm/1-116.dcm           \n",
      "  inflating: dcm/1-117.dcm           \n",
      "  inflating: dcm/1-118.dcm           \n",
      "  inflating: dcm/1-119.dcm           \n",
      "  inflating: dcm/1-120.dcm           \n",
      "  inflating: dcm/1-121.dcm           \n",
      "  inflating: dcm/1-122.dcm           \n",
      "  inflating: dcm/1-123.dcm           \n",
      "  inflating: dcm/1-124.dcm           \n",
      "  inflating: dcm/1-125.dcm           \n",
      "  inflating: dcm/1-126.dcm           \n",
      "  inflating: dcm/1-127.dcm           \n",
      "  inflating: dcm/1-128.dcm           \n",
      "  inflating: dcm/1-129.dcm           \n",
      "  inflating: dcm/1-130.dcm           \n",
      "  inflating: dcm/1-131.dcm           \n",
      "  inflating: dcm/1-132.dcm           \n",
      "  inflating: dcm/1-133.dcm           \n",
      "  inflating: dcm/1-134.dcm           \n",
      "  inflating: dcm/1-135.dcm           \n",
      "  inflating: dcm/1-136.dcm           \n",
      "  inflating: dcm/1-137.dcm           \n",
      "  inflating: dcm/1-138.dcm           \n",
      "  inflating: dcm/1-139.dcm           \n",
      "  inflating: dcm/1-140.dcm           \n",
      "  inflating: dcm/1-141.dcm           \n",
      "  inflating: dcm/1-142.dcm           \n",
      "  inflating: dcm/1-143.dcm           \n",
      "  inflating: dcm/1-144.dcm           \n",
      "  inflating: dcm/1-145.dcm           \n",
      "  inflating: dcm/1-146.dcm           \n",
      "  inflating: dcm/1-147.dcm           \n",
      "  inflating: dcm/1-148.dcm           \n",
      "  inflating: dcm/1-149.dcm           \n",
      "  inflating: dcm/1-150.dcm           \n",
      "  inflating: dcm/1-151.dcm           \n",
      "  inflating: dcm/1-152.dcm           \n",
      "  inflating: dcm/1-153.dcm           \n",
      "  inflating: dcm/1-154.dcm           \n",
      "  inflating: dcm/1-155.dcm           \n",
      "  inflating: dcm/1-156.dcm           \n",
      "  inflating: dcm/1-157.dcm           \n",
      "  inflating: dcm/1-158.dcm           \n",
      "  inflating: dcm/1-159.dcm           \n",
      "  inflating: dcm/1-160.dcm           \n",
      "  inflating: dcm/1-161.dcm           \n",
      "  inflating: dcm/1-162.dcm           \n",
      "  inflating: dcm/1-163.dcm           \n",
      "  inflating: dcm/1-164.dcm           \n",
      "  inflating: dcm/1-165.dcm           \n",
      "  inflating: dcm/1-166.dcm           \n",
      "  inflating: dcm/1-167.dcm           \n",
      "  inflating: dcm/1-168.dcm           \n",
      "  inflating: dcm/1-169.dcm           \n",
      "  inflating: dcm/1-170.dcm           \n",
      "  inflating: dcm/1-171.dcm           \n",
      "  inflating: dcm/1-172.dcm           \n",
      "  inflating: dcm/1-173.dcm           \n",
      "  inflating: dcm/1-174.dcm           \n",
      "  inflating: dcm/1-175.dcm           \n",
      "  inflating: dcm/1-176.dcm           \n",
      "  inflating: dcm/1-177.dcm           \n",
      "  inflating: dcm/1-178.dcm           \n",
      "  inflating: dcm/1-179.dcm           \n",
      "  inflating: dcm/1-180.dcm           \n",
      "  inflating: dcm/1-181.dcm           \n",
      "  inflating: dcm/1-182.dcm           \n",
      "  inflating: dcm/1-183.dcm           \n",
      "  inflating: dcm/1-184.dcm           \n",
      "  inflating: dcm/1-185.dcm           \n",
      "  inflating: dcm/1-186.dcm           \n",
      "  inflating: dcm/1-187.dcm           \n",
      "  inflating: dcm/1-188.dcm           \n",
      "  inflating: dcm/1-189.dcm           \n",
      "  inflating: dcm/1-190.dcm           \n",
      "  inflating: dcm/1-191.dcm           \n",
      "  inflating: dcm/1-192.dcm           \n",
      "  inflating: dcm/1-193.dcm           \n",
      "  inflating: dcm/1-194.dcm           \n",
      "  inflating: dcm/1-195.dcm           \n",
      "  inflating: dcm/1-196.dcm           \n",
      "  inflating: dcm/1-197.dcm           \n",
      "  inflating: dcm/1-198.dcm           \n",
      "  inflating: dcm/1-199.dcm           \n",
      "  inflating: dcm/1-200.dcm           \n",
      "  inflating: dcm/1-201.dcm           \n",
      "  inflating: dcm/1-202.dcm           \n",
      "  inflating: dcm/1-203.dcm           \n",
      "  inflating: dcm/1-204.dcm           \n",
      "  inflating: model.ts                \n",
      "model.ts\n"
     ]
    }
   ],
   "source": [
    "# Download ai_spleen_bundle_data test data zip file\n",
    "!pip install gdown \n",
    "!gdown \"https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\"\n",
    "\n",
    "# After downloading ai_spleen_bundle_data zip file from the web browser or using gdown,\n",
    "!unzip -o \"ai_spleen_seg_bundle_data.zip\"\n",
    "\n",
    "# Need to copy the model.ts file to its own clean subfolder for packaging, to work around an issue in the Packager\n",
    "models_folder = \"models\"\n",
    "!rm -rf {models_folder} && mkdir -p {models_folder}/model && cp model.ts {models_folder}/model && ls {models_folder}/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=dcm\n",
      "env: HOLOSCAN_MODEL_PATH=models\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH dcm\n",
    "%env HOLOSCAN_MODEL_PATH {models_folder}\n",
    "%env HOLOSCAN_OUTPUT_PATH output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators to define Application and Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from numpy import uint8  # Needed if SaveImaged is enabled\n",
    "from pathlib import Path\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Operator, OperatorSpec\n",
    "from monai.deploy.core.domain import Image\n",
    "from monai.deploy.core.io_type import IOType\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.monai_seg_inference_operator import InfererType, InMemImageReader, MonaiSegInferenceOperator\n",
    "\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model Specific Inference Operator classes\n",
    "\n",
    "Each Operator class inherits the base `Operator` class. The input/output properties are specified by implementing the `setup()` method, and the business logic implemented in the `compute()` method.\n",
    "\n",
    "The App SDK provides a `MonaiSegInferenceOperator` class to perform segmentation prediction with a Torch Script model. For consistency, this class uses MONAI dictionary-based transforms, as `Compose` object, for pre and post transforms. The model-specific inference operator will then only need to create the pre and post transform `Compose` based on what has been used in the model during training and validation. Note that for deploy application, `ignite` is not needed nor supported.\n",
    "\n",
    "#### SpleenSegOperator\n",
    "\n",
    "The `SpleenSegOperator` gets as input an in-memory [Image](/modules/_autosummary/monai.deploy.core.domain.Image) object that has been converted from a DICOM CT series by the preceding `DICOMSeriesToVolumeOperator`, and as output in-memory segmentation [Image](/modules/_autosummary/monai.deploy.core.domain.Image) object.\n",
    "\n",
    "The `pre_process` function creates the pre-transforms `Compose` object. For `LoadImage`, a specialized `InMemImageReader`, derived from MONAI `ImageReader`, is used to convert the in-memory pixel data and return the `numpy` array as well as the meta-data. Also, the DICOM input pixel spacings are often not the same as expected by the model, so the `Spacingd` transform must be used to re-sample the image with the expected spacing.\n",
    "\n",
    "The `post_process` function creates the post-transform `Compose` object. The `SaveImageD` transform class is used to save the segmentation mask as NIfTI image file, which is optional as the in-memory mask image will be passed down to the DICOM Segmentation writer for creating a DICOM Segmentation instance. The `Invertd` must also be used to revert the segmentation image's orientation and spacing to be the same as the input.\n",
    "\n",
    "When the `MonaiSegInferenceOperator` object is created, the `ROI` size is specified, as well as the transform `Compose` objects. Furthermore, the dataset image key names are set accordingly.\n",
    "\n",
    "Loading of the model and performing the prediction are encapsulated in the `MonaiSegInferenceOperator` and other SDK classes. Once the inference is completed, the segmentation [Image](/modules/_autosummary/monai.deploy.core.domain.Image) object is created and set to the output by the `SpleenSegOperator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpleenSegOperator(Operator):\n",
    "    \"\"\"Performs Spleen segmentation with a 3D image converted from a DICOM CT series.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"output/saved_images_folder\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_path: Path,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.output_folder = output_folder\n",
    "        self.output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        self.app_context = app_context\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_seg = \"seg_image\"\n",
    "        self.output_name_saved_images_folder = \"saved_images_folder\"\n",
    "\n",
    "        # The base class has an attribute called fragment to hold the reference to the fragment object\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.output(self.output_name_seg)\n",
    "        spec.output(self.output_name_saved_images_folder).condition(\n",
    "            ConditionType.NONE\n",
    "        )  # Output not requiring a receiver\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        input_image = op_input.receive(self.input_name_image)\n",
    "        if not input_image:\n",
    "            raise ValueError(\"Input image is not found.\")\n",
    "\n",
    "        # This operator gets an in-memory Image object, so a specialized ImageReader is needed.\n",
    "        _reader = InMemImageReader(input_image)\n",
    "\n",
    "        pre_transforms = self.pre_process(_reader, str(self.output_folder))\n",
    "        post_transforms = self.post_process(pre_transforms, str(self.output_folder))\n",
    "\n",
    "        # Delegates inference and saving output to the built-in operator.\n",
    "        infer_operator = MonaiSegInferenceOperator(\n",
    "            self.fragment,\n",
    "            roi_size=(\n",
    "                96,\n",
    "                96,\n",
    "                96,\n",
    "            ),\n",
    "            pre_transforms=pre_transforms,\n",
    "            post_transforms=post_transforms,\n",
    "            overlap=0.6,\n",
    "            app_context=self.app_context,\n",
    "            model_name=\"\",\n",
    "            inferer=InfererType.SLIDING_WINDOW,\n",
    "            sw_batch_size=4,\n",
    "            model_path=self.model_path,\n",
    "            name=\"monai_seg_inference_op\",\n",
    "        )\n",
    "\n",
    "        # Setting the keys used in the dictionary based transforms may change.\n",
    "        infer_operator.input_dataset_key = self._input_dataset_key\n",
    "        infer_operator.pred_dataset_key = self._pred_dataset_key\n",
    "\n",
    "        # Now emit data to the output ports of this operator\n",
    "        op_output.emit(infer_operator.compute_impl(input_image, context), self.output_name_seg)\n",
    "        op_output.emit(self.output_folder, self.output_name_saved_images_folder)\n",
    "\n",
    "    def pre_process(self, img_reader, out_dir: str = \"./input_images\") -> Compose:\n",
    "        \"\"\"Composes transforms for preprocessing input before predicting on a model.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        my_key = self._input_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                LoadImaged(keys=my_key, reader=img_reader),\n",
    "                EnsureChannelFirstd(keys=my_key),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=my_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"\",\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "                Orientationd(keys=my_key, axcodes=\"RAS\"),\n",
    "                Spacingd(keys=my_key, pixdim=[1.5, 1.5, 2.9], mode=[\"bilinear\"]),\n",
    "                ScaleIntensityRanged(keys=my_key, a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                EnsureTyped(keys=my_key),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process(self, pre_transforms: Compose, out_dir: str = \"./prediction_output\") -> Compose:\n",
    "        \"\"\"Composes transforms for postprocessing the prediction results.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        pred_key = self._pred_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                Activationsd(keys=pred_key, softmax=True),\n",
    "                Invertd(\n",
    "                    keys=pred_key,\n",
    "                    transform=pre_transforms,\n",
    "                    orig_keys=self._input_dataset_key,\n",
    "                    nearest_interp=False,\n",
    "                    to_tensor=True,\n",
    "                ),\n",
    "                AsDiscreted(keys=pred_key, argmax=True),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=pred_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"seg\",\n",
    "                    output_dtype=uint8,\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class, inheriting the base `Application` class.\n",
    "\n",
    "The base class method, `compose`, is overridden. Objects required for DICOM parsing, series selection, pixel data conversion to volume image, and segmentation instance creation are created, so is the model-specific `SpleenSegOperator`. The execution pipeline, as a Directed Acyclic Graph (DAG), is created by connecting these objects through the `add_flow` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AISpleenSegApp(Application):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        self._logger.debug(f\"Begin {self.compose.__name__}\")\n",
    "        app_context = Application.init_app_context({})  # Do not pass argv in Jupyter Notebook\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        self._logger.info(f\"App input and output path: {app_input_path}, {app_output_path}\")\n",
    "\n",
    "        # instantiates the SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"dcm_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Model specific inference operator, supporting MONAI transforms.\n",
    "        spleen_seg_op = SpleenSegOperator(self, app_context=app_context, model_path=model_path, name=\"seg_op\")\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue.\n",
    "        # The segment_label, algorithm_name, and algorithm_version are limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        # User can Look up SNOMED CT codes at, e.g.\n",
    "        # https://bioportal.bioontology.org/ontologies/SNOMEDCT\n",
    "\n",
    "        _algorithm_name = \"3D segmentation of the Spleen from a CT series\"\n",
    "        _algorithm_family = codes.DCM.ArtificialIntelligence\n",
    "        _algorithm_version = \"0.1.0\"\n",
    "\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=_algorithm_name,\n",
    "                algorithm_family=_algorithm_family,\n",
    "                algorithm_version=_algorithm_version,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dcm_seg_writer_op\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, spleen_seg_op, {(\"image\", \"image\")})\n",
    "\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(spleen_seg_op, dicom_seg_writer, {(\"seg_image\", \"seg_image\")})\n",
    "\n",
    "        self._logger.debug(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "# For list of string values, e.g. \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"], it is a match if all elements\n",
    "# are all in the multi-value attribute of the DICOM series.\n",
    "\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\",\n",
    "                \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing app locally\n",
    "\n",
    "We can execute the app in Jupyter notebook. Note that the DICOM files of the CT Abdomen series must be present in the `dcm` folder and the TorchScript, `model.ts`, in the folder pointed to by the environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-23 15:42:43,990] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=[])\n",
      "[2024-04-23 15:42:43,998] [INFO] (root) - AppContext object: AppContext(input_path=dcm, output_path=output, model_path=models, workdir=)\n",
      "[2024-04-23 15:42:44,000] [INFO] (__main__.AISpleenSegApp) - App input and output path: dcm, output\n",
      "[info] [gxf_executor.cpp:247] Creating context\n",
      "[info] [gxf_executor.cpp:1672] Loading extensions from configs...\n",
      "[info] [gxf_executor.cpp:1842] Activating Graph...\n",
      "[info] [gxf_executor.cpp:1874] Running Graph...\n",
      "[info] [gxf_executor.cpp:1876] Waiting for completion...\n",
      "[2024-04-23 15:42:44,046] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m2024-04-23 15:42:44.043 INFO  gxf/std/greedy_scheduler.cpp@191: Scheduling 6 entities\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-23 15:42:44,615] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "[2024-04-23 15:42:44,616] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "[2024-04-23 15:42:44,617] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-23 15:42:44,618] [INFO] (root) - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "[2024-04-23 15:42:44,618] [INFO] (root) -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "[2024-04-23 15:42:44,618] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-23 15:42:44,619] [INFO] (root) - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "[2024-04-23 15:42:44,619] [INFO] (root) -     Series attribute Modality value: CT\n",
      "[2024-04-23 15:42:44,620] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-23 15:42:44,620] [INFO] (root) - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "[2024-04-23 15:42:44,621] [INFO] (root) -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "[2024-04-23 15:42:44,621] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-23 15:42:44,622] [INFO] (root) - On attribute: 'ImageType' to match value: ['PRIMARY', 'ORIGINAL']\n",
      "[2024-04-23 15:42:44,622] [INFO] (root) -     Series attribute ImageType value: None\n",
      "[2024-04-23 15:42:44,623] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-23 15:42:44,860] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Converted Image object metadata:\n",
      "[2024-04-23 15:42:44,862] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239, type <class 'str'>\n",
      "[2024-04-23 15:42:44,862] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDate: 20090831, type <class 'str'>\n",
      "[2024-04-23 15:42:44,863] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesTime: 101721.452, type <class 'str'>\n",
      "[2024-04-23 15:42:44,864] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Modality: CT, type <class 'str'>\n",
      "[2024-04-23 15:42:44,864] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDescription: ABD/PANC 3.0 B31f, type <class 'str'>\n",
      "[2024-04-23 15:42:44,865] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - PatientPosition: HFS, type <class 'str'>\n",
      "[2024-04-23 15:42:44,866] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesNumber: 8, type <class 'int'>\n",
      "[2024-04-23 15:42:44,866] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2024-04-23 15:42:44,867] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2024-04-23 15:42:44,867] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_pixel_spacing: 1.5, type <class 'float'>\n",
      "[2024-04-23 15:42:44,868] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_direction_cosine: [1.0, 0.0, 0.0], type <class 'list'>\n",
      "[2024-04-23 15:42:44,869] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_direction_cosine: [0.0, 1.0, 0.0], type <class 'list'>\n",
      "[2024-04-23 15:42:44,869] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_direction_cosine: [0.0, 0.0, 1.0], type <class 'list'>\n",
      "[2024-04-23 15:42:44,870] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - dicom_affine_transform: [[   0.7890625    0.           0.        -197.60547  ]\n",
      " [   0.           0.7890625    0.        -398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2024-04-23 15:42:44,871] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - nifti_affine_transform: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2024-04-23 15:42:44,872] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291, type <class 'str'>\n",
      "[2024-04-23 15:42:44,873] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyID: , type <class 'str'>\n",
      "[2024-04-23 15:42:44,875] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDate: 20090831, type <class 'str'>\n",
      "[2024-04-23 15:42:44,876] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyTime: 095948.599, type <class 'str'>\n",
      "[2024-04-23 15:42:44,877] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDescription: CT ABDOMEN W IV CONTRAST, type <class 'str'>\n",
      "[2024-04-23 15:42:44,878] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - AccessionNumber: 5471978513296937, type <class 'str'>\n",
      "[2024-04-23 15:42:44,879] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - selection_name: CT Series, type <class 'str'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-23 15:42:45,610 INFO image_writer.py:197 - writing: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "2024-04-23 15:42:51,791 INFO image_writer.py:197 - writing: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-23 15:42:53,711] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image numpy array shaped: (204, 512, 512)\n",
      "[2024-04-23 15:42:53,718] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image pixel max value: 1\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  warnings.warn(\n",
      "[2024-04-23 15:42:55,113] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-23 15:42:55,114] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "[2024-04-23 15:42:55,115] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-23 15:42:55,116] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "[2024-04-23 15:42:55,118] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "[2024-04-23 15:42:55,119] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-23 15:42:55,120] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "[2024-04-23 15:42:55,121] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "[2024-04-23 15:42:55,122] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "[info] [gxf_executor.cpp:1879] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:1887] Graph execution finished.\n",
      "[2024-04-23 15:42:55,233] [INFO] (__main__.AISpleenSegApp) - End run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m2024-04-23 15:42:55.231 INFO  gxf/std/greedy_scheduler.cpp@372: Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\u001b[0m\n",
      "\u001b[0m2024-04-23 15:42:55.231 INFO  gxf/std/greedy_scheduler.cpp@401: Scheduler finished.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "app = AISpleenSegApp()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the above Python code into Python files in an application folder.\n",
    "\n",
    "The application folder structure would look like below:\n",
    "\n",
    "```bash\n",
    "my_app\n",
    "├── __main__.py\n",
    "├── app.py\n",
    "└── spleen_seg_operator.py\n",
    "```\n",
    "\n",
    ":::{note}\n",
    "We can create a single application Python file (such as `spleen_app.py`) that includes the content of the files, instead of creating multiple files.\n",
    "You will see such an example in <a href=\"./02_mednist_app.html#executing-app-locally\">MedNist Classifier Tutorial</a>.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p my_app && rm -rf my_app/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### spleen_seg_operator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/spleen_seg_operator.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/spleen_seg_operator.py\n",
    "import logging\n",
    "\n",
    "from numpy import uint8\n",
    "from pathlib import Path\n",
    "\n",
    "from monai.deploy.core import AppContext, ConditionType, Fragment, Operator, OperatorSpec\n",
    "from monai.deploy.operators.monai_seg_inference_operator import InfererType, InMemImageReader, MonaiSegInferenceOperator\n",
    "from monai.transforms import (\n",
    "    Activationsd,\n",
    "    AsDiscreted,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    EnsureTyped,\n",
    "    Invertd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    ")\n",
    "\n",
    "class SpleenSegOperator(Operator):\n",
    "    \"\"\"Performs Spleen segmentation with a 3D image converted from a DICOM CT series.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"output/saved_images_folder\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_path: Path,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "\n",
    "        self.logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.output_folder = output_folder\n",
    "        self.output_folder.mkdir(parents=True, exist_ok=True)\n",
    "        self.app_context = app_context\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_seg = \"seg_image\"\n",
    "        self.output_name_saved_images_folder = \"saved_images_folder\"\n",
    "\n",
    "        # The base class has an attribute called fragment to hold the reference to the fragment object\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.output(self.output_name_seg)\n",
    "        spec.output(self.output_name_saved_images_folder).condition(\n",
    "            ConditionType.NONE\n",
    "        )  # Output not requiring a receiver\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        input_image = op_input.receive(self.input_name_image)\n",
    "        if not input_image:\n",
    "            raise ValueError(\"Input image is not found.\")\n",
    "\n",
    "        # This operator gets an in-memory Image object, so a specialized ImageReader is needed.\n",
    "        _reader = InMemImageReader(input_image)\n",
    "\n",
    "        pre_transforms = self.pre_process(_reader, str(self.output_folder))\n",
    "        post_transforms = self.post_process(pre_transforms, str(self.output_folder))\n",
    "\n",
    "        # Delegates inference and saving output to the built-in operator.\n",
    "        infer_operator = MonaiSegInferenceOperator(\n",
    "            self.fragment,\n",
    "            roi_size=(\n",
    "                96,\n",
    "                96,\n",
    "                96,\n",
    "            ),\n",
    "            pre_transforms=pre_transforms,\n",
    "            post_transforms=post_transforms,\n",
    "            overlap=0.6,\n",
    "            app_context=self.app_context,\n",
    "            model_name=\"\",\n",
    "            inferer=InfererType.SLIDING_WINDOW,\n",
    "            sw_batch_size=4,\n",
    "            model_path=self.model_path,\n",
    "            name=\"monai_seg_inference_op\",\n",
    "        )\n",
    "\n",
    "        # Setting the keys used in the dictionary based transforms may change.\n",
    "        infer_operator.input_dataset_key = self._input_dataset_key\n",
    "        infer_operator.pred_dataset_key = self._pred_dataset_key\n",
    "\n",
    "        # Now emit data to the output ports of this operator\n",
    "        op_output.emit(infer_operator.compute_impl(input_image, context), self.output_name_seg)\n",
    "        op_output.emit(self.output_folder, self.output_name_saved_images_folder)\n",
    "\n",
    "    def pre_process(self, img_reader, out_dir: str = \"./input_images\") -> Compose:\n",
    "        \"\"\"Composes transforms for preprocessing input before predicting on a model.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        my_key = self._input_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                LoadImaged(keys=my_key, reader=img_reader),\n",
    "                EnsureChannelFirstd(keys=my_key),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=my_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"\",\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "                Orientationd(keys=my_key, axcodes=\"RAS\"),\n",
    "                Spacingd(keys=my_key, pixdim=[1.5, 1.5, 2.9], mode=[\"bilinear\"]),\n",
    "                ScaleIntensityRanged(keys=my_key, a_min=-57, a_max=164, b_min=0.0, b_max=1.0, clip=True),\n",
    "                EnsureTyped(keys=my_key),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process(self, pre_transforms: Compose, out_dir: str = \"./prediction_output\") -> Compose:\n",
    "        \"\"\"Composes transforms for postprocessing the prediction results.\"\"\"\n",
    "\n",
    "        Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "        pred_key = self._pred_dataset_key\n",
    "\n",
    "        return Compose(\n",
    "            [\n",
    "                Activationsd(keys=pred_key, softmax=True),\n",
    "                Invertd(\n",
    "                    keys=pred_key,\n",
    "                    transform=pre_transforms,\n",
    "                    orig_keys=self._input_dataset_key,\n",
    "                    nearest_interp=False,\n",
    "                    to_tensor=True,\n",
    "                ),\n",
    "                AsDiscreted(keys=pred_key, argmax=True),\n",
    "                # The SaveImaged transform can be commented out to save 5 seconds.\n",
    "                # Uncompress NIfTI file, nii, is used favoring speed over size, but can be changed to nii.gz\n",
    "                SaveImaged(\n",
    "                    keys=pred_key,\n",
    "                    output_dir=out_dir,\n",
    "                    output_postfix=\"seg\",\n",
    "                    output_dtype=uint8,\n",
    "                    resample=False,\n",
    "                    output_ext=\".nii\",\n",
    "                ),\n",
    "            ]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.py\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "from spleen_seg_operator import SpleenSegOperator\n",
    "\n",
    "from pydicom.sr.codedict import codes  # Required for setting SegmentDescription attributes.\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n",
    "\n",
    "class AISpleenSegApp(Application):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        # Use Commandline options over environment variables to init context.\n",
    "        app_context = Application.init_app_context(self.argv)\n",
    "        self._logger.debug(f\"Begin {self.compose.__name__}\")\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        self._logger.info(f\"App input and output path: {app_input_path}, {app_output_path}\")\n",
    "\n",
    "        # instantiates the SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"dcm_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Model specific inference operator, supporting MONAI transforms.\n",
    "        spleen_seg_op = SpleenSegOperator(self, app_context=app_context, model_path=model_path, name=\"seg_op\")\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue.\n",
    "        # The segment_label, algorithm_name, and algorithm_version are limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        # User can Look up SNOMED CT codes at, e.g.\n",
    "        # https://bioportal.bioontology.org/ontologies/SNOMEDCT\n",
    "\n",
    "        _algorithm_name = \"3D segmentation of the Spleen from a CT series\"\n",
    "        _algorithm_family = codes.DCM.ArtificialIntelligence\n",
    "        _algorithm_version = \"0.1.0\"\n",
    "\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=_algorithm_name,\n",
    "                algorithm_family=_algorithm_family,\n",
    "                algorithm_version=_algorithm_version,\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dcm_seg_writer_op\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, spleen_seg_op, {(\"image\", \"image\")})\n",
    "\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(spleen_seg_op, dicom_seg_writer, {(\"seg_image\", \"seg_image\")})\n",
    "\n",
    "        self._logger.debug(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "# For list of string values, e.g. \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"], it is a match if all elements\n",
    "# are all in the multi-value attribute of the DICOM series.\n",
    "\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\",\n",
    "                \"ImageType\": [\"PRIMARY\", \"ORIGINAL\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Creates the app and test it standalone.\n",
    "    AISpleenSegApp().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter.\n",
    "\n",
    "### \\_\\_main\\_\\_.py\n",
    "\n",
    "\\_\\_main\\_\\_.py is needed for <a href=\"../../developing_with_sdk/packaging_app.html#required-arguments\">MONAI Application Packager</a> to detect the main application code (`app.py`) when the application is executed with the application folder path (e.g., `python simple_imaging_app`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/__main__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/__main__.py\n",
    "from app import AISpleenSegApp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py\t__main__.py  spleen_seg_operator.py\n"
     ]
    }
   ],
   "source": [
    "!ls my_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this time, let's execute the app in the command line.\n",
    "\n",
    ":::{note}\n",
    "Since the environment variables have been set and contain the correct paths, it is not necessary to provide the command line options on running the application.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 15:42:59,956] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=['my_app'])\n",
      "[2024-04-23 15:42:59,957] [INFO] (root) - AppContext object: AppContext(input_path=dcm, output_path=output, model_path=models, workdir=)\n",
      "[2024-04-23 15:42:59,957] [INFO] (app.AISpleenSegApp) - App input and output path: dcm, output\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:247] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1672] Loading extensions from configs...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1842] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1874] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1876] Waiting for completion...\n",
      "\u001b[0m2024-04-23 15:42:59.985 INFO  gxf/std/greedy_scheduler.cpp@191: Scheduling 6 entities\u001b[0m\n",
      "[2024-04-23 15:42:59,987] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "[2024-04-23 15:43:00,516] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) -     Series attribute Modality value: CT\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - On attribute: 'ImageType' to match value: ['PRIMARY', 'ORIGINAL']\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) -     Series attribute ImageType value: None\n",
      "[2024-04-23 15:43:00,517] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Converted Image object metadata:\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239, type <class 'str'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDate: 20090831, type <class 'str'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesTime: 101721.452, type <class 'str'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Modality: CT, type <class 'str'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDescription: ABD/PANC 3.0 B31f, type <class 'str'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - PatientPosition: HFS, type <class 'str'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesNumber: 8, type <class 'int'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "[2024-04-23 15:43:00,884] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_pixel_spacing: 1.5, type <class 'float'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_direction_cosine: [1.0, 0.0, 0.0], type <class 'list'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_direction_cosine: [0.0, 1.0, 0.0], type <class 'list'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_direction_cosine: [0.0, 0.0, 1.0], type <class 'list'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - dicom_affine_transform: [[   0.7890625    0.           0.        -197.60547  ]\n",
      " [   0.           0.7890625    0.        -398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - nifti_affine_transform: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      " [   0.           0.           1.5       -383.       ]\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291, type <class 'str'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyID: , type <class 'str'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDate: 20090831, type <class 'str'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyTime: 095948.599, type <class 'str'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDescription: CT ABDOMEN W IV CONTRAST, type <class 'str'>\n",
      "[2024-04-23 15:43:00,885] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - AccessionNumber: 5471978513296937, type <class 'str'>\n",
      "[2024-04-23 15:43:00,886] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - selection_name: CT Series, type <class 'str'>\n",
      "2024-04-23 15:43:01,872 INFO image_writer.py:197 - writing: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "2024-04-23 15:43:08,194 INFO image_writer.py:197 - writing: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n",
      "[2024-04-23 15:43:09,761] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image numpy array shaped: (204, 512, 512)\n",
      "[2024-04-23 15:43:09,767] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image pixel max value: 1\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  warnings.warn(\n",
      "[2024-04-23 15:43:11,092] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "[2024-04-23 15:43:11,093] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "\u001b[0m2024-04-23 15:43:11.181 INFO  gxf/std/greedy_scheduler.cpp@372: Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\u001b[0m\n",
      "\u001b[0m2024-04-23 15:43:11.181 INFO  gxf/std/greedy_scheduler.cpp@401: Scheduler finished.\u001b[0m\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1879] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1887] Graph execution finished.\n",
      "[2024-04-23 15:43:11,183] [INFO] (app.AISpleenSegApp) - End run\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:275] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!python my_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "1.2.826.0.1.3680043.10.511.3.57940295875624111168999103278306755.dcm\n",
      "saved_images_folder\n",
      "\n",
      "output/saved_images_folder:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626\n",
      "\n",
      "output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n"
     ]
    }
   ],
   "source": [
    "!ls -R $HOLOSCAN_OUTPUT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's package the app with [MONAI Application Packager](/developing_with_sdk/packaging_app).\n",
    "\n",
    "In this version of the App SDK, we need to write out the configuration yaml file as well as the package requirements file, in the application folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/app.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.yaml\n",
    "%YAML 1.2\n",
    "---\n",
    "application:\n",
    "  title: MONAI Deploy App Package - MONAI Bundle AI App\n",
    "  version: 1.0\n",
    "  inputFormats: [\"file\"]\n",
    "  outputFormats: [\"file\"]\n",
    "\n",
    "resources:\n",
    "  cpu: 1\n",
    "  gpu: 1\n",
    "  memory: 1Gi\n",
    "  gpuMemory: 6Gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/requirements.txt\n",
    "highdicom>=0.18.2\n",
    "monai>=1.0\n",
    "nibabel>=3.2.1\n",
    "numpy>=1.21.6\n",
    "pydicom>=2.3.0\n",
    "setuptools>=59.5.0 # for pkg_resources\n",
    "SimpleITK>=2.0.0\n",
    "torch>=1.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the CLI package command to build the MONAI Application Package (MAP) container image based on a supported base image.\n",
    "\n",
    ":::{note}\n",
    "Building a MONAI Application Package (Docker image) can take time. Use `-l DEBUG` option to see the progress.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-23 15:43:13,349] [INFO] (common) - Downloading CLI manifest file...\n",
      "[2024-04-23 15:43:13,718] [DEBUG] (common) - Validating CLI manifest file...\n",
      "[2024-04-23 15:43:13,720] [INFO] (packager.parameters) - Application: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/my_app\n",
      "[2024-04-23 15:43:13,721] [INFO] (packager.parameters) - Detected application type: Python Module\n",
      "[2024-04-23 15:43:13,721] [INFO] (packager) - Scanning for models in /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models...\n",
      "[2024-04-23 15:43:13,722] [DEBUG] (packager) - Model model=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model added.\n",
      "[2024-04-23 15:43:13,722] [INFO] (packager) - Reading application configuration from /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/my_app/app.yaml...\n",
      "[2024-04-23 15:43:13,725] [INFO] (packager) - Generating app.json...\n",
      "[2024-04-23 15:43:13,726] [INFO] (packager) - Generating pkg.json...\n",
      "[2024-04-23 15:43:13,738] [DEBUG] (common) - \n",
      "=============== Begin app.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app\\\"]\",\n",
      "    \"environment\": {\n",
      "        \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "        \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "        \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "        \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "        \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "        \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "        \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "        \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "        \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "        \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"path\": \"input/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"liveness\": null,\n",
      "    \"output\": {\n",
      "        \"path\": \"output/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"readiness\": null,\n",
      "    \"sdk\": \"monai-deploy\",\n",
      "    \"sdkVersion\": \"0.5.1\",\n",
      "    \"timeout\": 0,\n",
      "    \"version\": 1.0,\n",
      "    \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "================ End app.json ================\n",
      "                 \n",
      "[2024-04-23 15:43:13,739] [DEBUG] (common) - \n",
      "=============== Begin pkg.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "    \"modelRoot\": \"/opt/holoscan/models\",\n",
      "    \"models\": {\n",
      "        \"model\": \"/opt/holoscan/models/model\"\n",
      "    },\n",
      "    \"resources\": {\n",
      "        \"cpu\": 1,\n",
      "        \"gpu\": 1,\n",
      "        \"memory\": \"1Gi\",\n",
      "        \"gpuMemory\": \"6Gi\"\n",
      "    },\n",
      "    \"version\": 1.0,\n",
      "    \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "================ End pkg.json ================\n",
      "                 \n",
      "[2024-04-23 15:43:13,775] [DEBUG] (packager.builder) - \n",
      "========== Begin Dockerfile ==========\n",
      "\n",
      "\n",
      "FROM nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu\n",
      "\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "ENV TERM=xterm-256color\n",
      "\n",
      "ARG UNAME\n",
      "ARG UID\n",
      "ARG GID\n",
      "\n",
      "RUN mkdir -p /etc/holoscan/ \\\n",
      "        && mkdir -p /opt/holoscan/ \\\n",
      "        && mkdir -p /var/holoscan \\\n",
      "        && mkdir -p /opt/holoscan/app \\\n",
      "        && mkdir -p /var/holoscan/input \\\n",
      "        && mkdir -p /var/holoscan/output\n",
      "\n",
      "LABEL base=\"nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu\"\n",
      "LABEL tag=\"my_app:1.0\"\n",
      "LABEL org.opencontainers.image.title=\"MONAI Deploy App Package - MONAI Bundle AI App\"\n",
      "LABEL org.opencontainers.image.version=\"1.0\"\n",
      "LABEL org.nvidia.holoscan=\"2.0.0\"\n",
      "LABEL org.monai.deploy.app-sdk=\"0.5.1\"\n",
      "\n",
      "\n",
      "ENV HOLOSCAN_ENABLE_HEALTH_CHECK=true\n",
      "ENV HOLOSCAN_INPUT_PATH=/var/holoscan/input\n",
      "ENV HOLOSCAN_OUTPUT_PATH=/var/holoscan/output\n",
      "ENV HOLOSCAN_WORKDIR=/var/holoscan\n",
      "ENV HOLOSCAN_APPLICATION=/opt/holoscan/app\n",
      "ENV HOLOSCAN_TIMEOUT=0\n",
      "ENV HOLOSCAN_MODEL_PATH=/opt/holoscan/models\n",
      "ENV HOLOSCAN_DOCS_PATH=/opt/holoscan/docs\n",
      "ENV HOLOSCAN_CONFIG_PATH=/var/holoscan/app.yaml\n",
      "ENV HOLOSCAN_APP_MANIFEST_PATH=/etc/holoscan/app.json\n",
      "ENV HOLOSCAN_PKG_MANIFEST_PATH=/etc/holoscan/pkg.json\n",
      "ENV HOLOSCAN_LOGS_PATH=/var/holoscan/logs\n",
      "ENV PATH=/root/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/libtorch/1.13.1/lib/:/opt/nvidia/holoscan/lib\n",
      "\n",
      "RUN apt-get update \\\n",
      "    && apt-get install -y curl jq \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "ENV PYTHONPATH=\"/opt/holoscan/app:$PYTHONPATH\"\n",
      "\n",
      "\n",
      "RUN groupadd -f -g $GID $UNAME\n",
      "RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME\n",
      "RUN chown -R holoscan /var/holoscan \n",
      "RUN chown -R holoscan /var/holoscan/input \n",
      "RUN chown -R holoscan /var/holoscan/output \n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "# Copy HAP/MAP tool script\n",
      "COPY ./tools /var/holoscan/tools\n",
      "RUN chmod +x /var/holoscan/tools\n",
      "\n",
      "\n",
      "# Copy gRPC health probe\n",
      "\n",
      "USER $UNAME\n",
      "\n",
      "ENV PATH=/root/.local/bin:/home/holoscan/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "\n",
      "COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "\n",
      " \n",
      "# MONAI Deploy\n",
      "\n",
      "# Copy user-specified MONAI Deploy SDK file\n",
      "COPY ./monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl\n",
      "RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl\n",
      "\n",
      "\n",
      "COPY ./models  /opt/holoscan/models\n",
      "\n",
      "COPY ./map/app.json /etc/holoscan/app.json\n",
      "COPY ./app.config /var/holoscan/app.yaml\n",
      "COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "\n",
      "COPY ./app /opt/holoscan/app\n",
      "\n",
      "ENTRYPOINT [\"/var/holoscan/tools\"]\n",
      "=========== End Dockerfile ===========\n",
      "\n",
      "[2024-04-23 15:43:13,775] [INFO] (packager.builder) - \n",
      "===============================================================================\n",
      "Building image for:                 x64-workstation\n",
      "    Architecture:                   linux/amd64\n",
      "    Base Image:                     nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu\n",
      "    Build Image:                    N/A\n",
      "    Cache:                          Enabled\n",
      "    Configuration:                  dgpu\n",
      "    Holoscan SDK Package:           pypi.org\n",
      "    MONAI Deploy App SDK Package:   /home/mqin/src/monai-deploy-app-sdk/dist/monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl\n",
      "    gRPC Health Probe:              N/A\n",
      "    SDK Version:                    2.0.0\n",
      "    SDK:                            monai-deploy\n",
      "    Tag:                            my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    \n",
      "[2024-04-23 15:43:14,073] [INFO] (common) - Using existing Docker BuildKit builder `holoscan_app_builder`\n",
      "[2024-04-23 15:43:14,073] [DEBUG] (packager.builder) - Building Holoscan Application Package: tag=my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "#0 building with \"holoscan_app_builder\" instance using docker-container driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 2.66kB done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load metadata for nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu\n",
      "#2 DONE 0.4s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 1.79kB done\n",
      "#3 DONE 0.1s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 importing cache manifest from local:12311818318063394630\n",
      "#5 inferred cache manifest type: application/vnd.oci.image.index.v1+json done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 1/21] FROM nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu@sha256:20adbccd2c7b12dfb1798f6953f071631c3b85cd337858a7506f8e420add6d4a\n",
      "#6 resolve nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu@sha256:20adbccd2c7b12dfb1798f6953f071631c3b85cd337858a7506f8e420add6d4a 0.1s done\n",
      "#6 DONE 0.1s\n",
      "\n",
      "#7 importing cache manifest from nvcr.io/nvidia/clara-holoscan/holoscan:v2.0.0-dgpu\n",
      "#7 inferred cache manifest type: application/vnd.docker.distribution.manifest.list.v2+json done\n",
      "#7 DONE 0.7s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 transferring context: 19.56MB 0.1s done\n",
      "#4 DONE 0.2s\n",
      "\n",
      "#8 [ 8/21] RUN chown -R holoscan /var/holoscan/output\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 9/21] WORKDIR /var/holoscan\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 7/21] RUN chown -R holoscan /var/holoscan/input\n",
      "#10 CACHED\n",
      "\n",
      "#11 [ 4/21] RUN groupadd -f -g 1000 holoscan\n",
      "#11 CACHED\n",
      "\n",
      "#12 [13/21] RUN pip install --upgrade pip\n",
      "#12 CACHED\n",
      "\n",
      "#13 [10/21] COPY ./tools /var/holoscan/tools\n",
      "#13 CACHED\n",
      "\n",
      "#14 [12/21] COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "#14 CACHED\n",
      "\n",
      "#15 [ 6/21] RUN chown -R holoscan /var/holoscan\n",
      "#15 CACHED\n",
      "\n",
      "#16 [ 2/21] RUN mkdir -p /etc/holoscan/         && mkdir -p /opt/holoscan/         && mkdir -p /var/holoscan         && mkdir -p /opt/holoscan/app         && mkdir -p /var/holoscan/input         && mkdir -p /var/holoscan/output\n",
      "#16 CACHED\n",
      "\n",
      "#17 [ 3/21] RUN apt-get update     && apt-get install -y curl jq     && rm -rf /var/lib/apt/lists/*\n",
      "#17 CACHED\n",
      "\n",
      "#18 [ 5/21] RUN useradd -rm -d /home/holoscan -s /bin/bash -g 1000 -G sudo -u 1000 holoscan\n",
      "#18 CACHED\n",
      "\n",
      "#19 [11/21] RUN chmod +x /var/holoscan/tools\n",
      "#19 CACHED\n",
      "\n",
      "#20 [14/21] RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "#20 CACHED\n",
      "\n",
      "#21 [15/21] COPY ./monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl\n",
      "#21 DONE 0.8s\n",
      "\n",
      "#22 [16/21] RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl\n",
      "#22 0.711 Defaulting to user installation because normal site-packages is not writeable\n",
      "#22 0.833 Processing /tmp/monai_deploy_app_sdk-0.5.1+20.gb869749.dirty-py3-none-any.whl\n",
      "#22 0.843 Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (1.23.5)\n",
      "#22 1.040 Collecting holoscan~=2.0 (from monai-deploy-app-sdk==0.5.1+20.gb869749.dirty)\n",
      "#22 1.139   Downloading holoscan-2.0.0-cp310-cp310-manylinux_2_35_x86_64.whl.metadata (6.7 kB)\n",
      "#22 1.213 Collecting colorama>=0.4.1 (from monai-deploy-app-sdk==0.5.1+20.gb869749.dirty)\n",
      "#22 1.216   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "#22 1.308 Collecting typeguard>=3.0.0 (from monai-deploy-app-sdk==0.5.1+20.gb869749.dirty)\n",
      "#22 1.312   Downloading typeguard-4.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "#22 1.349 Requirement already satisfied: pip>=20.3 in /home/holoscan/.local/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (24.0)\n",
      "#22 1.350 Requirement already satisfied: cupy-cuda12x==12.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (12.2.0)\n",
      "#22 1.351 Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (2.2.1)\n",
      "#22 1.353 Requirement already satisfied: python-on-whales==0.60.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (0.60.1)\n",
      "#22 1.353 Requirement already satisfied: Jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (3.1.3)\n",
      "#22 1.354 Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (23.1)\n",
      "#22 1.355 Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (6.0)\n",
      "#22 1.356 Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (2.31.0)\n",
      "#22 1.357 Requirement already satisfied: psutil==5.9.6 in /usr/local/lib/python3.10/dist-packages (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (5.9.6)\n",
      "#22 1.468 Collecting wheel-axle-runtime<1.0 (from holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty)\n",
      "#22 1.474   Downloading wheel_axle_runtime-0.0.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "#22 1.512 Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x==12.2->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (0.8.2)\n",
      "#22 1.515 Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.1.3->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (2.1.3)\n",
      "#22 1.529 Requirement already satisfied: pydantic<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (1.10.15)\n",
      "#22 1.529 Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (4.66.2)\n",
      "#22 1.530 Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (0.12.3)\n",
      "#22 1.531 Requirement already satisfied: typing-extensions in /home/holoscan/.local/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (4.11.0)\n",
      "#22 1.540 Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (3.3.2)\n",
      "#22 1.541 Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (3.7)\n",
      "#22 1.542 Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (2.2.1)\n",
      "#22 1.543 Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (2024.2.2)\n",
      "#22 1.563 Requirement already satisfied: filelock in /home/holoscan/.local/lib/python3.10/site-packages (from wheel-axle-runtime<1.0->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (3.13.4)\n",
      "#22 1.586 Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (8.1.7)\n",
      "#22 1.587 Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (1.5.4)\n",
      "#22 1.588 Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (13.7.1)\n",
      "#22 1.623 Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.4.1->python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (3.0.0)\n",
      "#22 1.624 Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.4.1->python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (2.17.2)\n",
      "#22 1.645 Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.4.1->python-on-whales==0.60.1->holoscan~=2.0->monai-deploy-app-sdk==0.5.1+20.gb869749.dirty) (0.1.2)\n",
      "#22 1.662 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#22 1.686 Downloading holoscan-2.0.0-cp310-cp310-manylinux_2_35_x86_64.whl (33.2 MB)\n",
      "#22 2.182    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.2/33.2 MB 44.5 MB/s eta 0:00:00\n",
      "#22 2.187 Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "#22 2.210 Downloading wheel_axle_runtime-0.0.5-py3-none-any.whl (12 kB)\n",
      "#22 2.567 Installing collected packages: wheel-axle-runtime, typeguard, colorama, holoscan, monai-deploy-app-sdk\n",
      "#22 3.333 Successfully installed colorama-0.4.6 holoscan-2.0.0 monai-deploy-app-sdk-0.5.1+20.gb869749.dirty typeguard-4.2.1 wheel-axle-runtime-0.0.5\n",
      "#22 DONE 3.7s\n",
      "\n",
      "#23 [17/21] COPY ./models  /opt/holoscan/models\n",
      "#23 DONE 0.2s\n",
      "\n",
      "#24 [18/21] COPY ./map/app.json /etc/holoscan/app.json\n",
      "#24 DONE 0.1s\n",
      "\n",
      "#25 [19/21] COPY ./app.config /var/holoscan/app.yaml\n",
      "#25 DONE 0.1s\n",
      "\n",
      "#26 [20/21] COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "#26 DONE 0.1s\n",
      "\n",
      "#27 [21/21] COPY ./app /opt/holoscan/app\n",
      "#27 DONE 0.1s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 exporting layers\n",
      "#28 exporting layers 4.7s done\n",
      "#28 exporting manifest sha256:272f9320d555ec164d2cdbdf3af72c2508a3768b3438478dfebc976ab20bdef5 0.0s done\n",
      "#28 exporting config sha256:af6b96cbe7081e40c1393d1adcbb0d90e60f1eee0f770de931c17ec7e661922f 0.0s done\n",
      "#28 sending tarball\n",
      "#28 ...\n",
      "\n",
      "#29 importing to docker\n",
      "#29 loading layer 5c74dcc5f86c 32.77kB / 125.82kB\n",
      "#29 loading layer cf9ad481b317 557.06kB / 67.35MB\n",
      "#29 loading layer c4db34b6201c 196.61kB / 17.81MB\n",
      "#29 loading layer 37555bd01c91 490B / 490B\n",
      "#29 loading layer 47758cf3f2be 313B / 313B\n",
      "#29 loading layer f6490513de44 299B / 299B\n",
      "#29 loading layer d1e36c8e77c6 3.91kB / 3.91kB\n",
      "#29 loading layer 47758cf3f2be 313B / 313B 1.0s done\n",
      "#29 loading layer 5c74dcc5f86c 32.77kB / 125.82kB 3.3s done\n",
      "#29 loading layer cf9ad481b317 557.06kB / 67.35MB 3.2s done\n",
      "#29 loading layer c4db34b6201c 196.61kB / 17.81MB 1.4s done\n",
      "#29 loading layer 37555bd01c91 490B / 490B 1.1s done\n",
      "#29 loading layer f6490513de44 299B / 299B 1.0s done\n",
      "#29 loading layer d1e36c8e77c6 3.91kB / 3.91kB 0.9s done\n",
      "#29 DONE 3.3s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 sending tarball 69.0s done\n",
      "#28 DONE 73.8s\n",
      "\n",
      "#30 exporting cache to client directory\n",
      "#30 preparing build cache for export\n",
      "#30 writing layer sha256:014cff740c9ec6e9a30d0b859219a700ae880eb385d62095d348f5ea136d6015\n",
      "#30 writing layer sha256:014cff740c9ec6e9a30d0b859219a700ae880eb385d62095d348f5ea136d6015 done\n",
      "#30 writing layer sha256:0487800842442c7a031a39e1e1857bc6dae4b4f7e5daf3d625f7a8a4833fb364 done\n",
      "#30 writing layer sha256:06c6aee94862daf0603783db4e1de6f8524b30ac9fbe0374ab3f1d85b2f76f7f done\n",
      "#30 writing layer sha256:0a1756432df4a4350712d8ae5c003f1526bd2180800b3ae6301cfc9ccf370254 done\n",
      "#30 writing layer sha256:0a77dcbd0e648ddc4f8e5230ade8fdb781d99e24fa4f13ca96a360c7f7e6751f done\n",
      "#30 writing layer sha256:0ec682bf99715a9f88631226f3749e2271b8b9f254528ef61f65ed829984821c done\n",
      "#30 writing layer sha256:1c5c3aa9c2c8bfd1b9eb36248f5b6d67b3db73ef43440f9dd897615771974b39 done\n",
      "#30 writing layer sha256:1f4a978bb76db2d138cfe7c7c9e76db4096247b06e34d349a2ed504bcd6a7ead done\n",
      "#30 writing layer sha256:1f73278b7f17492ce1a8b28b139d54596961596d6790dc20046fa6d5909f3e9c done\n",
      "#30 writing layer sha256:20d331454f5fb557f2692dfbdbe092c718fd2cb55d5db9d661b62228dacca5c2 done\n",
      "#30 writing layer sha256:20e14f0a8ca68167afb8296c10d7a1b4c3b17b54681cbf3b9b45e1be96afa699 0.0s done\n",
      "#30 writing layer sha256:238f69a43816e481f0295995fcf5fe74d59facf0f9f99734c8d0a2fb140630e0 done\n",
      "#30 writing layer sha256:255cc51d2e47738a5db3059cbe9f403785cf9496c7df8a28a3c9f0c46a0b3b58 done\n",
      "#30 writing layer sha256:2ad84487f9d4d31cd1e0a92697a5447dd241935253d036b272ef16d31620c1e7 done\n",
      "#30 writing layer sha256:2f65750928993b5b31fe572d9e085b53853c5a344feeb0e8615898e285a8c256 done\n",
      "#30 writing layer sha256:34c541b0f73b95f074d23fe925ff6a983a971ca2fbfad7bd9a6863b47994c312\n",
      "#30 writing layer sha256:34c541b0f73b95f074d23fe925ff6a983a971ca2fbfad7bd9a6863b47994c312 0.4s done\n",
      "#30 writing layer sha256:3777c6498f08c0400339c243e827d465075b7296eb2526e38d9b01c84f8764d8\n",
      "#30 writing layer sha256:3777c6498f08c0400339c243e827d465075b7296eb2526e38d9b01c84f8764d8 done\n",
      "#30 writing layer sha256:3c91e9a3b2c9cb860c5001bb174d4ebf28358626e66f6e33f7b6209d6e0d2ce0 0.0s done\n",
      "#30 writing layer sha256:3e3e04011ebdba380ab129f0ee390626cb2a600623815ca756340c18bedb9517 done\n",
      "#30 writing layer sha256:42619ce4a0c9e54cfd0ee41a8e5f27d58b3f51becabd1ac6de725fbe6c42b14a done\n",
      "#30 writing layer sha256:49bdc9abf8a437ccff67cc11490ba52c976577992909856a86be872a34d3b950 done\n",
      "#30 writing layer sha256:4b691ba9f48b41eaa0c754feba8366f1c030464fcbc55eeffa6c86675990933a done\n",
      "#30 writing layer sha256:4d04a8db404f16c2704fa10739cb6745a0187713a21a6ef0deb34b48629b54c1 done\n",
      "#30 writing layer sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 done\n",
      "#30 writing layer sha256:542bc8c8d18fbc95e6794122c3593a4a693f8ab6dda4460406f4d7b1ae64a2bc done\n",
      "#30 writing layer sha256:57f244836ad318f9bbb3b29856ae1a5b31038bfbb9b43d2466d51c199eb55041 done\n",
      "#30 writing layer sha256:5b5b131e0f20db4cb8e568b623a95f8fc16ed1c6b322a9366df70b59a881f24f done\n",
      "#30 writing layer sha256:5b90d17b5048adcadefd0b1e4dba9a99247a8827a887e1ca042df375c85b518d done\n",
      "#30 writing layer sha256:62452179df7c18e292f141d4aec29e6aba9ff8270c893731169fc6f41dc07631 done\n",
      "#30 writing layer sha256:6630c387f5f2115bca2e646fd0c2f64e1f3d5431c2e050abe607633883eda230 done\n",
      "#30 writing layer sha256:6661e0146e77a8bcb03edbfda95bf7780c8bb4c4f98bc03a398c88f4b2403d12 done\n",
      "#30 writing layer sha256:717ebf8c9c66ae393ad01e50dbac4413d7b026b9c97d4d348b22ad17052a1a35 done\n",
      "#30 writing layer sha256:773c6815e5e7d6855a62f8c5e2fabce3d939ded36c5420f15b54dd7908cdbcfa done\n",
      "#30 writing layer sha256:7852b73ea931e3a8d3287ee7ef3cf4bad068e44f046583bfc2b81336fb299284 done\n",
      "#30 writing layer sha256:7f8ec130348bcdac81c295e37fe82b4a6e5e9a3ca980a6343809c561020d82d7 done\n",
      "#30 writing layer sha256:80885adcad6b5d021bb9f68b6c952018085bb4ce72011bdc0cf7fe8178b5960b done\n",
      "#30 writing layer sha256:82a3436133b2b17bb407c7fe488932aa0ca55411f23ab55c34a6134b287c6a27 done\n",
      "#30 writing layer sha256:8371d15eb4d69b1d98174dd098b8ddd5c4f19ec6f8d8b67e72dfa9891dc454b4 done\n",
      "#30 writing layer sha256:85713f9b166b5add777c524ee807f6265d88b967cbeb9f961d6b09bf220c9a65 done\n",
      "#30 writing layer sha256:8fe00505006a09966e763918147ef6ed55bb6695b26e4940c780ee430dc5da8e done\n",
      "#30 writing layer sha256:90eae6faa5cc5ba62f12c25915cdfb1a7a51abfba0d05cb5818c3f908f4e345f done\n",
      "#30 writing layer sha256:9205d97d9d3e906698bcc6c42d45727c2fa6ec2622abf953d46778c3b8c78edc done\n",
      "#30 writing layer sha256:92301d1270c19cab329818fb215b41138720ab9b588a2070107860f0b6fb5e11\n",
      "#30 writing layer sha256:92301d1270c19cab329818fb215b41138720ab9b588a2070107860f0b6fb5e11 1.4s done\n",
      "#30 writing layer sha256:993369dbcc13162a6654d2a3e990b8d8b5f37963564d25710e12764337261ae3\n",
      "#30 writing layer sha256:993369dbcc13162a6654d2a3e990b8d8b5f37963564d25710e12764337261ae3 done\n",
      "#30 writing layer sha256:99e42a4adebadb39bf55bf94bbd9fb8034230ee19b6b0a42e6ff96f2e7794f30 done\n",
      "#30 writing layer sha256:9ac855545fa90ed2bf3b388fdff9ef06ac9427b0c0fca07c9e59161983d8827e done\n",
      "#30 writing layer sha256:9d19ee268e0d7bcf6716e6658ee1b0384a71d6f2f9aa1ae2085610cf7c7b316f done\n",
      "#30 writing layer sha256:9fafbd4203c4fefe007a462e0d2cd4c1c7c41db2cfdc58d212279e1b9b4b230c done\n",
      "#30 writing layer sha256:a1748eee9d376f97bd19225ba61dfada9986f063f4fc429e435f157abb629fc6 done\n",
      "#30 writing layer sha256:a251fe5ae6c6d2d5034e4ca88b5dfe5d4827ff90b18e9b143a073232a32bb18d done\n",
      "#30 writing layer sha256:a68f4e0ec09ec3b78cb4cf8e4511d658e34e7b6f676d7806ad9703194ff17604 done\n",
      "#30 writing layer sha256:a8e4decc8f7289623b8fd7b9ba1ca555b5a755ebdbf81328d68209f148d9e602 done\n",
      "#30 writing layer sha256:add6bd0fec8e510c778856ae5993f823022a9a0230681b9333c83c58bca70f56 0.0s done\n",
      "#30 writing layer sha256:afde1c269453ce68a0f2b54c1ba8c5ecddeb18a19e5618a4acdef1f0fe3921af done\n",
      "#30 writing layer sha256:b406feb20a37b8c87ef4f5ef814039e3adc90473d50c366b7d9bb6ded4e94a2e done\n",
      "#30 writing layer sha256:b48a5fafcaba74eb5d7e7665601509e2889285b50a04b5b639a23f8adc818157 done\n",
      "#30 writing layer sha256:b93a8d787a5c613029585348476c2b6aa666ea47936e138082b0e9175a5583e0 0.0s done\n",
      "#30 writing layer sha256:ba9f7c75e4dd7942b944679995365aab766d3677da2e69e1d74472f471a484dd done\n",
      "#30 writing layer sha256:bdc13166216ae226fa6976f9ce91f4f259d43972f1e0a9b723e436919534b2f4 done\n",
      "#30 writing layer sha256:c815f0be64eded102822d81e029bd23b0d8d9a0fbfeb492ec0b4b0bc4ee777bf done\n",
      "#30 writing layer sha256:c97f7fb19e2e0b8ee3e1065f4dee369e35029cc620cafb7fe3dec2e9e06a3ae0 done\n",
      "#30 writing layer sha256:c98533d2908f36a5e9b52faae83809b3b6865b50e90e2817308acfc64cd3655f done\n",
      "#30 writing layer sha256:d7da5c5e9a40c476c4b3188a845e3276dedfd752e015ea5113df5af64d4d43f7 done\n",
      "#30 writing layer sha256:db20521a869adda8244cb64b783c65e1a911efaae0e73ae00e4a34ea6213d6ce done\n",
      "#30 writing layer sha256:df4fd0ac710d7af949afbc6d25b5b4daf3f0596dabf3dec36fa7ca8fa6e1d049 done\n",
      "#30 writing layer sha256:e291ddecfbe16b95ee9e90b5e90b1a3d0cfd53dc5e720d6b0f3d28e4a47cf5ac done\n",
      "#30 writing layer sha256:e8acb678f16bc0c369d5cf9c184f2d3a1c773986816526e5e3e9c0354f7e757f done\n",
      "#30 writing layer sha256:e9225f7ab6606813ec9acba98a064826ebfd6713a9645a58cd068538af1ecddb done\n",
      "#30 writing layer sha256:f0d70ecec43610ba497f9ab128ee1fbb4ec2aabcacca4f5be136d13bd1ee0fcb 0.0s done\n",
      "#30 writing layer sha256:f249faf9663a96b0911a903f8803b11a553c59b698013fb8343492fefdaaea90 done\n",
      "#30 writing layer sha256:f608e2fbff86e98627b7e462057e7d2416522096d73fe4664b82fe6ce8a4047d done\n",
      "#30 writing layer sha256:f65d191416580d6c38e3d95eee12377b75a4df548be1492618ce2a8c3c41b99e done\n",
      "#30 writing config sha256:d8b1ede40893d3af61eaf7d4d58ae3afaa55e9e0fc7722d020635c545f81df0c 0.0s done\n",
      "#30 preparing build cache for export 2.6s done\n",
      "#30 writing cache manifest sha256:00058bfc69cbf02a85b5242dfe17b06ca30b9c7312be3f7b2cf3aa215c57747f 0.0s done\n",
      "#30 DONE 2.6s\n",
      "[2024-04-23 15:44:38,817] [INFO] (packager) - Build Summary:\n",
      "\n",
      "Platform: x64-workstation/dgpu\n",
      "    Status:     Succeeded\n",
      "    Docker Tag: my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Tarball:    None\n"
     ]
    }
   ],
   "source": [
    "tag_prefix = \"my_app\"\n",
    "\n",
    "!monai-deploy package my_app -m {models_folder} -c my_app/app.yaml -t {tag_prefix}:1.0 --platform x64-workstation -l DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MAP Docker image is created.\n",
    "\n",
    "We can choose to display and inspect the MAP manifests by running the container with the `show` command, as well as extracting the manifests and other contents in the MAP by using the `extract` command, but not demonstrated in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_app-x64-workstation-dgpu-linux-amd64                                                   1.0                 af6b96cbe708   About a minute ago   17.7GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep {tag_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing packaged app locally\n",
    "\n",
    "The packaged app can be run locally through [MONAI Application Runner](/developing_with_sdk/executing_packaged_app_locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output\n",
      "dcm\n",
      "[2024-04-23 15:44:40,497] [INFO] (runner) - Checking dependencies...\n",
      "[2024-04-23 15:44:40,497] [INFO] (runner) - --> Verifying if \"docker\" is installed...\n",
      "\n",
      "[2024-04-23 15:44:40,497] [INFO] (runner) - --> Verifying if \"docker-buildx\" is installed...\n",
      "\n",
      "[2024-04-23 15:44:40,497] [INFO] (runner) - --> Verifying if \"my_app-x64-workstation-dgpu-linux-amd64:1.0\" is available...\n",
      "\n",
      "[2024-04-23 15:44:40,571] [INFO] (runner) - Reading HAP/MAP manifest...\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.56kB to /tmp/tmpojmzf387/app.json\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.05kB to /tmp/tmpojmzf387/pkg.json\n",
      "[2024-04-23 15:44:41,518] [INFO] (runner) - --> Verifying if \"nvidia-ctk\" is installed...\n",
      "\n",
      "[2024-04-23 15:44:41,518] [INFO] (runner) - --> Verifying \"nvidia-ctk\" version...\n",
      "\n",
      "[2024-04-23 15:44:41,869] [INFO] (common) - Launching container (a6bc36c774bd) using image 'my_app-x64-workstation-dgpu-linux-amd64:1.0'...\n",
      "    container name:      dreamy_goldberg\n",
      "    host name:           mingq-dt\n",
      "    network:             host\n",
      "    user:                1000:1000\n",
      "    ulimits:             memlock=-1:-1, stack=67108864:67108864\n",
      "    cap_add:             CAP_SYS_PTRACE\n",
      "    ipc mode:            host\n",
      "    shared memory size:  67108864\n",
      "    devices:             \n",
      "    group_add:           44\n",
      "2024-04-23 22:44:42 [INFO] Launching application python3 /opt/holoscan/app ...\n",
      "\n",
      "[2024-04-23 22:44:46,465] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=['/opt/holoscan/app'])\n",
      "\n",
      "[2024-04-23 22:44:46,467] [INFO] (root) - AppContext object: AppContext(input_path=/var/holoscan/input, output_path=/var/holoscan/output, model_path=/opt/holoscan/models, workdir=/var/holoscan)\n",
      "\n",
      "[2024-04-23 22:44:46,467] [INFO] (app.AISpleenSegApp) - App input and output path: /var/holoscan/input, /var/holoscan/output\n",
      "\n",
      "[info] [app_driver.cpp:1161] Launching the driver/health checking service\n",
      "\n",
      "[info] [gxf_executor.cpp:247] Creating context\n",
      "\n",
      "[info] [server.cpp:87] Health checking server listening on 0.0.0.0:8777\n",
      "\n",
      "[info] [gxf_executor.cpp:1672] Loading extensions from configs...\n",
      "\n",
      "[info] [gxf_executor.cpp:1842] Activating Graph...\n",
      "\n",
      "\u001b[0m2024-04-23 22:44:46.511 INFO  gxf/std/greedy_scheduler.cpp@191: Scheduling 6 entities\u001b[0m\n",
      "\n",
      "[info] [gxf_executor.cpp:1874] Running Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1876] Waiting for completion...\n",
      "\n",
      "[2024-04-23 22:44:46,513] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "\n",
      "  # of series: 1\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) -     Series attribute Modality value: CT\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - On attribute: 'ImageType' to match value: ['PRIMARY', 'ORIGINAL']\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) -     Series attribute ImageType value: None\n",
      "\n",
      "[2024-04-23 22:44:46,974] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Converted Image object metadata:\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDate: 20090831, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesTime: 101721.452, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Modality: CT, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesDescription: ABD/PANC 3.0 B31f, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - PatientPosition: HFS, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,194] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - SeriesNumber: 8, type <class 'int'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_pixel_spacing: 0.7890625, type <class 'float'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_pixel_spacing: 1.5, type <class 'float'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - row_direction_cosine: [1.0, 0.0, 0.0], type <class 'list'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - col_direction_cosine: [0.0, 1.0, 0.0], type <class 'list'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - depth_direction_cosine: [0.0, 0.0, 1.0], type <class 'list'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - dicom_affine_transform: [[   0.7890625    0.           0.        -197.60547  ]\n",
      "\n",
      " [   0.           0.7890625    0.        -398.60547  ]\n",
      "\n",
      " [   0.           0.           1.5       -383.       ]\n",
      "\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "\n",
      "[2024-04-23 22:44:47,195] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - nifti_affine_transform: [[  -0.7890625   -0.          -0.         197.60547  ]\n",
      "\n",
      " [  -0.          -0.7890625   -0.         398.60547  ]\n",
      "\n",
      " [   0.           0.           1.5       -383.       ]\n",
      "\n",
      " [   0.           0.           0.           1.       ]], type <class 'numpy.ndarray'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyInstanceUID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyID: , type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDate: 20090831, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyTime: 095948.599, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - StudyDescription: CT ABDOMEN W IV CONTRAST, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - AccessionNumber: 5471978513296937, type <class 'str'>\n",
      "\n",
      "[2024-04-23 22:44:47,196] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - selection_name: CT Series, type <class 'str'>\n",
      "\n",
      "2024-04-23 22:44:47,986 INFO image_writer.py:197 - writing: /var/holoscan/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "\n",
      "2024-04-23 22:44:51,638 INFO image_writer.py:197 - writing: /var/holoscan/output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626/1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n",
      "\n",
      "[2024-04-23 22:44:53,491] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image numpy array shaped: (204, 512, 512)\n",
      "\n",
      "[2024-04-23 22:44:53,497] [INFO] (monai.deploy.operators.monai_seg_inference_operator.MonaiSegInferenceOperator) - Output Seg image pixel max value: 1\n",
      "\n",
      "/home/holoscan/.local/lib/python3.10/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2024-04-23 22:44:54,694] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "\n",
      "[2024-04-23 22:44:54,695] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "\n",
      "[2024-04-23 22:44:54,695] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "\n",
      "\u001b[0m2024-04-23 22:44:54.787 INFO  gxf/std/greedy_scheduler.cpp@372: Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\u001b[0m\n",
      "\n",
      "\u001b[0m2024-04-23 22:44:54.788 INFO  gxf/std/greedy_scheduler.cpp@401: Scheduler finished.\u001b[0m\n",
      "\n",
      "[info] [gxf_executor.cpp:1879] Deactivating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1887] Graph execution finished.\n",
      "\n",
      "[2024-04-23 22:44:54,793] [INFO] (app.AISpleenSegApp) - End run\n",
      "\n",
      "[info] [gxf_executor.cpp:275] Destroying context\n",
      "\n",
      "[2024-04-23 15:44:56,376] [INFO] (common) - Container 'dreamy_goldberg'(a6bc36c774bd) exited.\n"
     ]
    }
   ],
   "source": [
    "# Clear the output folder and run the MAP. The input is expected to be a folder.\n",
    "!echo $HOLOSCAN_OUTPUT_PATH\n",
    "!echo $HOLOSCAN_INPUT_PATH\n",
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!monai-deploy run -i $HOLOSCAN_INPUT_PATH -o $HOLOSCAN_OUTPUT_PATH my_app-x64-workstation-dgpu-linux-amd64:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:\n",
      "1.2.826.0.1.3680043.10.511.3.57272145768055517649062567242794544.dcm\n",
      "saved_images_folder\n",
      "\n",
      "output/saved_images_folder:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626\n",
      "\n",
      "output/saved_images_folder/1.3.6.1.4.1.14519.5.2.1.7085.2626:\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626.nii\n",
      "1.3.6.1.4.1.14519.5.2.1.7085.2626_seg.nii\n"
     ]
    }
   ],
   "source": [
    "!ls -R $HOLOSCAN_OUTPUT_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b4ab1155d0cd1042497eb40fd55b2d15caf4b3c0f9fbfcc7ba4404045d40f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
