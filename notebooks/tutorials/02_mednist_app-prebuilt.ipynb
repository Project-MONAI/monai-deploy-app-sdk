{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a MedNIST Classifier App with MONAI Deploy App SDK (Prebuilt Model)\n",
    "\n",
    "This tutorial demos the process of packaging up a trained model using MONAI Deploy App SDK into an deployable inference application which can be run as a local program, as well as an MONAI Application Package (MAP) for containerized workflow execution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the github project (the latest version of the main branch only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'source'...\n",
      "remote: Enumerating objects: 276, done.\u001b[K\n",
      "remote: Counting objects: 100% (276/276), done.\u001b[K\n",
      "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
      "remote: Total 276 (delta 55), reused 150 (delta 32), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (276/276), 1.43 MiB | 3.51 MiB/s, done.\n",
      "Resolving deltas: 100% (55/55), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf source \\\n",
    " && git clone --branch main --depth 1 https://github.com/Project-MONAI/monai-deploy-app-sdk.git source \\\n",
    " && rm -rf source/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml  mednist_classifier_monaideploy.py  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls source/examples/apps/mednist_classifier_monaideploy/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install monai-deploy-app-sdk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai-deploy-app-sdk in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (0.5.1+12.gb2f5a07.dirty)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (1.26.4)\n",
      "Requirement already satisfied: holoscan~=1.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (1.0.3)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (0.4.6)\n",
      "Requirement already satisfied: typeguard>=3.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (4.2.1)\n",
      "Requirement already satisfied: pip==23.3.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (23.3.2)\n",
      "Requirement already satisfied: cupy-cuda12x==12.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (12.2.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (2.2.1)\n",
      "Requirement already satisfied: python-on-whales==0.60.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (0.60.1)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (3.1.2)\n",
      "Requirement already satisfied: packaging==23.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (23.1)\n",
      "Requirement already satisfied: pyyaml==6.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (6.0)\n",
      "Requirement already satisfied: requests==2.28.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (2.28.2)\n",
      "Requirement already satisfied: psutil==5.9.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (5.9.6)\n",
      "Requirement already satisfied: wheel-axle-runtime<1.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=1.0->monai-deploy-app-sdk) (0.0.5)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from cupy-cuda12x==12.2->holoscan~=1.0->monai-deploy-app-sdk) (0.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from Jinja2==3.1.2->holoscan~=1.0->monai-deploy-app-sdk) (2.1.5)\n",
      "Requirement already satisfied: pydantic<2,>=1.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (1.10.15)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (4.66.2)\n",
      "Requirement already satisfied: typer>=0.4.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (0.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk) (2024.2.2)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from wheel-axle-runtime<1.0->holoscan~=1.0->monai-deploy-app-sdk) (3.13.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (13.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai-deploy-app-sdk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (1.3.0)\n",
      "Requirement already satisfied: Pillow in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (10.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai) (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (1.12)\n",
      "Requirement already satisfied: networkx in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->monai) (69.2.0)\n",
      "Requirement already satisfied: wheel in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.9->monai) (0.43.0)\n",
      "Requirement already satisfied: cmake in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->monai) (3.29.0.1)\n",
      "Requirement already satisfied: lit in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.9->monai) (18.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install monai Pillow # for MONAI transforms and Pillow\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=1.4.2\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\" # for the use of DICOM Writer operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/Extract mednist_classifier_data.zip from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (3.13.3)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (4.66.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\n",
      "From (redirected): https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E&confirm=t&uuid=8dfa9939-2267-4d12-ba17-3e35b1626357\n",
      "To: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/mednist_classifier_data.zip\n",
      "100%|██████████████████████████████████████| 28.6M/28.6M [00:00<00:00, 62.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download mednist_classifier_data.zip\n",
    "!pip install gdown \n",
    "!gdown \"https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mednist_classifier_data.zip\n",
      " extracting: classifier.zip          \n",
      " extracting: input/AbdomenCT_007000.jpeg  \n",
      "classifier.zip\n"
     ]
    }
   ],
   "source": [
    "# Unzip the downloaded mednist_classifier_data.zip from the web browser or using gdown, and set up folders\n",
    "input_folder = \"input\"\n",
    "output_folder = \"output\"\n",
    "models_folder = \"models\"\n",
    "!rm -rf {input_folder}\n",
    "!unzip -o \"mednist_classifier_data.zip\"\n",
    "\n",
    "# Need to copy the model file to its own clean subfolder for pacakging, to workaround an issue in the Packager\n",
    "models_folder = \"models\"\n",
    "!rm -rf {models_folder} && mkdir -p {models_folder}/model && cp classifier.zip {models_folder}/model && ls {models_folder}/model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment variables\n",
    "The application uses well-known enviornment variables for the input/output data path, working dir, as well as AI model file path if applicable. Defaults are used if these environment variable are absent.\n",
    "\n",
    "Set the environment variables corresponding to the extracted data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=input\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n",
      "env: HOLOSCAN_MODEL_PATH=models\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH {input_folder}\n",
    "%env HOLOSCAN_OUTPUT_PATH {output_folder}\n",
    "%env HOLOSCAN_MODEL_PATH {models_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package app (creating MAP container image)\n",
    "\n",
    "Now we can use the CLI package command to build the MONAI Application Package (MAP) container image based on a supported base image\n",
    "\n",
    "Use `-l DEBUG` option to see progress.\n",
    "\n",
    ":::{note}\n",
    "This assumes that <a href=\"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\">NVIDIA Container Toolkit or nvidia docker</a> is installed on the local machine.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 16:23:51,962] [INFO] (packager.parameters) - Application: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/mednist_classifier_monaideploy.py\n",
      "[2024-04-10 16:23:51,962] [INFO] (packager.parameters) - Detected application type: Python File\n",
      "[2024-04-10 16:23:51,962] [INFO] (packager) - Scanning for models in /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models...\n",
      "[2024-04-10 16:23:51,962] [DEBUG] (packager) - Model model=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model added.\n",
      "[2024-04-10 16:23:51,962] [INFO] (packager) - Reading application configuration from /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/app.yaml...\n",
      "[2024-04-10 16:23:51,964] [INFO] (packager) - Generating app.json...\n",
      "[2024-04-10 16:23:51,964] [INFO] (packager) - Generating pkg.json...\n",
      "[2024-04-10 16:23:51,969] [DEBUG] (common) - \n",
      "=============== Begin app.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app/mednist_classifier_monaideploy.py\\\"]\",\n",
      "    \"environment\": {\n",
      "        \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "        \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "        \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "        \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "        \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "        \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "        \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "        \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "        \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "        \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"path\": \"input/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"liveness\": null,\n",
      "    \"output\": {\n",
      "        \"path\": \"output/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"readiness\": null,\n",
      "    \"sdk\": \"monai-deploy\",\n",
      "    \"sdkVersion\": \"0.5.1\",\n",
      "    \"timeout\": 0,\n",
      "    \"version\": 1.0,\n",
      "    \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "================ End app.json ================\n",
      "                 \n",
      "[2024-04-10 16:23:51,969] [DEBUG] (common) - \n",
      "=============== Begin pkg.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "    \"modelRoot\": \"/opt/holoscan/models\",\n",
      "    \"models\": {\n",
      "        \"model\": \"/opt/holoscan/models/model\"\n",
      "    },\n",
      "    \"resources\": {\n",
      "        \"cpu\": 1,\n",
      "        \"gpu\": 1,\n",
      "        \"memory\": \"1Gi\",\n",
      "        \"gpuMemory\": \"1Gi\"\n",
      "    },\n",
      "    \"version\": 1.0,\n",
      "    \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "================ End pkg.json ================\n",
      "                 \n",
      "[2024-04-10 16:23:52,003] [DEBUG] (packager.builder) - \n",
      "========== Begin Dockerfile ==========\n",
      "\n",
      "\n",
      "FROM nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "ENV TERM=xterm-256color\n",
      "\n",
      "ARG UNAME\n",
      "ARG UID\n",
      "ARG GID\n",
      "\n",
      "RUN mkdir -p /etc/holoscan/ \\\n",
      "        && mkdir -p /opt/holoscan/ \\\n",
      "        && mkdir -p /var/holoscan \\\n",
      "        && mkdir -p /opt/holoscan/app \\\n",
      "        && mkdir -p /var/holoscan/input \\\n",
      "        && mkdir -p /var/holoscan/output\n",
      "\n",
      "LABEL base=\"nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\"\n",
      "LABEL tag=\"mednist_app:1.0\"\n",
      "LABEL org.opencontainers.image.title=\"MONAI Deploy App Package - MedNIST Classifier App\"\n",
      "LABEL org.opencontainers.image.version=\"1.0\"\n",
      "LABEL org.nvidia.holoscan=\"1.0.3\"\n",
      "LABEL org.monai.deploy.app-sdk=\"0.5.1\"\n",
      "\n",
      "\n",
      "ENV HOLOSCAN_ENABLE_HEALTH_CHECK=true\n",
      "ENV HOLOSCAN_INPUT_PATH=/var/holoscan/input\n",
      "ENV HOLOSCAN_OUTPUT_PATH=/var/holoscan/output\n",
      "ENV HOLOSCAN_WORKDIR=/var/holoscan\n",
      "ENV HOLOSCAN_APPLICATION=/opt/holoscan/app\n",
      "ENV HOLOSCAN_TIMEOUT=0\n",
      "ENV HOLOSCAN_MODEL_PATH=/opt/holoscan/models\n",
      "ENV HOLOSCAN_DOCS_PATH=/opt/holoscan/docs\n",
      "ENV HOLOSCAN_CONFIG_PATH=/var/holoscan/app.yaml\n",
      "ENV HOLOSCAN_APP_MANIFEST_PATH=/etc/holoscan/app.json\n",
      "ENV HOLOSCAN_PKG_MANIFEST_PATH=/etc/holoscan/pkg.json\n",
      "ENV HOLOSCAN_LOGS_PATH=/var/holoscan/logs\n",
      "ENV PATH=/root/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/libtorch/1.13.1/lib/:/opt/nvidia/holoscan/lib\n",
      "\n",
      "RUN apt-get update \\\n",
      "    && apt-get install -y curl jq \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "ENV PYTHONPATH=\"/opt/holoscan/app:$PYTHONPATH\"\n",
      "\n",
      "\n",
      "\n",
      "RUN groupadd -f -g $GID $UNAME\n",
      "RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME\n",
      "RUN chown -R holoscan /var/holoscan \n",
      "RUN chown -R holoscan /var/holoscan/input \n",
      "RUN chown -R holoscan /var/holoscan/output \n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "# Copy HAP/MAP tool script\n",
      "COPY ./tools /var/holoscan/tools\n",
      "RUN chmod +x /var/holoscan/tools\n",
      "\n",
      "\n",
      "# Copy gRPC health probe\n",
      "\n",
      "USER $UNAME\n",
      "\n",
      "ENV PATH=/root/.local/bin:/home/holoscan/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "\n",
      "COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "\n",
      "# Install Holoscan from PyPI only when sdk_type is Holoscan. \n",
      "# For MONAI Deploy, the APP SDK will install it unless user specifies the Holoscan SDK file.\n",
      "\n",
      "# Copy user-specified MONAI Deploy SDK file\n",
      "COPY ./monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "COPY ./models  /opt/holoscan/models\n",
      "\n",
      "COPY ./map/app.json /etc/holoscan/app.json\n",
      "COPY ./app.config /var/holoscan/app.yaml\n",
      "COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "\n",
      "COPY ./app /opt/holoscan/app\n",
      "\n",
      "ENTRYPOINT [\"/var/holoscan/tools\"]\n",
      "=========== End Dockerfile ===========\n",
      "\n",
      "[2024-04-10 16:23:52,003] [INFO] (packager.builder) - \n",
      "===============================================================================\n",
      "Building image for:                 x64-workstation\n",
      "    Architecture:                   linux/amd64\n",
      "    Base Image:                     nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "    Build Image:                    N/A\n",
      "    Cache:                          Enabled\n",
      "    Configuration:                  dgpu\n",
      "    Holoscan SDK Package:           pypi.org\n",
      "    MONAI Deploy App SDK Package:   /home/mqin/src/monai-deploy-app-sdk/dist/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "    gRPC Health Probe:              N/A\n",
      "    SDK Version:                    1.0.3\n",
      "    SDK:                            monai-deploy\n",
      "    Tag:                            mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    \n",
      "[2024-04-10 16:23:52,265] [INFO] (common) - Using existing Docker BuildKit builder `holoscan_app_builder`\n",
      "[2024-04-10 16:23:52,265] [DEBUG] (packager.builder) - Building Holoscan Application Package: tag=mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "#0 building with \"holoscan_app_builder\" instance using docker-container driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 2.81kB done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load metadata for nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "#2 DONE 0.1s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 1.79kB done\n",
      "#3 DONE 0.1s\n",
      "\n",
      "#4 importing cache manifest from nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "#4 ...\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 importing cache manifest from local:3023656059275295125\n",
      "#6 inferred cache manifest type: application/vnd.oci.image.index.v1+json done\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 [ 1/21] FROM nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu@sha256:50343c616bf910e2a7651abb59db7833933e82cce64c3c4885f938d7e4af6155\n",
      "#7 resolve nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu@sha256:50343c616bf910e2a7651abb59db7833933e82cce64c3c4885f938d7e4af6155 0.1s done\n",
      "#7 DONE 0.1s\n",
      "\n",
      "#4 importing cache manifest from nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "#4 inferred cache manifest type: application/vnd.docker.distribution.manifest.list.v2+json done\n",
      "#4 DONE 0.7s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 28.73MB 0.2s done\n",
      "#5 DONE 0.2s\n",
      "\n",
      "#8 [ 9/21] WORKDIR /var/holoscan\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 2/21] RUN mkdir -p /etc/holoscan/         && mkdir -p /opt/holoscan/         && mkdir -p /var/holoscan         && mkdir -p /opt/holoscan/app         && mkdir -p /var/holoscan/input         && mkdir -p /var/holoscan/output\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 5/21] RUN useradd -rm -d /home/holoscan -s /bin/bash -g 1000 -G sudo -u 1000 holoscan\n",
      "#10 CACHED\n",
      "\n",
      "#11 [12/21] COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "#11 CACHED\n",
      "\n",
      "#12 [ 6/21] RUN chown -R holoscan /var/holoscan\n",
      "#12 CACHED\n",
      "\n",
      "#13 [11/21] RUN chmod +x /var/holoscan/tools\n",
      "#13 CACHED\n",
      "\n",
      "#14 [13/21] RUN pip install --upgrade pip\n",
      "#14 CACHED\n",
      "\n",
      "#15 [10/21] COPY ./tools /var/holoscan/tools\n",
      "#15 CACHED\n",
      "\n",
      "#16 [ 8/21] RUN chown -R holoscan /var/holoscan/output\n",
      "#16 CACHED\n",
      "\n",
      "#17 [ 4/21] RUN groupadd -f -g 1000 holoscan\n",
      "#17 CACHED\n",
      "\n",
      "#18 [ 3/21] RUN apt-get update     && apt-get install -y curl jq     && rm -rf /var/lib/apt/lists/*\n",
      "#18 CACHED\n",
      "\n",
      "#19 [ 7/21] RUN chown -R holoscan /var/holoscan/input\n",
      "#19 CACHED\n",
      "\n",
      "#20 [14/21] RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "#20 CACHED\n",
      "\n",
      "#21 [15/21] COPY ./monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "#21 DONE 0.3s\n",
      "\n",
      "#22 [16/21] RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "#22 0.682 Defaulting to user installation because normal site-packages is not writeable\n",
      "#22 0.793 Processing /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "#22 0.803 Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (1.23.5)\n",
      "#22 0.906 Collecting holoscan~=1.0 (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 0.971   Downloading holoscan-1.0.3-cp310-cp310-manylinux_2_35_x86_64.whl.metadata (4.1 kB)\n",
      "#22 1.044 Collecting colorama>=0.4.1 (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.050   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "#22 1.135 Collecting typeguard>=3.0.0 (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.139   Downloading typeguard-4.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "#22 1.248 Collecting pip==23.3.2 (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.254   Downloading pip-23.3.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "#22 1.269 Requirement already satisfied: cupy-cuda12x==12.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (12.2.0)\n",
      "#22 1.269 Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2.2.1)\n",
      "#22 1.271 Requirement already satisfied: python-on-whales==0.60.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (0.60.1)\n",
      "#22 1.272 Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.1.2)\n",
      "#22 1.272 Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (23.1)\n",
      "#22 1.273 Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (6.0)\n",
      "#22 1.274 Requirement already satisfied: requests==2.28.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2.28.2)\n",
      "#22 1.275 Requirement already satisfied: psutil==5.9.6 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (5.9.6)\n",
      "#22 1.308 Collecting wheel-axle-runtime<1.0 (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.313   Downloading wheel_axle_runtime-0.0.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "#22 1.347 Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x==12.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (0.8.2)\n",
      "#22 1.351 Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.1.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2.1.3)\n",
      "#22 1.366 Requirement already satisfied: pydantic<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (1.10.14)\n",
      "#22 1.367 Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (4.66.1)\n",
      "#22 1.367 Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (0.9.0)\n",
      "#22 1.369 Requirement already satisfied: typing-extensions in /home/holoscan/.local/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (4.10.0)\n",
      "#22 1.380 Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.3.2)\n",
      "#22 1.381 Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.6)\n",
      "#22 1.382 Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (1.26.18)\n",
      "#22 1.383 Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2023.11.17)\n",
      "#22 1.401 Requirement already satisfied: filelock in /home/holoscan/.local/lib/python3.10/site-packages (from wheel-axle-runtime<1.0->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.13.3)\n",
      "#22 1.443 Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (8.1.7)\n",
      "#22 1.490 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#22 1.516 Downloading holoscan-1.0.3-cp310-cp310-manylinux_2_35_x86_64.whl (33.6 MB)\n",
      "#22 1.982    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.6/33.6 MB 43.1 MB/s eta 0:00:00\n",
      "#22 1.989 Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
      "#22 2.032    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 53.0 MB/s eta 0:00:00\n",
      "#22 2.039 Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "#22 2.064 Downloading wheel_axle_runtime-0.0.5-py3-none-any.whl (12 kB)\n",
      "#22 2.417 Installing collected packages: wheel-axle-runtime, typeguard, pip, colorama, holoscan, monai-deploy-app-sdk\n",
      "#22 2.492   Attempting uninstall: pip\n",
      "#22 2.493     Found existing installation: pip 24.0\n",
      "#22 2.547     Uninstalling pip-24.0:\n",
      "#22 2.977       Successfully uninstalled pip-24.0\n",
      "#22 4.656 Successfully installed colorama-0.4.6 holoscan-1.0.3 monai-deploy-app-sdk-0.5.1+25.g31e4165.dirty pip-23.3.2 typeguard-4.2.1 wheel-axle-runtime-0.0.5\n",
      "#22 DONE 5.2s\n",
      "\n",
      "#23 [17/21] COPY ./models  /opt/holoscan/models\n",
      "#23 DONE 0.2s\n",
      "\n",
      "#24 [18/21] COPY ./map/app.json /etc/holoscan/app.json\n",
      "#24 DONE 0.1s\n",
      "\n",
      "#25 [19/21] COPY ./app.config /var/holoscan/app.yaml\n",
      "#25 DONE 0.1s\n",
      "\n",
      "#26 [20/21] COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "#26 DONE 0.1s\n",
      "\n",
      "#27 [21/21] COPY ./app /opt/holoscan/app\n",
      "#27 DONE 0.1s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 exporting layers\n",
      "#28 exporting layers 6.0s done\n",
      "#28 exporting manifest sha256:02c9015ef90dc072d10044946ce69d29e7dbd7e748cd98b56713e2a32f1823bc 0.0s done\n",
      "#28 exporting config sha256:26b7cd41adaba5d7700f104387d1c2d4b66829292de9fe656dff6f30ba20e56d 0.0s done\n",
      "#28 sending tarball\n",
      "#28 ...\n",
      "\n",
      "#29 importing to docker\n",
      "#29 loading layer 3c784a11874c 32.77kB / 125.57kB\n",
      "#29 loading layer 71abc17edeb9 557.06kB / 73.96MB\n",
      "#29 loading layer 71abc17edeb9 73.53MB / 73.96MB 2.0s\n",
      "#29 loading layer 8eee96e0be35 262.14kB / 25.59MB\n",
      "#29 loading layer 81dfa72eaf50 512B / 512B\n",
      "#29 loading layer c726a53666d2 697B / 697B\n",
      "#29 loading layer 0266dfb048c0 297B / 297B\n",
      "#29 loading layer d4a6edcf43fc 4.17kB / 4.17kB\n",
      "#29 loading layer 3c784a11874c 32.77kB / 125.57kB 5.0s done\n",
      "#29 loading layer 71abc17edeb9 73.53MB / 73.96MB 4.9s done\n",
      "#29 loading layer 8eee96e0be35 262.14kB / 25.59MB 2.8s done\n",
      "#29 loading layer 81dfa72eaf50 512B / 512B 2.2s done\n",
      "#29 loading layer c726a53666d2 697B / 697B 1.9s done\n",
      "#29 loading layer 0266dfb048c0 297B / 297B 1.5s done\n",
      "#29 loading layer d4a6edcf43fc 4.17kB / 4.17kB 1.1s done\n",
      "#29 DONE 5.0s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 sending tarball 65.8s done\n",
      "#28 DONE 72.0s\n",
      "\n",
      "#30 exporting cache to client directory\n",
      "#30 preparing build cache for export\n",
      "#30 writing layer sha256:00bb4c1319ba1a33ac3edcb3aa1240d8abcb8d0383c6267ed8028d3b6228a8a4\n",
      "#30 writing layer sha256:00bb4c1319ba1a33ac3edcb3aa1240d8abcb8d0383c6267ed8028d3b6228a8a4 done\n",
      "#30 writing layer sha256:014cff740c9ec6e9a30d0b859219a700ae880eb385d62095d348f5ea136d6015 done\n",
      "#30 writing layer sha256:03a29f2f0e10f79ee63a9017483d2f5c668ef6c02e479f306e7ec76203d450a9 0.0s done\n",
      "#30 writing layer sha256:0a1756432df4a4350712d8ae5c003f1526bd2180800b3ae6301cfc9ccf370254 done\n",
      "#30 writing layer sha256:0a77dcbd0e648ddc4f8e5230ade8fdb781d99e24fa4f13ca96a360c7f7e6751f done\n",
      "#30 writing layer sha256:0ec682bf99715a9f88631226f3749e2271b8b9f254528ef61f65ed829984821c done\n",
      "#30 writing layer sha256:1133dfcee0e851b490d17b3567f50c4b25ba5750da02ba4b3f3630655d0b1a7b done\n",
      "#30 writing layer sha256:1294b2835667d633f938174d9fecb18a60bbbebb6fb49788a1f939893a25d1af done\n",
      "#30 writing layer sha256:16a03c6e0373b62f9713416da0229bb7ce2585183141081d3ea8427ad2e84408 done\n",
      "#30 writing layer sha256:20d331454f5fb557f2692dfbdbe092c718fd2cb55d5db9d661b62228dacca5c2 done\n",
      "#30 writing layer sha256:2232aeb26b5b7ea57227e9a5b84da4fb229624d7bc976a5f7ce86d9c8653d277 done\n",
      "#30 writing layer sha256:238f69a43816e481f0295995fcf5fe74d59facf0f9f99734c8d0a2fb140630e0 done\n",
      "#30 writing layer sha256:2ad84487f9d4d31cd1e0a92697a5447dd241935253d036b272ef16d31620c1e7 done\n",
      "#30 writing layer sha256:2bb73464628bd4a136c4937f42d522c847bea86b2215ae734949e24c1caf450e done\n",
      "#30 writing layer sha256:3e3e04011ebdba380ab129f0ee390626cb2a600623815ca756340c18bedb9517 done\n",
      "#30 writing layer sha256:3f26964a76655c86158d285c57a280ad1e8f9c246a879db10773dc0218685fbc\n",
      "#30 writing layer sha256:3f26964a76655c86158d285c57a280ad1e8f9c246a879db10773dc0218685fbc 0.5s done\n",
      "#30 writing layer sha256:42619ce4a0c9e54cfd0ee41a8e5f27d58b3f51becabd1ac6de725fbe6c42b14a\n",
      "#30 writing layer sha256:42619ce4a0c9e54cfd0ee41a8e5f27d58b3f51becabd1ac6de725fbe6c42b14a done\n",
      "#30 writing layer sha256:43a21fb6c76bd2b3715cc09d9f8c3865dc61c51dd9e2327b429f5bec8fff85d1 done\n",
      "#30 writing layer sha256:49bdc9abf8a437ccff67cc11490ba52c976577992909856a86be872a34d3b950 done\n",
      "#30 writing layer sha256:4b691ba9f48b41eaa0c754feba8366f1c030464fcbc55eeffa6c86675990933a done\n",
      "#30 writing layer sha256:4d04a8db404f16c2704fa10739cb6745a0187713a21a6ef0deb34b48629b54c1 done\n",
      "#30 writing layer sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 done\n",
      "#30 writing layer sha256:5275a41be8f6691a490c0a15589e0910c73bf971169ad33a850ef570d37f63dd done\n",
      "#30 writing layer sha256:52fbfeaf78318d843054ce2bfb5bfc9f71278939a815f6035ab5b14573ad017b done\n",
      "#30 writing layer sha256:5792b18b6f162bae61ff5840cdb9e8567e6847a56ac886f940b47e7271c529a7 done\n",
      "#30 writing layer sha256:57f244836ad318f9bbb3b29856ae1a5b31038bfbb9b43d2466d51c199eb55041 done\n",
      "#30 writing layer sha256:5b5b131e0f20db4cb8e568b623a95f8fc16ed1c6b322a9366df70b59a881f24f done\n",
      "#30 writing layer sha256:5ccb787d371fd3697122101438ddd0f55b537832e9756d2c51ab1d8158710ac5 done\n",
      "#30 writing layer sha256:62452179df7c18e292f141d4aec29e6aba9ff8270c893731169fc6f41dc07631 done\n",
      "#30 writing layer sha256:6630c387f5f2115bca2e646fd0c2f64e1f3d5431c2e050abe607633883eda230 done\n",
      "#30 writing layer sha256:69af4b756272a77f683a8d118fd5ca55c03ad5f1bacc673b463f54d16b833da5 done\n",
      "#30 writing layer sha256:6ae1f1fb92c0cb2b6e219f687b08c8e511501a7af696c943ca20d119eba7cd02 done\n",
      "#30 writing layer sha256:6deb3d550b15a5e099c0b3d0cbc242e351722ca16c058d3a6c28ba1a02824d0f done\n",
      "#30 writing layer sha256:7386814d57100e2c7389fbf4e16f140f5c549d31434c62c3884a85a3ee5cd2a7 done\n",
      "#30 writing layer sha256:76e786eeb0fbc65fd083d100043e47d0c35ba615444907aa299e635d624bd426 0.0s done\n",
      "#30 writing layer sha256:77e0d1bb7a2b6458b8bd911429c58386169319dfb6ae2e9ae05f57571522d815 0.0s done\n",
      "#30 writing layer sha256:7852b73ea931e3a8d3287ee7ef3cf4bad068e44f046583bfc2b81336fb299284 done\n",
      "#30 writing layer sha256:7e73869c74822e4539e104a3d2aff853f4622cd0bb873576db1db53c9e91f621 done\n",
      "#30 writing layer sha256:7eae142b38745fe88962874372374deb672998600264a17e638c010b79e6b535 done\n",
      "#30 writing layer sha256:7f2e5ab2c599fa36698918d3e73c991d8616fff9037077cd230529e7cd1c5e0e done\n",
      "#30 writing layer sha256:82a3436133b2b17bb407c7fe488932aa0ca55411f23ab55c34a6134b287c6a27 done\n",
      "#30 writing layer sha256:82b1d37999127ab8412181eae2a5ff1c1a1854f9a76064512942ba9bde82afaa done\n",
      "#30 writing layer sha256:90eae6faa5cc5ba62f12c25915cdfb1a7a51abfba0d05cb5818c3f908f4e345f done\n",
      "#30 writing layer sha256:9ac855545fa90ed2bf3b388fdff9ef06ac9427b0c0fca07c9e59161983d8827e done\n",
      "#30 writing layer sha256:9d19ee268e0d7bcf6716e6658ee1b0384a71d6f2f9aa1ae2085610cf7c7b316f done\n",
      "#30 writing layer sha256:a10c8d7d2714eabf661d1f43a1ccb87a51748cbb9094d5bc0b713e2481b5d329 done\n",
      "#30 writing layer sha256:a1748eee9d376f97bd19225ba61dfada9986f063f4fc429e435f157abb629fc6 done\n",
      "#30 writing layer sha256:a68f4e0ec09ec3b78cb4cf8e4511d658e34e7b6f676d7806ad9703194ff17604 done\n",
      "#30 writing layer sha256:a8e4decc8f7289623b8fd7b9ba1ca555b5a755ebdbf81328d68209f148d9e602\n",
      "#30 writing layer sha256:a8e4decc8f7289623b8fd7b9ba1ca555b5a755ebdbf81328d68209f148d9e602 done\n",
      "#30 writing layer sha256:afde1c269453ce68a0f2b54c1ba8c5ecddeb18a19e5618a4acdef1f0fe3921af done\n",
      "#30 writing layer sha256:b48a5fafcaba74eb5d7e7665601509e2889285b50a04b5b639a23f8adc818157 done\n",
      "#30 writing layer sha256:ba9f7c75e4dd7942b944679995365aab766d3677da2e69e1d74472f471a484dd done\n",
      "#30 writing layer sha256:bafd0706f1969063f2baea22f5df92629ba228c67819e957f88b20582aaa4801\n",
      "#30 writing layer sha256:bafd0706f1969063f2baea22f5df92629ba228c67819e957f88b20582aaa4801 1.5s done\n",
      "#30 writing layer sha256:bdfc73b2a0fa11b4086677e117a2f9feb6b4ffeccb23a3d58a30543339607e31\n",
      "#30 writing layer sha256:bdfc73b2a0fa11b4086677e117a2f9feb6b4ffeccb23a3d58a30543339607e31 done\n",
      "#30 writing layer sha256:c175bb235295e50de2961fa1e1a2235c57e6eba723a914287dfc26d3be0eac11 done\n",
      "#30 writing layer sha256:c2a80b194dd0ff43e8e6ea838efe3b6f24371797b498b6d2d7ac53fb9d4aee8b done\n",
      "#30 writing layer sha256:c6e0f549352b7817454c6c4540b863766f732e9216158288017cfcb19cd91bef 0.0s done\n",
      "#30 writing layer sha256:c98533d2908f36a5e9b52faae83809b3b6865b50e90e2817308acfc64cd3655f done\n",
      "#30 writing layer sha256:cb6c95b33bc30dd285c5b3cf99a05281b8f12decae1c932ab64bd58f56354021 done\n",
      "#30 writing layer sha256:d7da5c5e9a40c476c4b3188a845e3276dedfd752e015ea5113df5af64d4d43f7 done\n",
      "#30 writing layer sha256:e4aedc686433c0ec5e676e6cc54a164345f7016aa0eb714f00c07e11664a1168 done\n",
      "#30 writing layer sha256:e4e14fa6c90d19eb19aad3f52f9cd59a25c44007ba201741ac7cbff722837883 done\n",
      "#30 writing layer sha256:e8acb678f16bc0c369d5cf9c184f2d3a1c773986816526e5e3e9c0354f7e757f done\n",
      "#30 writing layer sha256:e9225f7ab6606813ec9acba98a064826ebfd6713a9645a58cd068538af1ecddb done\n",
      "#30 writing layer sha256:f33546e75bf1a7d9dc9e21b9a2c54c9d09b24790ad7a4192a8509002ceb14688 done\n",
      "#30 writing layer sha256:f608e2fbff86e98627b7e462057e7d2416522096d73fe4664b82fe6ce8a4047d done\n",
      "#30 writing layer sha256:f7702077ced42a1ee35e7f5e45f72634328ff3bcfe3f57735ba80baa5ec45daf done\n",
      "#30 writing layer sha256:fa66a49172c6e821a1bace57c007c01da10cbc61507c44f8cdfeed8c4e5febab done\n",
      "#30 writing layer sha256:fc1f60b32aa696c9cfeacbee0e2c0aeefd8331e0a38fcd082b60ae33b67e34e4 0.0s done\n",
      "#30 writing config sha256:b2150835373b386791df4e482a3f33750ce9ec1d81393ee061a6d9c06dc8d52a 0.0s done\n",
      "#30 preparing build cache for export 2.8s done\n",
      "#30 writing cache manifest sha256:ed8fc8e6d14dafb96aed8205ce985667c75f419d2bf7ce449e533b415b01b699 0.0s done\n",
      "#30 DONE 2.8s\n",
      "[2024-04-10 16:25:16,137] [INFO] (packager) - Build Summary:\n",
      "\n",
      "Platform: x64-workstation/dgpu\n",
      "    Status:     Succeeded\n",
      "    Docker Tag: mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Tarball:    None\n"
     ]
    }
   ],
   "source": [
    "tag_prefix = \"mednist_app\"\n",
    "\n",
    "!monai-deploy package \"source/examples/apps/mednist_classifier_monaideploy/mednist_classifier_monaideploy.py\" -m {models_folder} -c \"source/examples/apps/mednist_classifier_monaideploy/app.yaml\" -t {tag_prefix}:1.0 --platform x64-workstation -l DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MAP Docker image is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mednist_app-x64-workstation-dgpu-linux-amd64                                              1.0                        26b7cd41adab   About a minute ago   17.5GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep {tag_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to display and inspect the MAP manifests by running the container with the `show` command.\n",
    "Furthermore, we can also extract the manifests and other contents in the MAP by using the `extract` command while mapping specific folder to the host's (we know that our MAP is compliant and supports these commands).\n",
    "\n",
    ":::{note}\n",
    "The host folder for storing the extracted content must first be created by the user, and if it has been created by Docker on running the container, the folder needs to be deleted and re-created.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display manifests and extract MAP contents to the host folder, ./export\n",
      "\n",
      "============================== app.json ==============================\n",
      "{\n",
      "  \"apiVersion\": \"1.0.0\",\n",
      "  \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app/mednist_classifier_monaideploy.py\\\"]\",\n",
      "  \"environment\": {\n",
      "    \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "    \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "    \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "    \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "    \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "    \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "    \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "    \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "    \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "    \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "  },\n",
      "  \"input\": {\n",
      "    \"path\": \"input/\",\n",
      "    \"formats\": null\n",
      "  },\n",
      "  \"liveness\": null,\n",
      "  \"output\": {\n",
      "    \"path\": \"output/\",\n",
      "    \"formats\": null\n",
      "  },\n",
      "  \"readiness\": null,\n",
      "  \"sdk\": \"monai-deploy\",\n",
      "  \"sdkVersion\": \"0.5.1\",\n",
      "  \"timeout\": 0,\n",
      "  \"version\": 1,\n",
      "  \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "\n",
      "============================== pkg.json ==============================\n",
      "{\n",
      "  \"apiVersion\": \"1.0.0\",\n",
      "  \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "  \"modelRoot\": \"/opt/holoscan/models\",\n",
      "  \"models\": {\n",
      "    \"model\": \"/opt/holoscan/models/model\"\n",
      "  },\n",
      "  \"resources\": {\n",
      "    \"cpu\": 1,\n",
      "    \"gpu\": 1,\n",
      "    \"memory\": \"1Gi\",\n",
      "    \"gpuMemory\": \"1Gi\"\n",
      "  },\n",
      "  \"version\": 1,\n",
      "  \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "\n",
      "2024-04-10 23:25:19 [INFO] Copying application from /opt/holoscan/app to /var/run/holoscan/export/app\n",
      "\n",
      "2024-04-10 23:25:19 [INFO] Copying application manifest file from /etc/holoscan/app.json to /var/run/holoscan/export/config/app.json\n",
      "2024-04-10 23:25:19 [INFO] Copying pkg manifest file from /etc/holoscan/pkg.json to /var/run/holoscan/export/config/pkg.json\n",
      "2024-04-10 23:25:19 [INFO] Copying application configuration from /var/holoscan/app.yaml to /var/run/holoscan/export/config/app.yaml\n",
      "\n",
      "2024-04-10 23:25:19 [INFO] Copying models from /opt/holoscan/models to /var/run/holoscan/export/models\n",
      "\n",
      "2024-04-10 23:25:19 [INFO] Copying documentation from /opt/holoscan/docs/ to /var/run/holoscan/export/docs\n",
      "2024-04-10 23:25:19 [INFO] '/opt/holoscan/docs/' cannot be found.\n",
      "\n",
      "app  config  models\n"
     ]
    }
   ],
   "source": [
    "!echo \"Display manifests and extract MAP contents to the host folder, ./export\"\n",
    "!docker run --rm {tag_prefix}-x64-workstation-dgpu-linux-amd64:1.0 show\n",
    "!rm -rf `pwd`/export && mkdir -p `pwd`/export\n",
    "!docker run --rm -v `pwd`/export/:/var/run/holoscan/export/ {tag_prefix}-x64-workstation-dgpu-linux-amd64:1.0 extract\n",
    "!ls `pwd`/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing packaged app locally\n",
    "\n",
    "The packaged app can be run locally through [MONAI Application Runner](/developing_with_sdk/executing_packaged_app_locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 16:25:20,790] [INFO] (runner) - Checking dependencies...\n",
      "[2024-04-10 16:25:20,790] [INFO] (runner) - --> Verifying if \"docker\" is installed...\n",
      "\n",
      "[2024-04-10 16:25:20,791] [INFO] (runner) - --> Verifying if \"docker-buildx\" is installed...\n",
      "\n",
      "[2024-04-10 16:25:20,791] [INFO] (runner) - --> Verifying if \"mednist_app-x64-workstation-dgpu-linux-amd64:1.0\" is available...\n",
      "\n",
      "[2024-04-10 16:25:20,871] [INFO] (runner) - Reading HAP/MAP manifest...\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.56kB to /tmp/tmpryp430i1/app.json\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.05kB to /tmp/tmpryp430i1/pkg.json\n",
      "[2024-04-10 16:25:21,124] [INFO] (runner) - --> Verifying if \"nvidia-ctk\" is installed...\n",
      "\n",
      "[2024-04-10 16:25:21,124] [INFO] (runner) - --> Verifying \"nvidia-ctk\" version...\n",
      "\n",
      "[2024-04-10 16:25:21,410] [INFO] (common) - Launching container (7cf522bd06c4) using image 'mednist_app-x64-workstation-dgpu-linux-amd64:1.0'...\n",
      "    container name:      dazzling_hugle\n",
      "    host name:           mingq-dt\n",
      "    network:             host\n",
      "    user:                1000:1000\n",
      "    ulimits:             memlock=-1:-1, stack=67108864:67108864\n",
      "    cap_add:             CAP_SYS_PTRACE\n",
      "    ipc mode:            host\n",
      "    shared memory size:  67108864\n",
      "    devices:             \n",
      "    group_add:           44\n",
      "2024-04-10 23:25:22 [INFO] Launching application python3 /opt/holoscan/app/mednist_classifier_monaideploy.py ...\n",
      "\n",
      "[2024-04-10 23:25:31,408] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=['/opt/holoscan/app/mednist_classifier_monaideploy.py'])\n",
      "\n",
      "[2024-04-10 23:25:31,419] [INFO] (root) - AppContext object: AppContext(input_path=/var/holoscan/input, output_path=/var/holoscan/output, model_path=/opt/holoscan/models, workdir=/var/holoscan)\n",
      "\n",
      "[info] [app_driver.cpp:1161] Launching the driver/health checking service\n",
      "\n",
      "[info] [gxf_executor.cpp:211] Creating context\n",
      "\n",
      "[info] [server.cpp:87] Health checking server listening on 0.0.0.0:8777\n",
      "\n",
      "[info] [gxf_executor.cpp:1674] Loading extensions from configs...\n",
      "\n",
      "[info] [gxf_executor.cpp:1864] Activating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1894] Running Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1896] Waiting for completion...\n",
      "\n",
      "[info] [gxf_executor.cpp:1897] Graph execution waiting. Fragment: \n",
      "\n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "\n",
      "/home/holoscan/.local/lib/python3.10/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)\n",
      "\n",
      "[2024-04-10 23:25:34,063] [INFO] (root) - Finished writing DICOM instance to file /var/holoscan/output/1.2.826.0.1.3680043.8.498.23303108191806495091599558367348667557.dcm\n",
      "\n",
      "[2024-04-10 23:25:34,064] [INFO] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - DICOM SOP instance saved in /var/holoscan/output/1.2.826.0.1.3680043.8.498.23303108191806495091599558367348667557.dcm\n",
      "\n",
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "\n",
      "[info] [gxf_executor.cpp:1906] Graph execution deactivating. Fragment: \n",
      "\n",
      "[info] [gxf_executor.cpp:1907] Deactivating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1910] Graph execution finished. Fragment: \n",
      "\n",
      "[info] [gxf_executor.cpp:230] Destroying context\n",
      "\n",
      "AbdomenCT\n",
      "\n",
      "[2024-04-10 16:25:35,771] [INFO] (common) - Container 'dazzling_hugle'(7cf522bd06c4) exited.\n"
     ]
    }
   ],
   "source": [
    "# Clear the output folder and run the MAP. The input is expected to be a folder.\n",
    "!rm -rf {ouput_folder}\n",
    "!monai-deploy run -i $HOLOSCAN_INPUT_PATH -o $HOLOSCAN_OUTPUT_PATH mednist_app-x64-workstation-dgpu-linux-amd64:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat {output_folder}/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Packaging Application with MONAI Deploy App SDK\n",
    "\n",
    "In the following sections we will discuss the details of buildng the application that was packaged and run above.\n",
    "\n",
    "Based on the Torchscript model(`classifier.zip`), we will implement an application that process an input Jpeg image and write the prediction(classification) result as JSON file(`output.json`).\n",
    "\n",
    "In our inference application, we will define two operators:\n",
    "\n",
    "1. `LoadPILOperator` - Load a JPEG image from the input path and pass the loaded image object to the next operator.\n",
    "    - **Input**: a file path (`Path`)\n",
    "    - **Output**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "2. `MedNISTClassifierOperator` - Pre-transform the given image by using MONAI's `Compose` class, feed to the Torchscript model (`classifier.zip`), and write the prediction into JSON file(`output.json`)\n",
    "    - Pre-transforms consist of three transforms -- `EnsureChannelFirst`, `ScaleIntensity`, and `EnsureType`.\n",
    "    - **Input**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output**: a folder path that the prediction result(`output.json`) would be written (`Path`)\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/1928522/133868503-46671f0a-7741-4f9d-aefa-83e95e9a5f84.png\" alt=\"Workflow\" style=\"width: 600px;margin-left:auto;margin-right:auto;\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators and define `MEDNIST_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import EnsureChannelFirst, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Operator classes\n",
    "\n",
    "#### LoadPILOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MedNISTClassifierOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([EnsureChannelFirst(channel_dim=\"no_channel\"), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class inheriting `Application` class.\n",
    "\n",
    "`LoadPILOperator` is connected to `MedNISTClassifierOperator` by using `self.add_flow()` in `compose()` method of `App`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        app_context = Application.init_app_context({})  # Do not pass argv in Jupyter Notebook\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing app locally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute the app in the Jupyter notebook. Before doing so, we also need to clean the output folder which was created by running the packaged containerizd app in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-10 16:25:39,884] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=[])\n",
      "[2024-04-10 16:25:39,898] [INFO] (root) - AppContext object: AppContext(input_path=input, output_path=output, model_path=models, workdir=)\n",
      "[info] [gxf_executor.cpp:211] Creating context\n",
      "[info] [gxf_executor.cpp:1674] Loading extensions from configs...\n",
      "[info] [gxf_executor.cpp:1864] Activating Graph...\n",
      "[info] [gxf_executor.cpp:1894] Running Graph...\n",
      "[info] [gxf_executor.cpp:1896] Waiting for completion...\n",
      "[info] [gxf_executor.cpp:1897] Graph execution waiting. Fragment: \n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "[2024-04-10 16:25:42,470] [INFO] (root) - Finished writing DICOM instance to file output/1.2.826.0.1.3680043.8.498.71636533308287156684391922232397043508.dcm\n",
      "[2024-04-10 16:25:42,472] [INFO] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - DICOM SOP instance saved in output/1.2.826.0.1.3680043.8.498.71636533308287156684391922232397043508.dcm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbdomenCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[info] [gxf_executor.cpp:1906] Graph execution deactivating. Fragment: \n",
      "[info] [gxf_executor.cpp:1907] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:1910] Graph execution finished. Fragment: \n",
      "[info] [gxf_executor.cpp:230] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "app = App().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat $HOLOSCAN_OUTPUT_PATH/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the whole application as a file(`mednist_classifier_monaideploy.py`) by concatenating code above, then add the following lines:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p mednist_app && rm -rf mednist_app/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/mednist_classifier_monaideploy.py\n",
    "\n",
    "# Copyright 2021-2023 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import EnsureChannelFirst, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([EnsureChannelFirst(channel_dim=\"no_channel\"), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "\n",
    "# @md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        # Use Commandline options over environment variables to init context.\n",
    "        app_context = Application.init_app_context(self.argv)\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's execute the app on the command line.\n",
    "\n",
    ":::{note}\n",
    "Since the environment variables have been set and contain the correct paths, it is not necessary to provide the command line options on running the application, though the following demonstrates the use of the options.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 16:25:46,989] [INFO] (root) - Parsed args: Namespace(log_level='DEBUG', input=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/input'), output=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output'), model=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models'), workdir=None, argv=['mednist_app/mednist_classifier_monaideploy.py', '-i', 'input', '-o', 'output', '-m', 'models', '-l', 'DEBUG'])\n",
      "[2024-04-10 16:25:46,993] [INFO] (root) - AppContext object: AppContext(input_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/input, output_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output, model_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models, workdir=)\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:211] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1674] Loading extensions from configs...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1864] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1894] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1896] Waiting for completion...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1897] Graph execution waiting. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)\n",
      "AbdomenCT\n",
      "[2024-04-10 16:25:49,239] [DEBUG] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - Writing DICOM object...\n",
      "\n",
      "[2024-04-10 16:25:49,239] [DEBUG] (root) - Writing DICOM common modules...\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "[2024-04-10 16:25:49,242] [DEBUG] (root) - DICOM common modules written:\n",
      "Dataset.file_meta -------------------------------\n",
      "(0002, 0000) File Meta Information Group Length  UL: 198\n",
      "(0002, 0001) File Meta Information Version       OB: b'01'\n",
      "(0002, 0002) Media Storage SOP Class UID         UI: Basic Text SR Storage\n",
      "(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.826.0.1.3680043.8.498.10219575881227434107206425977009168141\n",
      "(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n",
      "(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n",
      "(0002, 0013) Implementation Version Name         SH: '0.5.1+25.g31e41'\n",
      "-------------------------------------------------\n",
      "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008, 0012) Instance Creation Date              DA: '20240410'\n",
      "(0008, 0013) Instance Creation Time              TM: '162549'\n",
      "(0008, 0016) SOP Class UID                       UI: Basic Text SR Storage\n",
      "(0008, 0018) SOP Instance UID                    UI: 1.2.826.0.1.3680043.8.498.10219575881227434107206425977009168141\n",
      "(0008, 0020) Study Date                          DA: '20240410'\n",
      "(0008, 0021) Series Date                         DA: '20240410'\n",
      "(0008, 0023) Content Date                        DA: '20240410'\n",
      "(0008, 002a) Acquisition DateTime                DT: '20240410162549'\n",
      "(0008, 0030) Study Time                          TM: '162549'\n",
      "(0008, 0031) Series Time                         TM: '162549'\n",
      "(0008, 0033) Content Time                        TM: '162549'\n",
      "(0008, 0050) Accession Number                    SH: ''\n",
      "(0008, 0060) Modality                            CS: 'SR'\n",
      "(0008, 0070) Manufacturer                        LO: 'MOANI Deploy App SDK'\n",
      "(0008, 0090) Referring Physician's Name          PN: ''\n",
      "(0008, 0201) Timezone Offset From UTC            SH: '-0700'\n",
      "(0008, 1030) Study Description                   LO: 'AI results.'\n",
      "(0008, 103e) Series Description                  LO: 'CAUTION: Not for Diagnostic Use, for research use only.'\n",
      "(0008, 1090) Manufacturer's Model Name           LO: 'DICOM SR Writer'\n",
      "(0010, 0010) Patient's Name                      PN: ''\n",
      "(0010, 0020) Patient ID                          LO: ''\n",
      "(0010, 0021) Issuer of Patient ID                LO: ''\n",
      "(0010, 0030) Patient's Birth Date                DA: ''\n",
      "(0010, 0040) Patient's Sex                       CS: ''\n",
      "(0018, 0015) Body Part Examined                  CS: ''\n",
      "(0018, 1020) Software Versions                   LO: '0.5.1+25.g31e41'\n",
      "(0018, a001)  Contributing Equipment Sequence  1 item(s) ---- \n",
      "   (0008, 0070) Manufacturer                        LO: 'MONAI WG Trainer'\n",
      "   (0008, 1090) Manufacturer's Model Name           LO: 'MEDNIST Classifier'\n",
      "   (0018, 1002) Device UID                          UI: xyz\n",
      "   (0018, 1020) Software Versions                   LO: '0.1'\n",
      "   (0040, a170)  Purpose of Reference Code Sequence  1 item(s) ---- \n",
      "      (0008, 0100) Code Value                          SH: 'Newcode1'\n",
      "      (0008, 0102) Coding Scheme Designator            SH: '99IHE'\n",
      "      (0008, 0104) Code Meaning                        LO: '\"Processing Algorithm'\n",
      "      ---------\n",
      "   ---------\n",
      "(0020, 000d) Study Instance UID                  UI: 1.2.826.0.1.3680043.8.498.99895869772559254532078552857455521250\n",
      "(0020, 000e) Series Instance UID                 UI: 1.2.826.0.1.3680043.8.498.11097411469528473023282906105369639673\n",
      "(0020, 0010) Study ID                            SH: '1'\n",
      "(0020, 0011) Series Number                       IS: '7823'\n",
      "(0020, 0013) Instance Number                     IS: '1'\n",
      "(0040, 1001) Requested Procedure ID              SH: ''\n",
      "[2024-04-10 16:25:49,242] [DEBUG] (root) - DICOM dataset to be written:Dataset.file_meta -------------------------------\n",
      "(0002, 0000) File Meta Information Group Length  UL: 198\n",
      "(0002, 0001) File Meta Information Version       OB: b'01'\n",
      "(0002, 0002) Media Storage SOP Class UID         UI: Basic Text SR Storage\n",
      "(0002, 0003) Media Storage SOP Instance UID      UI: 1.2.826.0.1.3680043.8.498.10219575881227434107206425977009168141\n",
      "(0002, 0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n",
      "(0002, 0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n",
      "(0002, 0013) Implementation Version Name         SH: '0.5.1+25.g31e41'\n",
      "-------------------------------------------------\n",
      "(0008, 0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008, 0012) Instance Creation Date              DA: '20240410'\n",
      "(0008, 0013) Instance Creation Time              TM: '162549'\n",
      "(0008, 0016) SOP Class UID                       UI: Basic Text SR Storage\n",
      "(0008, 0018) SOP Instance UID                    UI: 1.2.826.0.1.3680043.8.498.10219575881227434107206425977009168141\n",
      "(0008, 0020) Study Date                          DA: '20240410'\n",
      "(0008, 0021) Series Date                         DA: '20240410'\n",
      "(0008, 0023) Content Date                        DA: '20240410'\n",
      "(0008, 002a) Acquisition DateTime                DT: '20240410162549'\n",
      "(0008, 0030) Study Time                          TM: '162549'\n",
      "(0008, 0031) Series Time                         TM: '162549'\n",
      "(0008, 0033) Content Time                        TM: '162549'\n",
      "(0008, 0050) Accession Number                    SH: ''\n",
      "(0008, 0060) Modality                            CS: 'SR'\n",
      "(0008, 0070) Manufacturer                        LO: 'MOANI Deploy App SDK'\n",
      "(0008, 0090) Referring Physician's Name          PN: ''\n",
      "(0008, 0201) Timezone Offset From UTC            SH: '-0700'\n",
      "(0008, 1030) Study Description                   LO: 'AI results.'\n",
      "(0008, 103e) Series Description                  LO: 'Not for clinical use. The result is for research use only.'\n",
      "(0008, 1090) Manufacturer's Model Name           LO: 'DICOM SR Writer'\n",
      "(0010, 0010) Patient's Name                      PN: ''\n",
      "(0010, 0020) Patient ID                          LO: ''\n",
      "(0010, 0021) Issuer of Patient ID                LO: ''\n",
      "(0010, 0030) Patient's Birth Date                DA: ''\n",
      "(0010, 0040) Patient's Sex                       CS: ''\n",
      "(0018, 0015) Body Part Examined                  CS: ''\n",
      "(0018, 1020) Software Versions                   LO: '0.5.1+25.g31e41'\n",
      "(0018, a001)  Contributing Equipment Sequence  1 item(s) ---- \n",
      "   (0008, 0070) Manufacturer                        LO: 'MONAI WG Trainer'\n",
      "   (0008, 1090) Manufacturer's Model Name           LO: 'MEDNIST Classifier'\n",
      "   (0018, 1002) Device UID                          UI: xyz\n",
      "   (0018, 1020) Software Versions                   LO: '0.1'\n",
      "   (0040, a170)  Purpose of Reference Code Sequence  1 item(s) ---- \n",
      "      (0008, 0100) Code Value                          SH: 'Newcode1'\n",
      "      (0008, 0102) Coding Scheme Designator            SH: '99IHE'\n",
      "      (0008, 0104) Code Meaning                        LO: '\"Processing Algorithm'\n",
      "      ---------\n",
      "   ---------\n",
      "(0020, 000d) Study Instance UID                  UI: 1.2.826.0.1.3680043.8.498.99895869772559254532078552857455521250\n",
      "(0020, 000e) Series Instance UID                 UI: 1.2.826.0.1.3680043.8.498.11097411469528473023282906105369639673\n",
      "(0020, 0010) Study ID                            SH: '1'\n",
      "(0020, 0011) Series Number                       IS: '7823'\n",
      "(0020, 0013) Instance Number                     IS: '1'\n",
      "(0040, 1001) Requested Procedure ID              SH: ''\n",
      "(0040, a040) Value Type                          CS: 'CONTAINER'\n",
      "(0040, a043)  Concept Name Code Sequence  1 item(s) ---- \n",
      "   (0008, 0100) Code Value                          SH: '18748-4'\n",
      "   (0008, 0102) Coding Scheme Designator            SH: 'LN'\n",
      "   (0008, 0104) Code Meaning                        LO: 'Diagnostic Imaging Report'\n",
      "   ---------\n",
      "(0040, a050) Continuity Of Content               CS: 'SEPARATE'\n",
      "(0040, a493) Verification Flag                   CS: 'UNVERIFIED'\n",
      "(0040, a730)  Content Sequence  1 item(s) ---- \n",
      "   (0040, a010) Relationship Type                   CS: 'CONTAINS'\n",
      "   (0040, a040) Value Type                          CS: 'TEXT'\n",
      "   (0040, a043)  Concept Name Code Sequence  1 item(s) ---- \n",
      "      (0008, 0100) Code Value                          SH: '111412'\n",
      "      (0008, 0102) Coding Scheme Designator            SH: 'DCM'\n",
      "      (0008, 0104) Code Meaning                        LO: 'Narrative Summary'\n",
      "      ---------\n",
      "   (0040, a160) Text Value                          UT: 'AbdomenCT'\n",
      "   ---------\n",
      "[2024-04-10 16:25:49,245] [INFO] (root) - Finished writing DICOM instance to file /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/1.2.826.0.1.3680043.8.498.10219575881227434107206425977009168141.dcm\n",
      "[2024-04-10 16:25:49,246] [INFO] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - DICOM SOP instance saved in /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/1.2.826.0.1.3680043.8.498.10219575881227434107206425977009168141.dcm\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1906] Graph execution deactivating. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1907] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1910] Graph execution finished. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:230] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!python \"mednist_app/mednist_classifier_monaideploy.py\" -i {input_folder} -o {output_folder} -m {models_folder} -l DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat {output_folder}/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional file required for packaging the app (creating MAP Docker image)\n",
    "\n",
    "In this version of the App SDK, we need to write out the configuration yaml file as well as the package requirements file, in the application folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/app.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/app.yaml\n",
    "%YAML 1.2\n",
    "---\n",
    "application:\n",
    "  title: MONAI Deploy App Package - MedNIST Classifier App\n",
    "  version: 1.0\n",
    "  inputFormats: [\"file\"]\n",
    "  outputFormats: [\"file\"]\n",
    "\n",
    "resources:\n",
    "  cpu: 1\n",
    "  gpu: 1\n",
    "  memory: 1Gi\n",
    "  gpuMemory: 1Gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/requirements.txt\n",
    "monai>=1.2.0\n",
    "Pillow>=8.4.0\n",
    "pydicom>=2.3.0\n",
    "highdicom>=0.18.2\n",
    "SimpleITK>=2.0.0\n",
    "setuptools>=59.5.0 # for pkg_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we have built the application and prepared all necessary files for create the MONAI Application Package (MAP)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
