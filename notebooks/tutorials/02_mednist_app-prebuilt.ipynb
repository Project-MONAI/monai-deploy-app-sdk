{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a MedNIST Classifier App with MONAI Deploy App SDK (Prebuilt Model)\n",
    "\n",
    "This tutorial demos the process of packaging up a trained model using MONAI Deploy App SDK into an application which can be run as a local program performing inference, and an application package in Docker form for containerized workflow execution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the github project (the latest version of the main branch only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'source'...\n",
      "remote: Enumerating objects: 289, done.\u001b[K\n",
      "remote: Counting objects: 100% (289/289), done.\u001b[K\n",
      "remote: Compressing objects: 100% (255/255), done.\u001b[K\n",
      "remote: Total 289 (delta 60), reused 112 (delta 20), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (289/289), 1.22 MiB | 13.04 MiB/s, done.\n",
      "Resolving deltas: 100% (60/60), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf source \\\n",
    " && git clone --branch main --depth 1 https://github.com/Project-MONAI/monai-deploy-app-sdk.git source \\\n",
    " && rm -rf source/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_settings.sh  mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "!ls source/examples/apps/mednist_classifier_monaideploy/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install monai-deploy-app-sdk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai-deploy-app-sdk in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (0.4.0+75.g16a6784.dirty)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from monai-deploy-app-sdk) (1.24.1)\n",
      "Requirement already satisfied: networkx>=2.4 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from monai-deploy-app-sdk) (2.8.3)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from monai-deploy-app-sdk) (0.4.6)\n",
      "Requirement already satisfied: typeguard>=3.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from monai-deploy-app-sdk) (4.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from typeguard>=3.0.0->monai-deploy-app-sdk) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from typeguard>=3.0.0->monai-deploy-app-sdk) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from importlib-metadata>=3.6->typeguard>=3.0.0->monai-deploy-app-sdk) (3.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai-deploy-app-sdk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (1.1.0)\n",
      "Requirement already satisfied: Pillow in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (8.4.0)\n",
      "Requirement already satisfied: torch>=1.8 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from monai) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from monai) (1.24.1)\n",
      "Requirement already satisfied: typing-extensions in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from torch>=1.8->monai) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from torch>=1.8->monai) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from torch>=1.8->monai) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from torch>=1.8->monai) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from torch>=1.8->monai) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->monai) (68.0.0)\n",
      "Requirement already satisfied: wheel in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8->monai) (0.40.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai Pillow # for MONAI transforms and Pillow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/Extract mednist_classifier_data.zip from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (4.6.4)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (3.10.0)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: six in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (4.12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\n",
      "To: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/mednist_classifier_data.zip\n",
      "100%|██████████████████████████████████████| 28.6M/28.6M [00:00<00:00, 38.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Download mednist_classifier_data.zip\n",
    "!pip install gdown \n",
    "!gdown \"https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mednist_classifier_data.zip\n",
      " extracting: classifier.zip          \n",
      " extracting: input/AbdomenCT_007000.jpeg  \n"
     ]
    }
   ],
   "source": [
    "# After downloading mednist_classifier_data.zip from the web browser or using gdown,\n",
    "!unzip -o \"mednist_classifier_data.zip\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment variables\n",
    "The application uses well-known enviornment variables for the input/output data path, working dir, as well as AI model file path if applicable. Defaults are used if these environment variable are absent.\n",
    "\n",
    "Set the environment variables corresponding to the extracted data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=input\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n",
      "env: HOLOSCAN_MODEL_PATH=classifier.zip\n",
      "AbdomenCT_007000.jpeg\n",
      "classifier.zip\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH input\n",
    "%env HOLOSCAN_OUTPUT_PATH output\n",
    "%env HOLOSCAN_MODEL_PATH classifier.zip\n",
    "%ls $HOLOSCAN_INPUT_PATH\n",
    "%ls $HOLOSCAN_MODEL_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Packaging Application with MONAI Deploy App SDK\n",
    "\n",
    "Based on the Torchscript model(`classifier.zip`), we will implement an application that process an input Jpeg image and write the prediction(classification) result as JSON file(`output.json`).\n",
    "\n",
    "In our inference application, we will define two operators:\n",
    "\n",
    "1. `LoadPILOperator` - Load a JPEG image from the input path and pass the loaded image object to the next operator.\n",
    "    - **Input**: a file path (`Path`)\n",
    "    - **Output**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "2. `MedNISTClassifierOperator` - Pre-transform the given image by using MONAI's `Compose` class, feed to the Torchscript model (`classifier.zip`), and write the prediction into JSON file(`output.json`)\n",
    "    - Pre-transforms consist of three transforms -- `AddChannel`, `ScaleIntensity`, and `EnsureType`.\n",
    "    - **Input**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output**: a folder path that the prediction result(`output.json`) would be written (`Path`)\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/1928522/133868503-46671f0a-7741-4f9d-aefa-83e95e9a5f84.png\" alt=\"Workflow\" style=\"width: 600px;margin-left:auto;margin-right:auto;\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators and define `MEDNIST_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Operator classes\n",
    "\n",
    "#### LoadPILOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MedNISTClassifierOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class inheriting `Application` class.\n",
    "\n",
    "`LoadPILOperator` is connected to `MedNISTClassifierOperator` by using `self.add_flow()` in `compose()` method of `App`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        app_context = AppContext({})  # Let it figure out all the attributes without overriding\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing app locally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute the app in the Jupyter notebook. Before doing so, we also need to clean the output folder which was created by running the packaged containerizd app in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] [gxf_executor.cpp:182] Creating context\n",
      "[info] [gxf_executor.cpp:1576] Loading extensions from configs...\n",
      "[info] [gxf_executor.cpp:1718] Activating Graph...\n",
      "[info] [gxf_executor.cpp:1748] Running Graph...\n",
      "[info] [gxf_executor.cpp:1750] Waiting for completion...\n",
      "[info] [gxf_executor.cpp:1751] Graph execution waiting. Fragment: \n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbdomenCT\n",
      "2023-07-18 19:41:14,113 - Finished writing DICOM instance to file output/1.2.826.0.1.3680043.8.498.11217327959761158158717529440256044057.dcm\n",
      "2023-07-18 19:41:14,116 - DICOM SOP instance saved in output/1.2.826.0.1.3680043.8.498.11217327959761158158717529440256044057.dcm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/pydicom/valuerep.py:290: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[info] [gxf_executor.cpp:1760] Graph execution deactivating. Fragment: \n",
      "[info] [gxf_executor.cpp:1761] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:1764] Graph execution finished. Fragment: \n"
     ]
    }
   ],
   "source": [
    "app = App()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the whole application as a file(`mednist_classifier_monaideploy.py`) by concatenating code above, then add the following lines:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_classifier_monaideploy.py\n",
    "\n",
    "# Copyright 2021-2023 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "\n",
    "# @md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        app_context = AppContext({})  # Let it figure out all the attributes without overriding\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's execute the app on the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:182] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1576] Loading extensions from configs...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1718] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1748] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1750] Waiting for completion...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1751] Graph execution waiting. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:107: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "AbdomenCT\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/pydicom/valuerep.py:290: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "2023-07-18 19:41:21,335 - Finished writing DICOM instance to file output/1.2.826.0.1.3680043.8.498.11580941046207068535187781766809028999.dcm\n",
      "2023-07-18 19:41:21,336 - DICOM SOP instance saved in output/1.2.826.0.1.3680043.8.498.11580941046207068535187781766809028999.dcm\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1760] Graph execution deactivating. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1761] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1764] Graph execution finished. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:201] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!python \"mednist_classifier_monaideploy.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package app (creating MAP Docker image)\n",
    "\n",
    "This assumes that nvidia docker is installed in the local machine.\n",
    "\n",
    "Please see https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#docker to install nvidia-docker2.\n",
    "\n",
    "Use `-l DEBUG` option to see progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending release of the Holoscan packager\n"
     ]
    }
   ],
   "source": [
    "!echo \"Pending release of the Holoscan packager\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the app with docker image and input file locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pending completion of the Holoscan package runner\n"
     ]
    }
   ],
   "source": [
    "!echo \"Pending completion of the Holoscan package runner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat output/output.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
