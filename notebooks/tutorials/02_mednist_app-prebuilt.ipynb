{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a MedNIST Classifier App with MONAI Deploy App SDK (Prebuilt Model)\n",
    "\n",
    "This tutorial demos the process of packaging up a trained model using MONAI Deploy App SDK into an deployable inference application which can be run as a local program, as well as an MONAI Application Package (MAP) for containerized workflow execution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone the github project (the latest version of the main branch only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'source'...\n",
      "remote: Enumerating objects: 280, done.\u001b[K\n",
      "remote: Counting objects: 100% (280/280), done.\u001b[K\n",
      "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
      "remote: Total 280 (delta 59), reused 154 (delta 33), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (280/280), 1.40 MiB | 7.29 MiB/s, done.\n",
      "Resolving deltas: 100% (59/59), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf source \\\n",
    " && git clone --branch main --depth 1 https://github.com/Project-MONAI/monai-deploy-app-sdk.git source \\\n",
    " && rm -rf source/.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.yaml  mednist_classifier_monaideploy.py  requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls source/examples/apps/mednist_classifier_monaideploy/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install monai-deploy-app-sdk package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai-deploy-app-sdk in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (1.26.4)\n",
      "Requirement already satisfied: holoscan~=2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (2.8.0)\n",
      "Requirement already satisfied: colorama>=0.4.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (0.4.6)\n",
      "Requirement already satisfied: typeguard>=3.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai-deploy-app-sdk) (4.4.1)\n",
      "Requirement already satisfied: pip>22.0.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (24.3.1)\n",
      "Requirement already satisfied: cupy-cuda12x<14.0,>=12.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (13.3.0)\n",
      "Requirement already satisfied: cloudpickle<4.0,>=3.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (3.1.1)\n",
      "Requirement already satisfied: python-on-whales<1.0,>=0.60.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (0.75.1)\n",
      "Requirement already satisfied: Jinja2<4.0,>=3.1.3 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (3.1.5)\n",
      "Requirement already satisfied: packaging>=23.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (24.2)\n",
      "Requirement already satisfied: pyyaml<7.0,>=6.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (6.0.2)\n",
      "Requirement already satisfied: requests<3.0,>=2.31.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (2.32.3)\n",
      "Requirement already satisfied: psutil<7.0,>=6.0.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (6.1.1)\n",
      "Requirement already satisfied: wheel-axle-runtime<1.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk) (0.0.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from typeguard>=3.0.0->monai-deploy-app-sdk) (4.12.2)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from cupy-cuda12x<14.0,>=12.2->holoscan~=2.0->monai-deploy-app-sdk) (0.8.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from Jinja2<4.0,>=3.1.3->holoscan~=2.0->monai-deploy-app-sdk) (3.0.2)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (2.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk) (2024.12.14)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from wheel-axle-runtime<1.0->holoscan~=2.0->monai-deploy-app-sdk) (3.16.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk) (2.27.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai-deploy-app-sdk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install necessary packages for the app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: monai in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: Pillow in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (11.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from monai) (2.5.1)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from torch>=1.9->monai) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install monai Pillow # for MONAI transforms and Pillow\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=1.4.2\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\" # for the use of DICOM Writer operators"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download/Extract mednist_classifier_data.zip from Google Drive\n",
    "\n",
    "**_Note:_** Data files are now access controlled. Please first request permission to access the [shared folder on Google Drive](https://drive.google.com/drive/folders/1Z9s3JB2YdKjcw8ELwjVYJcCEvqlQ_HTN?usp=drive_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting beautifulsoup4 (from gdown)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (3.16.1)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (2.32.3)\n",
      "Collecting tqdm (from gdown)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->gdown)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.12.14)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: tqdm, soupsieve, PySocks, beautifulsoup4, gdown\n",
      "Successfully installed PySocks-1.7.1 beautifulsoup4-4.12.3 gdown-5.2.0 soupsieve-2.6 tqdm-4.67.1\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/gdown/download.py:33: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = bs4.BeautifulSoup(line, features=\"html.parser\")\n",
      "Failed to retrieve file url:\n",
      "\n",
      "\tCannot retrieve the public link of the file. You may need to change\n",
      "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
      "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
      "\n",
      "You may still be able to access the file from the browser:\n",
      "\n",
      "\thttps://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\n",
      "\n",
      "but Gdown can't. Please check connections and permissions.\n"
     ]
    }
   ],
   "source": [
    "# Download mednist_classifier_data.zip\n",
    "!pip install gdown \n",
    "!gdown \"https://drive.google.com/uc?id=1yJ4P-xMNEfN6lIOq_u6x1eMAq1_MJu-E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  mednist_classifier_data.zip\n",
      " extracting: classifier.zip          \n",
      " extracting: input/AbdomenCT_007000.jpeg  \n",
      "classifier.zip\n"
     ]
    }
   ],
   "source": [
    "# Unzip the downloaded mednist_classifier_data.zip from the web browser or using gdown, to the notebook/turotials folder, and set up folders\n",
    "input_folder = \"input\"\n",
    "output_folder = \"output\"\n",
    "models_folder = \"models\"\n",
    "!rm -rf {input_folder}\n",
    "!unzip -o \"mednist_classifier_data.zip\"\n",
    "\n",
    "# Need to copy the model file to its own clean subfolder for pacakging, to workaround an issue in the Packager\n",
    "models_folder = \"models\"\n",
    "!rm -rf {models_folder} && mkdir -p {models_folder}/model && cp classifier.zip {models_folder}/model && ls {models_folder}/model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment variables\n",
    "The application uses well-known enviornment variables for the input/output data path, working dir, as well as AI model file path if applicable. Defaults are used if these environment variable are absent.\n",
    "\n",
    "Set the environment variables corresponding to the extracted data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=input\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n",
      "env: HOLOSCAN_MODEL_PATH=models\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH {input_folder}\n",
    "%env HOLOSCAN_OUTPUT_PATH {output_folder}\n",
    "%env HOLOSCAN_MODEL_PATH {models_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package app (creating MAP container image)\n",
    "\n",
    "Now we can use the CLI package command to build the MONAI Application Package (MAP) container image based on a supported base image\n",
    "\n",
    "Use `-l DEBUG` option to see progress.\n",
    "\n",
    ":::{note}\n",
    "This assumes that <a href=\"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html\">NVIDIA Container Toolkit or nvidia docker</a> is installed on the local machine.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 10:31:42,258] [INFO] (common) - Downloading CLI manifest file...\n",
      "[2025-01-16 10:31:42,695] [DEBUG] (common) - Validating CLI manifest file...\n",
      "[2025-01-16 10:31:42,696] [INFO] (packager.parameters) - Application: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/mednist_classifier_monaideploy.py\n",
      "[2025-01-16 10:31:42,696] [INFO] (packager.parameters) - Detected application type: Python File\n",
      "[2025-01-16 10:31:42,696] [INFO] (packager) - Scanning for models in /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models...\n",
      "[2025-01-16 10:31:42,697] [DEBUG] (packager) - Model model=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model added.\n",
      "[2025-01-16 10:31:42,697] [INFO] (packager) - Reading application configuration from /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/app.yaml...\n",
      "[2025-01-16 10:31:42,702] [INFO] (packager) - Generating app.json...\n",
      "[2025-01-16 10:31:42,703] [INFO] (packager) - Generating pkg.json...\n",
      "[2025-01-16 10:31:42,706] [DEBUG] (common) - \n",
      "=============== Begin app.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app/mednist_classifier_monaideploy.py\\\"]\",\n",
      "    \"environment\": {\n",
      "        \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "        \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "        \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "        \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "        \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "        \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "        \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "        \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "        \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "        \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"path\": \"input/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"liveness\": null,\n",
      "    \"output\": {\n",
      "        \"path\": \"output/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"readiness\": null,\n",
      "    \"sdk\": \"monai-deploy\",\n",
      "    \"sdkVersion\": \"2.0.0\",\n",
      "    \"timeout\": 0,\n",
      "    \"version\": 1.0,\n",
      "    \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "================ End app.json ================\n",
      "                 \n",
      "[2025-01-16 10:31:42,707] [DEBUG] (common) - \n",
      "=============== Begin pkg.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "    \"modelRoot\": \"/opt/holoscan/models\",\n",
      "    \"models\": {\n",
      "        \"model\": \"/opt/holoscan/models/model\"\n",
      "    },\n",
      "    \"resources\": {\n",
      "        \"cpu\": 1,\n",
      "        \"gpu\": 1,\n",
      "        \"memory\": \"1Gi\",\n",
      "        \"gpuMemory\": \"1Gi\"\n",
      "    },\n",
      "    \"version\": 1.0,\n",
      "    \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "================ End pkg.json ================\n",
      "                 \n",
      "[2025-01-16 10:31:42,742] [DEBUG] (packager.builder) - \n",
      "========== Begin Build Parameters ==========\n",
      "{'additional_lib_paths': '',\n",
      " 'app_config_file_path': PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/app.yaml'),\n",
      " 'app_dir': PosixPath('/opt/holoscan/app'),\n",
      " 'app_json': '/etc/holoscan/app.json',\n",
      " 'application': PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/mednist_classifier_monaideploy.py'),\n",
      " 'application_directory': PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy'),\n",
      " 'application_type': 'PythonFile',\n",
      " 'build_cache': PosixPath('/home/mqin/.holoscan_build_cache'),\n",
      " 'cmake_args': '',\n",
      " 'command': '[\"python3\", '\n",
      "            '\"/opt/holoscan/app/mednist_classifier_monaideploy.py\"]',\n",
      " 'command_filename': 'mednist_classifier_monaideploy.py',\n",
      " 'config_file_path': PosixPath('/var/holoscan/app.yaml'),\n",
      " 'docs_dir': PosixPath('/opt/holoscan/docs'),\n",
      " 'full_input_path': PosixPath('/var/holoscan/input'),\n",
      " 'full_output_path': PosixPath('/var/holoscan/output'),\n",
      " 'gid': 1000,\n",
      " 'holoscan_sdk_version': '2.8.0',\n",
      " 'includes': [],\n",
      " 'input_dir': 'input/',\n",
      " 'lib_dir': PosixPath('/opt/holoscan/lib'),\n",
      " 'logs_dir': PosixPath('/var/holoscan/logs'),\n",
      " 'models': {'model': PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model')},\n",
      " 'models_dir': PosixPath('/opt/holoscan/models'),\n",
      " 'monai_deploy_app_sdk_version': '2.0.0',\n",
      " 'no_cache': False,\n",
      " 'output_dir': 'output/',\n",
      " 'pip_packages': None,\n",
      " 'pkg_json': '/etc/holoscan/pkg.json',\n",
      " 'requirements_file_path': PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/source/examples/apps/mednist_classifier_monaideploy/requirements.txt'),\n",
      " 'sdk': <SdkType.MonaiDeploy: 'monai-deploy'>,\n",
      " 'sdk_type': 'monai-deploy',\n",
      " 'tarball_output': None,\n",
      " 'timeout': 0,\n",
      " 'title': 'MONAI Deploy App Package - MedNIST Classifier App',\n",
      " 'uid': 1000,\n",
      " 'username': 'holoscan',\n",
      " 'version': 1.0,\n",
      " 'working_dir': PosixPath('/var/holoscan')}\n",
      "=========== End Build Parameters ===========\n",
      "\n",
      "[2025-01-16 10:31:42,742] [DEBUG] (packager.builder) - \n",
      "========== Begin Platform Parameters ==========\n",
      "{'base_image': 'nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04',\n",
      " 'build_image': None,\n",
      " 'cuda_deb_arch': 'x86_64',\n",
      " 'custom_base_image': False,\n",
      " 'custom_holoscan_sdk': False,\n",
      " 'custom_monai_deploy_sdk': False,\n",
      " 'gpu_type': 'dgpu',\n",
      " 'holoscan_deb_arch': 'amd64',\n",
      " 'holoscan_sdk_file': '2.8.0',\n",
      " 'holoscan_sdk_filename': '2.8.0',\n",
      " 'monai_deploy_sdk_file': None,\n",
      " 'monai_deploy_sdk_filename': None,\n",
      " 'tag': 'mednist_app:1.0',\n",
      " 'target_arch': 'x86_64'}\n",
      "=========== End Platform Parameters ===========\n",
      "\n",
      "[2025-01-16 10:31:42,777] [DEBUG] (packager.builder) - \n",
      "========== Begin Dockerfile ==========\n",
      "\n",
      "ARG GPU_TYPE=dgpu\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FROM nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04 AS base\n",
      "\n",
      "RUN apt-get update \\\n",
      "    && apt-get install -y --no-install-recommends --no-install-suggests \\\n",
      "        curl \\\n",
      "        jq \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# FROM base AS mofed-installer\n",
      "# ARG MOFED_VERSION=23.10-2.1.3.1\n",
      "\n",
      "# # In a container, we only need to install the user space libraries, though the drivers are still\n",
      "# # needed on the host.\n",
      "# # Note: MOFED's installation is not easily portable, so we can't copy the output of this stage\n",
      "# # to our final stage, but must inherit from it. For that reason, we keep track of the build/install\n",
      "# # only dependencies in the `MOFED_DEPS` variable (parsing the output of `--check-deps-only`) to\n",
      "# # remove them in that same layer, to ensure they are not propagated in the final image.\n",
      "# WORKDIR /opt/nvidia/mofed\n",
      "# ARG MOFED_INSTALL_FLAGS=\"--dpdk --with-mft --user-space-only --force --without-fw-update\"\n",
      "# RUN UBUNTU_VERSION=$(cat /etc/lsb-release | grep DISTRIB_RELEASE | cut -d= -f2) \\\n",
      "#     && OFED_PACKAGE=\"MLNX_OFED_LINUX-${MOFED_VERSION}-ubuntu${UBUNTU_VERSION}-$(uname -m)\" \\\n",
      "#     && curl -S -# -o ${OFED_PACKAGE}.tgz -L \\\n",
      "#         https://www.mellanox.com/downloads/ofed/MLNX_OFED-${MOFED_VERSION}/${OFED_PACKAGE}.tgz \\\n",
      "#     && tar xf ${OFED_PACKAGE}.tgz \\\n",
      "#     && MOFED_INSTALLER=$(find . -name mlnxofedinstall -type f -executable -print) \\\n",
      "#     && MOFED_DEPS=$(${MOFED_INSTALLER} ${MOFED_INSTALL_FLAGS} --check-deps-only 2>/dev/null | tail -n1 |  cut -d' ' -f3-) \\\n",
      "#     && apt-get update \\\n",
      "#     && apt-get install --no-install-recommends -y ${MOFED_DEPS} \\\n",
      "#     && ${MOFED_INSTALLER} ${MOFED_INSTALL_FLAGS} \\\n",
      "#     && rm -r * \\\n",
      "#     && apt-get remove -y ${MOFED_DEPS} && apt-get autoremove -y \\\n",
      "#     && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "FROM base AS release\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "ENV TERM=xterm-256color\n",
      "\n",
      "ARG GPU_TYPE\n",
      "ARG UNAME\n",
      "ARG UID\n",
      "ARG GID\n",
      "\n",
      "RUN mkdir -p /etc/holoscan/ \\\n",
      "        && mkdir -p /opt/holoscan/ \\\n",
      "        && mkdir -p /var/holoscan \\\n",
      "        && mkdir -p /opt/holoscan/app \\\n",
      "        && mkdir -p /var/holoscan/input \\\n",
      "        && mkdir -p /var/holoscan/output\n",
      "\n",
      "LABEL base=\"nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04\"\n",
      "LABEL tag=\"mednist_app:1.0\"\n",
      "LABEL org.opencontainers.image.title=\"MONAI Deploy App Package - MedNIST Classifier App\"\n",
      "LABEL org.opencontainers.image.version=\"1.0\"\n",
      "LABEL org.nvidia.holoscan=\"2.8.0\"\n",
      "\n",
      "LABEL org.monai.deploy.app-sdk=\"2.0.0\"\n",
      "\n",
      "ENV HOLOSCAN_INPUT_PATH=/var/holoscan/input\n",
      "ENV HOLOSCAN_OUTPUT_PATH=/var/holoscan/output\n",
      "ENV HOLOSCAN_WORKDIR=/var/holoscan\n",
      "ENV HOLOSCAN_APPLICATION=/opt/holoscan/app\n",
      "ENV HOLOSCAN_TIMEOUT=0\n",
      "ENV HOLOSCAN_MODEL_PATH=/opt/holoscan/models\n",
      "ENV HOLOSCAN_DOCS_PATH=/opt/holoscan/docs\n",
      "ENV HOLOSCAN_CONFIG_PATH=/var/holoscan/app.yaml\n",
      "ENV HOLOSCAN_APP_MANIFEST_PATH=/etc/holoscan/app.json\n",
      "ENV HOLOSCAN_PKG_MANIFEST_PATH=/etc/holoscan/pkg.json\n",
      "ENV HOLOSCAN_LOGS_PATH=/var/holoscan/logs\n",
      "ENV HOLOSCAN_VERSION=2.8.0\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# If torch is installed, we can skip installing Python\n",
      "ENV PYTHON_VERSION=3.10.6-1~22.04\n",
      "ENV PYTHON_PIP_VERSION=22.0.2+dfsg-*\n",
      "\n",
      "RUN apt update \\\n",
      "    && apt-get install -y --no-install-recommends --no-install-suggests \\\n",
      "        python3-minimal=${PYTHON_VERSION} \\\n",
      "        libpython3-stdlib=${PYTHON_VERSION} \\\n",
      "        python3=${PYTHON_VERSION} \\\n",
      "        python3-venv=${PYTHON_VERSION} \\\n",
      "        python3-pip=${PYTHON_PIP_VERSION} \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RUN groupadd -f -g $GID $UNAME\n",
      "RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME\n",
      "RUN chown -R holoscan /var/holoscan && \\\n",
      "    chown -R holoscan /var/holoscan/input && \\\n",
      "    chown -R holoscan /var/holoscan/output\n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "# Copy HAP/MAP tool script\n",
      "COPY ./tools /var/holoscan/tools\n",
      "RUN chmod +x /var/holoscan/tools\n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "USER $UNAME\n",
      "\n",
      "ENV PATH=/home/${UNAME}/.local/bin:/opt/nvidia/holoscan/bin:$PATH\n",
      "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/${UNAME}/.local/lib/python3.10/site-packages/holoscan/lib\n",
      "\n",
      "COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "\n",
      "\n",
      "# Install MONAI Deploy App SDK\n",
      "\n",
      "# Install MONAI Deploy from PyPI org\n",
      "RUN pip install monai-deploy-app-sdk==2.0.0\n",
      "\n",
      "\n",
      "COPY ./models  /opt/holoscan/models\n",
      "\n",
      "\n",
      "COPY ./map/app.json /etc/holoscan/app.json\n",
      "COPY ./app.config /var/holoscan/app.yaml\n",
      "COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "\n",
      "COPY ./app /opt/holoscan/app\n",
      "\n",
      "\n",
      "ENTRYPOINT [\"/var/holoscan/tools\"]\n",
      "=========== End Dockerfile ===========\n",
      "\n",
      "[2025-01-16 10:31:42,778] [INFO] (packager.builder) - \n",
      "===============================================================================\n",
      "Building image for:                 x64-workstation\n",
      "    Architecture:                   linux/amd64\n",
      "    Base Image:                     nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04\n",
      "    Build Image:                    N/A\n",
      "    Cache:                          Enabled\n",
      "    Configuration:                  dgpu\n",
      "    Holoscan SDK Package:           2.8.0\n",
      "    MONAI Deploy App SDK Package:   N/A\n",
      "    gRPC Health Probe:              N/A\n",
      "    SDK Version:                    2.8.0\n",
      "    SDK:                            monai-deploy\n",
      "    Tag:                            mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Included features/dependencies: N/A\n",
      "    \n",
      "[2025-01-16 10:31:43,130] [INFO] (common) - Using existing Docker BuildKit builder `holoscan_app_builder`\n",
      "[2025-01-16 10:31:43,131] [DEBUG] (packager.builder) - Building Holoscan Application Package: tag=mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "#0 building with \"holoscan_app_builder\" instance using docker-container driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 4.57kB done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [auth] nvidia/cuda:pull token for nvcr.io\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04\n",
      "#3 DONE 0.5s\n",
      "\n",
      "#4 [internal] load .dockerignore\n",
      "#4 transferring context: 1.79kB done\n",
      "#4 DONE 0.1s\n",
      "\n",
      "#5 importing cache manifest from nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04\n",
      "#5 ...\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 DONE 0.0s\n",
      "\n",
      "#7 importing cache manifest from local:3196701368451557751\n",
      "#7 inferred cache manifest type: application/vnd.oci.image.index.v1+json done\n",
      "#7 DONE 0.0s\n",
      "\n",
      "#8 [base 1/2] FROM nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04@sha256:22fc009e5cea0b8b91d94c99fdd419d2366810b5ea835e47b8343bc15800c186\n",
      "#8 resolve nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04@sha256:22fc009e5cea0b8b91d94c99fdd419d2366810b5ea835e47b8343bc15800c186 0.0s done\n",
      "#8 DONE 0.0s\n",
      "\n",
      "#5 importing cache manifest from nvcr.io/nvidia/cuda:12.6.0-runtime-ubuntu22.04\n",
      "#5 inferred cache manifest type: application/vnd.docker.distribution.manifest.list.v2+json done\n",
      "#5 DONE 0.3s\n",
      "\n",
      "#6 [internal] load build context\n",
      "#6 transferring context: 28.60MB 0.2s done\n",
      "#6 DONE 0.3s\n",
      "\n",
      "#9 [release  6/18] WORKDIR /var/holoscan\n",
      "#9 CACHED\n",
      "\n",
      "#10 [base 2/2] RUN apt-get update     && apt-get install -y --no-install-recommends --no-install-suggests         curl         jq     && rm -rf /var/lib/apt/lists/*\n",
      "#10 CACHED\n",
      "\n",
      "#11 [release  2/18] RUN apt update     && apt-get install -y --no-install-recommends --no-install-suggests         python3-minimal=3.10.6-1~22.04         libpython3-stdlib=3.10.6-1~22.04         python3=3.10.6-1~22.04         python3-venv=3.10.6-1~22.04         python3-pip=22.0.2+dfsg-*     && rm -rf /var/lib/apt/lists/*\n",
      "#11 CACHED\n",
      "\n",
      "#12 [release  5/18] RUN chown -R holoscan /var/holoscan &&     chown -R holoscan /var/holoscan/input &&     chown -R holoscan /var/holoscan/output\n",
      "#12 CACHED\n",
      "\n",
      "#13 [release  8/18] RUN chmod +x /var/holoscan/tools\n",
      "#13 CACHED\n",
      "\n",
      "#14 [release  4/18] RUN useradd -rm -d /home/holoscan -s /bin/bash -g 1000 -G sudo -u 1000 holoscan\n",
      "#14 CACHED\n",
      "\n",
      "#15 [release  3/18] RUN groupadd -f -g 1000 holoscan\n",
      "#15 CACHED\n",
      "\n",
      "#16 [release  7/18] COPY ./tools /var/holoscan/tools\n",
      "#16 CACHED\n",
      "\n",
      "#17 [release  1/18] RUN mkdir -p /etc/holoscan/         && mkdir -p /opt/holoscan/         && mkdir -p /var/holoscan         && mkdir -p /opt/holoscan/app         && mkdir -p /var/holoscan/input         && mkdir -p /var/holoscan/output\n",
      "#17 CACHED\n",
      "\n",
      "#18 [release  9/18] WORKDIR /var/holoscan\n",
      "#18 CACHED\n",
      "\n",
      "#19 [release 10/18] COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "#19 DONE 0.4s\n",
      "\n",
      "#20 [release 11/18] RUN pip install --upgrade pip\n",
      "#20 1.519 Defaulting to user installation because normal site-packages is not writeable\n",
      "#20 1.591 Requirement already satisfied: pip in /usr/lib/python3/dist-packages (22.0.2)\n",
      "#20 1.748 Collecting pip\n",
      "#20 1.799   Downloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "#20 1.859      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 32.2 MB/s eta 0:00:00\n",
      "#20 1.883 Installing collected packages: pip\n",
      "#20 2.675 Successfully installed pip-24.3.1\n",
      "#20 DONE 2.9s\n",
      "\n",
      "#21 [release 12/18] RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "#21 0.686 Collecting monai>=1.2.0 (from -r /tmp/requirements.txt (line 1))\n",
      "#21 0.699   Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "#21 0.959 Collecting Pillow>=8.4.0 (from -r /tmp/requirements.txt (line 2))\n",
      "#21 0.963   Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "#21 0.981 Collecting pydicom>=2.3.0 (from -r /tmp/requirements.txt (line 3))\n",
      "#21 0.986   Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "#21 1.082 Collecting highdicom>=0.18.2 (from -r /tmp/requirements.txt (line 4))\n",
      "#21 1.089   Downloading highdicom-0.23.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "#21 1.125 Collecting SimpleITK>=2.0.0 (from -r /tmp/requirements.txt (line 5))\n",
      "#21 1.131   Downloading SimpleITK-2.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
      "#21 1.133 Requirement already satisfied: setuptools>=59.5.0 in /usr/lib/python3/dist-packages (from -r /tmp/requirements.txt (line 6)) (59.6.0)\n",
      "#21 1.372 Collecting numpy<2.0,>=1.24 (from monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 1.375   Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "#21 1.440 Collecting torch>=1.9 (from monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 1.445   Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "#21 1.580 Collecting pyjpegls>=1.0.0 (from highdicom>=0.18.2->-r /tmp/requirements.txt (line 4))\n",
      "#21 1.653   Downloading pyjpegls-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "#21 1.676 INFO: pip is looking at multiple versions of pyjpegls to determine which version is compatible with other requirements. This could take a while.\n",
      "#21 1.742   Downloading pyjpegls-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "#21 1.819   Downloading pyjpegls-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
      "#21 1.875 Collecting filelock (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 1.879   Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "#21 1.946 Collecting typing-extensions>=4.8.0 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 1.950   Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "#21 1.975 Collecting networkx (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 1.979   Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "#21 1.999 Collecting jinja2 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.003   Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "#21 2.041 Collecting fsspec (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.046   Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "#21 2.097 Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.101   Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#21 2.121 Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.126   Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#21 2.138 Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.143   Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#21 2.160 Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.166   Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#21 2.179 Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.183   Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#21 2.194 Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.198   Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#21 2.208 Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.213   Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#21 2.222 Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.226   Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#21 2.237 Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.242   Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "#21 2.249 Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.254   Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "#21 2.264 Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.270   Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "#21 2.291 Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.297   Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "#21 2.311 Collecting triton==3.1.0 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.316   Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "#21 2.337 Collecting sympy==1.13.1 (from torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.342   Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "#21 2.366 Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.370   Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "#21 2.430 Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.9->monai>=1.2.0->-r /tmp/requirements.txt (line 1))\n",
      "#21 2.433   Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "#21 2.444 Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
      "#21 2.465    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 114.1 MB/s eta 0:00:00\n",
      "#21 2.471 Downloading pillow-11.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "#21 2.514    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 118.6 MB/s eta 0:00:00\n",
      "#21 2.520 Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
      "#21 2.543    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 116.7 MB/s eta 0:00:00\n",
      "#21 2.549 Downloading highdicom-0.23.1-py3-none-any.whl (836 kB)\n",
      "#21 2.560    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 836.4/836.4 kB 123.6 MB/s eta 0:00:00\n",
      "#21 2.565 Downloading SimpleITK-2.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n",
      "#21 3.024    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 52.4/52.4 MB 115.0 MB/s eta 0:00:00\n",
      "#21 3.030 Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "#21 3.191    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.2/18.2 MB 117.4 MB/s eta 0:00:00\n",
      "#21 3.198 Downloading pyjpegls-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
      "#21 3.296    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 27.2 MB/s eta 0:00:00\n",
      "#21 3.305 Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
      "#21 14.12    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 906.4/906.4 MB 90.6 MB/s eta 0:00:00\n",
      "#21 14.13 Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "#21 17.68    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 363.4/363.4 MB 108.0 MB/s eta 0:00:00\n",
      "#21 17.69 Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "#21 17.81    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.8/13.8 MB 118.2 MB/s eta 0:00:00\n",
      "#21 17.82 Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "#21 18.05    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.6/24.6 MB 106.5 MB/s eta 0:00:00\n",
      "#21 18.06 Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "#21 18.07    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 883.7/883.7 kB 121.1 MB/s eta 0:00:00\n",
      "#21 18.08 Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "#21 24.46    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 664.8/664.8 MB 108.9 MB/s eta 0:00:00\n",
      "#21 24.46 Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "#21 26.56    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.5/211.5 MB 101.1 MB/s eta 0:00:00\n",
      "#21 26.57 Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "#21 27.11    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 MB 105.2 MB/s eta 0:00:00\n",
      "#21 27.12 Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "#21 28.22    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 127.9/127.9 MB 116.1 MB/s eta 0:00:00\n",
      "#21 28.23 Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "#21 30.13    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 207.5/207.5 MB 109.7 MB/s eta 0:00:00\n",
      "#21 30.14 Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "#21 31.87    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 188.7/188.7 MB 109.0 MB/s eta 0:00:00\n",
      "#21 31.88 Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "#21 32.07    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.1/21.1 MB 114.2 MB/s eta 0:00:00\n",
      "#21 32.08 Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "#21 32.08 Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "#21 32.14    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.2/6.2 MB 118.0 MB/s eta 0:00:00\n",
      "#21 32.15 Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "#21 34.33    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.5/209.5 MB 96.1 MB/s eta 0:00:00\n",
      "#21 34.34 Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "#21 34.34 Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "#21 34.35 Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "#21 34.35 Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "#21 34.36 Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "#21 34.38    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 117.5 MB/s eta 0:00:00\n",
      "#21 34.38 Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "#21 34.39 Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "#21 34.40    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 127.8 MB/s eta 0:00:00\n",
      "#21 47.33 Installing collected packages: SimpleITK, mpmath, typing-extensions, sympy, pydicom, Pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, fsspec, filelock, triton, pyjpegls, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, highdicom, torch, monai\n",
      "#21 109.4 Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 SimpleITK-2.4.1 filelock-3.16.1 fsspec-2024.12.0 highdicom-0.23.1 jinja2-3.1.5 monai-1.4.0 mpmath-1.3.0 networkx-3.4.2 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pydicom-3.0.1 pyjpegls-1.4.0 sympy-1.13.1 torch-2.5.1 triton-3.1.0 typing-extensions-4.12.2\n",
      "#21 DONE 110.2s\n",
      "\n",
      "#22 [release 13/18] RUN pip install monai-deploy-app-sdk==2.0.0\n",
      "#22 1.123 Defaulting to user installation because normal site-packages is not writeable\n",
      "#22 1.335 Collecting monai-deploy-app-sdk==2.0.0\n",
      "#22 1.415   Downloading monai_deploy_app_sdk-2.0.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "#22 1.444 Requirement already satisfied: numpy>=1.21.6 in /home/holoscan/.local/lib/python3.10/site-packages (from monai-deploy-app-sdk==2.0.0) (1.26.4)\n",
      "#22 1.482 Collecting holoscan~=2.0 (from monai-deploy-app-sdk==2.0.0)\n",
      "#22 1.554   Downloading holoscan-2.8.0-cp310-cp310-manylinux_2_35_x86_64.whl.metadata (7.3 kB)\n",
      "#22 1.622 Collecting colorama>=0.4.1 (from monai-deploy-app-sdk==2.0.0)\n",
      "#22 1.626   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "#22 1.787 Collecting typeguard>=3.0.0 (from monai-deploy-app-sdk==2.0.0)\n",
      "#22 1.791   Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "#22 1.812 Requirement already satisfied: pip>22.0.2 in /home/holoscan/.local/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0) (24.3.1)\n",
      "#22 1.854 Collecting cupy-cuda12x<14.0,>=12.2 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 1.860   Downloading cupy_cuda12x-13.3.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "#22 1.945 Collecting cloudpickle<4.0,>=3.0 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 1.951   Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "#22 2.029 Collecting python-on-whales<1.0,>=0.60.1 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.034   Downloading python_on_whales-0.75.1-py3-none-any.whl.metadata (18 kB)\n",
      "#22 2.050 Requirement already satisfied: Jinja2<4.0,>=3.1.3 in /home/holoscan/.local/lib/python3.10/site-packages (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0) (3.1.5)\n",
      "#22 2.103 Collecting packaging>=23.1 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.107   Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "#22 2.190 Collecting pyyaml<7.0,>=6.0 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.194   Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "#22 2.274 Collecting requests<3.0,>=2.31.0 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.278   Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "#22 2.419 Collecting psutil<7.0,>=6.0.0 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.423   Downloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "#22 2.478 Collecting wheel-axle-runtime<1.0 (from holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.486   Downloading wheel_axle_runtime-0.0.6-py3-none-any.whl.metadata (8.1 kB)\n",
      "#22 2.517 Requirement already satisfied: typing-extensions>=4.10.0 in /home/holoscan/.local/lib/python3.10/site-packages (from typeguard>=3.0.0->monai-deploy-app-sdk==2.0.0) (4.12.2)\n",
      "#22 2.588 Collecting fastrlock>=0.5 (from cupy-cuda12x<14.0,>=12.2->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.593   Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\n",
      "#22 2.611 Requirement already satisfied: MarkupSafe>=2.0 in /home/holoscan/.local/lib/python3.10/site-packages (from Jinja2<4.0,>=3.1.3->holoscan~=2.0->monai-deploy-app-sdk==2.0.0) (3.0.2)\n",
      "#22 2.761 Collecting pydantic!=2.0.*,<3,>=2 (from python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.765   Downloading pydantic-2.10.5-py3-none-any.whl.metadata (30 kB)\n",
      "#22 2.903 Collecting charset-normalizer<4,>=2 (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.908   Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "#22 2.963 Collecting idna<4,>=2.5 (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 2.985   Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "#22 3.081 Collecting urllib3<3,>=1.21.1 (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 3.085   Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "#22 3.149 Collecting certifi>=2017.4.17 (from requests<3.0,>=2.31.0->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 3.153   Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "#22 3.170 Requirement already satisfied: filelock in /home/holoscan/.local/lib/python3.10/site-packages (from wheel-axle-runtime<1.0->holoscan~=2.0->monai-deploy-app-sdk==2.0.0) (3.16.1)\n",
      "#22 3.207 Collecting annotated-types>=0.6.0 (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 3.214   Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "#22 3.965 Collecting pydantic-core==2.27.2 (from pydantic!=2.0.*,<3,>=2->python-on-whales<1.0,>=0.60.1->holoscan~=2.0->monai-deploy-app-sdk==2.0.0)\n",
      "#22 3.969   Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "#22 4.005 Downloading monai_deploy_app_sdk-2.0.0-py3-none-any.whl (132 kB)\n",
      "#22 4.028 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#22 4.120 Downloading holoscan-2.8.0-cp310-cp310-manylinux_2_35_x86_64.whl (41.1 MB)\n",
      "#22 6.880    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.1/41.1 MB 14.8 MB/s eta 0:00:00\n",
      "#22 6.885 Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
      "#22 6.907 Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "#22 6.930 Downloading cupy_cuda12x-13.3.0-cp310-cp310-manylinux2014_x86_64.whl (90.6 MB)\n",
      "#22 8.305    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.6/90.6 MB 66.0 MB/s eta 0:00:00\n",
      "#22 8.311 Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "#22 8.331 Downloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "#22 8.355 Downloading python_on_whales-0.75.1-py3-none-any.whl (114 kB)\n",
      "#22 8.378 Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
      "#22 8.410    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 751.2/751.2 kB 21.3 MB/s eta 0:00:00\n",
      "#22 8.418 Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "#22 8.441 Downloading wheel_axle_runtime-0.0.6-py3-none-any.whl (14 kB)\n",
      "#22 8.464 Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
      "#22 8.490 Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
      "#22 8.514 Downloading fastrlock-0.8.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (53 kB)\n",
      "#22 8.534 Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "#22 8.560 Downloading pydantic-2.10.5-py3-none-any.whl (431 kB)\n",
      "#22 8.587 Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "#22 8.637    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 42.2 MB/s eta 0:00:00\n",
      "#22 8.646 Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "#22 8.673 Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "#22 9.210 Installing collected packages: fastrlock, wheel-axle-runtime, urllib3, typeguard, pyyaml, pydantic-core, psutil, packaging, idna, cupy-cuda12x, colorama, cloudpickle, charset-normalizer, certifi, annotated-types, requests, pydantic, python-on-whales, holoscan, monai-deploy-app-sdk\n",
      "#22 12.83 Successfully installed annotated-types-0.7.0 certifi-2024.12.14 charset-normalizer-3.4.1 cloudpickle-3.1.1 colorama-0.4.6 cupy-cuda12x-13.3.0 fastrlock-0.8.3 holoscan-2.8.0 idna-3.10 monai-deploy-app-sdk-2.0.0 packaging-24.2 psutil-6.1.1 pydantic-2.10.5 pydantic-core-2.27.2 python-on-whales-0.75.1 pyyaml-6.0.2 requests-2.32.3 typeguard-4.4.1 urllib3-2.3.0 wheel-axle-runtime-0.0.6\n",
      "#22 DONE 14.3s\n",
      "\n",
      "#23 [release 14/18] COPY ./models  /opt/holoscan/models\n",
      "#23 DONE 0.3s\n",
      "\n",
      "#24 [release 15/18] COPY ./map/app.json /etc/holoscan/app.json\n",
      "#24 DONE 0.1s\n",
      "\n",
      "#25 [release 16/18] COPY ./app.config /var/holoscan/app.yaml\n",
      "#25 DONE 0.1s\n",
      "\n",
      "#26 [release 17/18] COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "#26 DONE 0.1s\n",
      "\n",
      "#27 [release 18/18] COPY ./app /opt/holoscan/app\n",
      "#27 DONE 0.1s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 exporting layers\n",
      "#28 exporting layers 185.9s done\n",
      "#28 exporting manifest sha256:4bc1a9e3ac99d016155586b056ae7599ffcde435c3a5e52e0f6657d6745cfe82 0.0s done\n",
      "#28 exporting config sha256:ccfd1f2b9063f802169c1b8c3f470a500bfc7d87310ad64a11a9cccfbc1af203 0.0s done\n",
      "#28 sending tarball\n",
      "#28 ...\n",
      "\n",
      "#29 importing to docker\n",
      "#29 loading layer 6ad61921c73a 238B / 238B\n",
      "#29 loading layer 38ceac2dea6c 65.54kB / 5.03MB\n",
      "#29 loading layer fef55c8b18b6 557.06kB / 3.14GB\n",
      "#29 loading layer fef55c8b18b6 75.20MB / 3.14GB 6.2s\n",
      "#29 loading layer fef55c8b18b6 303.60MB / 3.14GB 12.3s\n",
      "#29 loading layer fef55c8b18b6 494.11MB / 3.14GB 16.4s\n",
      "#29 loading layer fef55c8b18b6 698.55MB / 3.14GB 20.5s\n",
      "#29 loading layer fef55c8b18b6 875.69MB / 3.14GB 24.6s\n",
      "#29 loading layer fef55c8b18b6 1.08GB / 3.14GB 28.8s\n",
      "#29 loading layer fef55c8b18b6 1.27GB / 3.14GB 32.9s\n",
      "#29 loading layer fef55c8b18b6 1.48GB / 3.14GB 36.9s\n",
      "#29 loading layer fef55c8b18b6 1.71GB / 3.14GB 41.1s\n",
      "#29 loading layer fef55c8b18b6 1.96GB / 3.14GB 45.2s\n",
      "#29 loading layer fef55c8b18b6 2.02GB / 3.14GB 52.6s\n",
      "#29 loading layer fef55c8b18b6 2.22GB / 3.14GB 58.8s\n",
      "#29 loading layer fef55c8b18b6 2.38GB / 3.14GB 65.0s\n",
      "#29 loading layer fef55c8b18b6 2.57GB / 3.14GB 69.1s\n",
      "#29 loading layer fef55c8b18b6 2.85GB / 3.14GB 73.3s\n",
      "#29 loading layer fef55c8b18b6 3.04GB / 3.14GB 79.4s\n",
      "#29 loading layer fb8323017175 557.06kB / 275.85MB\n",
      "#29 loading layer fb8323017175 147.06MB / 275.85MB 2.0s\n",
      "#29 loading layer fb8323017175 207.78MB / 275.85MB 4.1s\n",
      "#29 loading layer fb8323017175 253.46MB / 275.85MB 6.2s\n",
      "#29 loading layer 63ccb78efd57 262.14kB / 25.59MB\n",
      "#29 loading layer 481e6ac82baa 512B / 512B\n",
      "#29 loading layer 82423b58afc8 698B / 698B\n",
      "#29 loading layer 6b8fb52b6635 300B / 300B\n",
      "#29 loading layer 0c97423a9424 4.17kB / 4.17kB\n",
      "#29 loading layer 63ccb78efd57 262.14kB / 25.59MB 0.9s done\n",
      "#29 loading layer 6ad61921c73a 238B / 238B 92.7s done\n",
      "#29 loading layer 38ceac2dea6c 65.54kB / 5.03MB 92.6s done\n",
      "#29 loading layer fef55c8b18b6 3.07GB / 3.14GB 91.7s done\n",
      "#29 loading layer fb8323017175 253.46MB / 275.85MB 8.4s done\n",
      "#29 loading layer 481e6ac82baa 512B / 512B 0.5s done\n",
      "#29 loading layer 82423b58afc8 698B / 698B 0.4s done\n",
      "#29 loading layer 6b8fb52b6635 300B / 300B 0.4s done\n",
      "#29 loading layer 0c97423a9424 4.17kB / 4.17kB 0.3s done\n",
      "#29 DONE 92.7s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 sending tarball 134.6s done\n",
      "#28 DONE 320.5s\n",
      "\n",
      "#30 exporting cache to client directory\n",
      "#30 preparing build cache for export\n",
      "#30 writing layer sha256:1a0d52c93099897b518eb6cc6cd0fa3d52ff733e8606b4d8c92675ba9e7101ff\n",
      "#30 writing layer sha256:1a0d52c93099897b518eb6cc6cd0fa3d52ff733e8606b4d8c92675ba9e7101ff done\n",
      "#30 writing layer sha256:1d6a324671b2bd0bb8dfe0e63d866c330b44541d4b242766403858e1e2bcd343\n",
      "#30 writing layer sha256:1d6a324671b2bd0bb8dfe0e63d866c330b44541d4b242766403858e1e2bcd343 0.2s done\n",
      "#30 writing layer sha256:234b866f57e0c5d555af2d87a1857a17ec4ac7e70d2dc6c31ff0a072a4607f24\n",
      "#30 writing layer sha256:234b866f57e0c5d555af2d87a1857a17ec4ac7e70d2dc6c31ff0a072a4607f24 done\n",
      "#30 writing layer sha256:24ceb7d12a7eb1ffbdfe5c5cda307f1ed9ae5498f0cda3bf7759f2d93befb498\n",
      "#30 writing layer sha256:24ceb7d12a7eb1ffbdfe5c5cda307f1ed9ae5498f0cda3bf7759f2d93befb498 45.6s done\n",
      "#30 writing layer sha256:255905badeaa82f032e1043580eed8b745c19cd4a2cb7183883ee5a30f851d6d\n",
      "#30 writing layer sha256:255905badeaa82f032e1043580eed8b745c19cd4a2cb7183883ee5a30f851d6d done\n",
      "#30 writing layer sha256:3713021b02770a720dea9b54c03d0ed83e03a2ef5dce2898c56a327fee9a8bca done\n",
      "#30 writing layer sha256:3a80776cdc9c9ef79bb38510849c9160f82462d346bf5a8bf29c811391b4e763 done\n",
      "#30 writing layer sha256:41e173df84c503c9e717e0e67c22260d4e6bb14660577b225dec5733b4155a78 done\n",
      "#30 writing layer sha256:45e69249659eac441e32d6dc2885927df861d03e48ed950eb2c83e9bae70392d 0.0s done\n",
      "#30 writing layer sha256:46c9c54348df10b0d7700bf932d5de7dc5bf9ab91e685db7086e29e381ff8e12 done\n",
      "#30 writing layer sha256:4bbb4cfc55e5ab11e1f9584ef77bd4e3d68b54c60e1a04f9c50e5a52ecee47f6 0.0s done\n",
      "#30 writing layer sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 done\n",
      "#30 writing layer sha256:659f397d4a5dc234d675c43b29226e9cf28d96e94e6f795bf9ac0014c1c0d4f3\n",
      "#30 writing layer sha256:659f397d4a5dc234d675c43b29226e9cf28d96e94e6f795bf9ac0014c1c0d4f3 0.6s done\n",
      "#30 writing layer sha256:67b3546b211deefd67122e680c0932886e0b3c6bd6ae0665e3ab25d2d9f0cda0\n",
      "#30 writing layer sha256:67b3546b211deefd67122e680c0932886e0b3c6bd6ae0665e3ab25d2d9f0cda0 done\n",
      "#30 writing layer sha256:80bca2723815227ee731a224812077b75319df51a59a5a118b813cc6a3453960 0.0s done\n",
      "#30 writing layer sha256:88b93bd9b42e790f7df250d8c8605831100f5a93b5191f72feb6bba341315dbe\n",
      "#30 writing layer sha256:88b93bd9b42e790f7df250d8c8605831100f5a93b5191f72feb6bba341315dbe 5.1s done\n",
      "#30 writing layer sha256:8a4c2d2307e5ad8365689c0967fcf7c31bd4a631ed79a2a03ef54220121106c7\n",
      "#30 preparing build cache for export 51.9s done\n",
      "#30 writing layer sha256:8a4c2d2307e5ad8365689c0967fcf7c31bd4a631ed79a2a03ef54220121106c7 0.0s done\n",
      "#30 writing layer sha256:94ea8fe9174939142272c5d49e179ba19f357ea997b5d4f3900d1fb7d4fe6707 done\n",
      "#30 writing layer sha256:980c13e156f90218b216bc6b0430472bbda71c0202804d350c0e16ef02075885 done\n",
      "#30 writing layer sha256:ac52600be001236a2c291a4c5902c915bf5ec9d2441c06d2a54c587b76345847 done\n",
      "#30 writing layer sha256:bc25d810fc1fd99656c1b07d422e88cdb896508730175bc3ec187b79f3787044 done\n",
      "#30 writing layer sha256:c0e9112106766f6d918279426468ca3a81ddca90d82a7e3e41ed3d96b0464a94 done\n",
      "#30 writing layer sha256:c8937b741c9ecd6b257aeb18daf07eddbf1c77b0c93f9ba4164faa8353cd1d3c done\n",
      "#30 writing layer sha256:d339273dfb7fc3b7fd896d3610d360ab9a09ab33a818093cb73b4be7639b6e99 done\n",
      "#30 writing layer sha256:e540d242f419a27800d601d7275f4fbb3488b97d209b454f52e63f1eb413a912 done\n",
      "#30 writing layer sha256:e75739bdd30fe589564286a797f7e975cc5405f1af3c9cdc4ffb141d46b9ea6a 0.0s done\n",
      "#30 writing layer sha256:efc9014e2a4cb1e133b80bb4f047e9141e98685eb95b8d2471a8e35b86643e31 done\n",
      "#30 writing config sha256:a23715cda6aca5cc84c6f8c44d9c6d6b85d4b81187551c705d12fab60d520207 0.0s done\n",
      "#30 writing cache manifest sha256:60e9718f338977306f06b2b74bcf2b3d98623fbd242ad8e3b9778ffe47878f10 0.0s done\n",
      "#30 DONE 51.9s\n",
      "[2025-01-16 10:40:06,415] [INFO] (packager) - Build Summary:\n",
      "\n",
      "Platform: x64-workstation/dgpu\n",
      "    Status:     Succeeded\n",
      "    Docker Tag: mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Tarball:    None\n"
     ]
    }
   ],
   "source": [
    "tag_prefix = \"mednist_app\"\n",
    "\n",
    "!monai-deploy package \"source/examples/apps/mednist_classifier_monaideploy/mednist_classifier_monaideploy.py\" -m {models_folder} -c \"source/examples/apps/mednist_classifier_monaideploy/app.yaml\" -t {tag_prefix}:1.0 --platform x64-workstation -l DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MAP Docker image is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mednist_app-x64-workstation-dgpu-linux-amd64                                  1.0                            ccfd1f2b9063   6 minutes ago    8.6GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep {tag_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to display and inspect the MAP manifests by running the container with the `show` command.\n",
    "Furthermore, we can also extract the manifests and other contents in the MAP by using the `extract` command while mapping specific folder to the host's (we know that our MAP is compliant and supports these commands).\n",
    "\n",
    ":::{note}\n",
    "The host folder for storing the extracted content must first be created by the user, and if it has been created by Docker on running the container, the folder needs to be deleted and re-created.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display manifests and extract MAP contents to the host folder, ./export\n",
      "\n",
      "============================== app.json ==============================\n",
      "{\n",
      "  \"apiVersion\": \"1.0.0\",\n",
      "  \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app/mednist_classifier_monaideploy.py\\\"]\",\n",
      "  \"environment\": {\n",
      "    \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "    \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "    \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "    \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "    \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "    \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "    \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "    \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "    \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "    \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "  },\n",
      "  \"input\": {\n",
      "    \"path\": \"input/\",\n",
      "    \"formats\": null\n",
      "  },\n",
      "  \"liveness\": null,\n",
      "  \"output\": {\n",
      "    \"path\": \"output/\",\n",
      "    \"formats\": null\n",
      "  },\n",
      "  \"readiness\": null,\n",
      "  \"sdk\": \"monai-deploy\",\n",
      "  \"sdkVersion\": \"2.0.0\",\n",
      "  \"timeout\": 0,\n",
      "  \"version\": 1,\n",
      "  \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "\n",
      "============================== pkg.json ==============================\n",
      "{\n",
      "  \"apiVersion\": \"1.0.0\",\n",
      "  \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "  \"modelRoot\": \"/opt/holoscan/models\",\n",
      "  \"models\": {\n",
      "    \"model\": \"/opt/holoscan/models/model\"\n",
      "  },\n",
      "  \"resources\": {\n",
      "    \"cpu\": 1,\n",
      "    \"gpu\": 1,\n",
      "    \"memory\": \"1Gi\",\n",
      "    \"gpuMemory\": \"1Gi\"\n",
      "  },\n",
      "  \"version\": 1,\n",
      "  \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "\n",
      "2025-01-16 18:40:10 [INFO] Copying application from /opt/holoscan/app to /var/run/holoscan/export/app\n",
      "\n",
      "2025-01-16 18:40:10 [INFO] Copying application manifest file from /etc/holoscan/app.json to /var/run/holoscan/export/config/app.json\n",
      "2025-01-16 18:40:10 [INFO] Copying pkg manifest file from /etc/holoscan/pkg.json to /var/run/holoscan/export/config/pkg.json\n",
      "2025-01-16 18:40:10 [INFO] Copying application configuration from /var/holoscan/app.yaml to /var/run/holoscan/export/config/app.yaml\n",
      "\n",
      "2025-01-16 18:40:10 [INFO] Copying models from /opt/holoscan/models to /var/run/holoscan/export/models\n",
      "\n",
      "2025-01-16 18:40:10 [INFO] Copying documentation from /opt/holoscan/docs/ to /var/run/holoscan/export/docs\n",
      "2025-01-16 18:40:10 [INFO] '/opt/holoscan/docs/' cannot be found.\n",
      "\n",
      "app  config  models\n"
     ]
    }
   ],
   "source": [
    "!echo \"Display manifests and extract MAP contents to the host folder, ./export\"\n",
    "!docker run --rm {tag_prefix}-x64-workstation-dgpu-linux-amd64:1.0 show\n",
    "!rm -rf `pwd`/export && mkdir -p `pwd`/export\n",
    "!docker run --rm -v `pwd`/export/:/var/run/holoscan/export/ {tag_prefix}-x64-workstation-dgpu-linux-amd64:1.0 extract\n",
    "!ls `pwd`/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing packaged app locally\n",
    "\n",
    "The packaged app can be run locally through [MONAI Application Runner](/developing_with_sdk/executing_packaged_app_locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 10:40:12,574] [INFO] (runner) - Checking dependencies...\n",
      "[2025-01-16 10:40:12,574] [INFO] (runner) - --> Verifying if \"docker\" is installed...\n",
      "\n",
      "[2025-01-16 10:40:12,574] [INFO] (runner) - --> Verifying if \"docker-buildx\" is installed...\n",
      "\n",
      "[2025-01-16 10:40:12,574] [INFO] (runner) - --> Verifying if \"mednist_app-x64-workstation-dgpu-linux-amd64:1.0\" is available...\n",
      "\n",
      "[2025-01-16 10:40:12,655] [INFO] (runner) - Reading HAP/MAP manifest...\n",
      "Successfully copied 2.56kB to /tmp/tmpucothga1/app.json\n",
      "Successfully copied 2.05kB to /tmp/tmpucothga1/pkg.json\n",
      "[2025-01-16 10:40:12,958] [INFO] (runner) - --> Verifying if \"nvidia-ctk\" is installed...\n",
      "\n",
      "[2025-01-16 10:40:12,959] [INFO] (runner) - --> Verifying \"nvidia-ctk\" version...\n",
      "\n",
      "[2025-01-16 10:40:13,372] [INFO] (common) - Launching container (9844c1c38ebe) using image 'mednist_app-x64-workstation-dgpu-linux-amd64:1.0'...\n",
      "    container name:      heuristic_merkle\n",
      "    host name:           mingq-dt\n",
      "    network:             host\n",
      "    user:                1000:1000\n",
      "    ulimits:             memlock=-1:-1, stack=67108864:67108864\n",
      "    cap_add:             CAP_SYS_PTRACE\n",
      "    ipc mode:            host\n",
      "    shared memory size:  67108864\n",
      "    devices:             \n",
      "    group_add:           44\n",
      "2025-01-16 18:40:14 [INFO] Launching application python3 /opt/holoscan/app/mednist_classifier_monaideploy.py ...\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/holoscan/app/mednist_classifier_monaideploy.py\", line 19, in <module>\n",
      "\n",
      "    from monai.deploy.conditions import CountCondition\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/__init__.py\", line 101, in <module>\n",
      "\n",
      "    load_submodules(sys.modules[__name__], False, exclude_pattern=excludes)\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/utils/module.py\", line 187, in load_submodules\n",
      "\n",
      "    mod = import_module(name)\n",
      "\n",
      "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
      "\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/__init__.py\", line 23, in <module>\n",
      "\n",
      "    from . import _version, conditions, core, exceptions, logger, resources, utils\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/core/__init__.py\", line 32, in <module>\n",
      "\n",
      "    from holoscan.core import *\n",
      "\n",
      "AttributeError: module 'holoscan.core' has no attribute 'MultiMessageConditionInfo'\n",
      "\n",
      "[2025-01-16 10:40:20,782] [INFO] (common) - Container 'heuristic_merkle'(9844c1c38ebe) exited.\n"
     ]
    }
   ],
   "source": [
    "# Clear the output folder and run the MAP. The input is expected to be a folder.\n",
    "!rm -rf {ouput_folder}\n",
    "!monai-deploy run -i $HOLOSCAN_INPUT_PATH -o $HOLOSCAN_OUTPUT_PATH mednist_app-x64-workstation-dgpu-linux-amd64:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: output/output.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cat {output_folder}/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Packaging Application with MONAI Deploy App SDK\n",
    "\n",
    "In the following sections we will discuss the details of buildng the application that was packaged and run above.\n",
    "\n",
    "Based on the Torchscript model(`classifier.zip`), we will implement an application that process an input Jpeg image and write the prediction(classification) result as JSON file(`output.json`).\n",
    "\n",
    "In our inference application, we will define two operators:\n",
    "\n",
    "1. `LoadPILOperator` - Load a JPEG image from the input path and pass the loaded image object to the next operator.\n",
    "    - **Input**: a file path (`Path`)\n",
    "    - **Output**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "2. `MedNISTClassifierOperator` - Pre-transform the given image by using MONAI's `Compose` class, feed to the Torchscript model (`classifier.zip`), and write the prediction into JSON file(`output.json`)\n",
    "    - Pre-transforms consist of three transforms -- `EnsureChannelFirst`, `ScaleIntensity`, and `EnsureType`.\n",
    "    - **Input**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output**: a folder path that the prediction result(`output.json`) would be written (`Path`)\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/1928522/133868503-46671f0a-7741-4f9d-aefa-83e95e9a5f84.png\" alt=\"Workflow\" style=\"width: 600px;margin-left:auto;margin-right:auto;\"/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators and define `MEDNIST_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import EnsureChannelFirst, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Operator classes\n",
    "\n",
    "#### LoadPILOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MedNISTClassifierOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([EnsureChannelFirst(channel_dim=\"no_channel\"), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class inheriting `Application` class.\n",
    "\n",
    "`LoadPILOperator` is connected to `MedNISTClassifierOperator` by using `self.add_flow()` in `compose()` method of `App`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        app_context = Application.init_app_context({})  # Do not pass argv in Jupyter Notebook\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing app locally"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can execute the app in the Jupyter notebook. Before doing so, we also need to clean the output folder which was created by running the packaged containerizd app in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] [fragment.cpp:588] Loading extensions from configs...\n",
      "[2025-01-16 10:40:29,317] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=[])\n",
      "[2025-01-16 10:40:29,339] [INFO] (root) - AppContext object: AppContext(input_path=input, output_path=output, model_path=models, workdir=)\n",
      "[info] [gxf_executor.cpp:262] Creating context\n",
      "[info] [gxf_executor.cpp:1767] creating input IOSpec named 'output_folder'\n",
      "[info] [gxf_executor.cpp:1767] creating input IOSpec named 'image'\n",
      "[info] [gxf_executor.cpp:1767] creating input IOSpec named 'study_selected_series_list'\n",
      "[info] [gxf_executor.cpp:1767] creating input IOSpec named 'text'\n",
      "[info] [gxf_executor.cpp:2178] Activating Graph...\n",
      "[info] [gxf_executor.cpp:2208] Running Graph...\n",
      "[info] [gxf_executor.cpp:2210] Waiting for completion...\n",
      "[info] [greedy_scheduler.cpp:191] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)\n",
      "[2025-01-16 10:40:31,758] [WARNING] (pydicom) - 'Dataset.is_implicit_VR' will be removed in v4.0, set the Transfer Syntax UID or use the 'implicit_vr' argument with Dataset.save_as() or dcmwrite() instead\n",
      "[2025-01-16 10:40:31,759] [WARNING] (pydicom) - 'Dataset.is_little_endian' will be removed in v4.0, set the Transfer Syntax UID or use the 'little_endian' argument with Dataset.save_as() or dcmwrite() instead\n",
      "[2025-01-16 10:40:31,761] [WARNING] (pydicom) - Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/pydicom/valuerep.py:440: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warn_and_log(msg)\n",
      "[2025-01-16 10:40:31,766] [WARNING] (pydicom) - 'write_like_original' is deprecated and will be removed in v4.0, please use 'enforce_file_format' instead\n",
      "[2025-01-16 10:40:31,769] [INFO] (root) - Finished writing DICOM instance to file output/1.2.826.0.1.3680043.8.498.74158999565375393607124538456016184224.dcm\n",
      "[2025-01-16 10:40:31,773] [INFO] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - DICOM SOP instance saved in output/1.2.826.0.1.3680043.8.498.74158999565375393607124538456016184224.dcm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbdomenCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] [greedy_scheduler.cpp:372] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[info] [greedy_scheduler.cpp:401] Scheduler finished.\n",
      "[info] [gxf_executor.cpp:2213] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:2221] Graph execution finished.\n",
      "[info] [gxf_executor.cpp:292] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "app = App().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat $HOLOSCAN_OUTPUT_PATH/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the whole application as a file(`mednist_classifier_monaideploy.py`) by concatenating code above, then add the following lines:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p mednist_app && rm -rf mednist_app/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/mednist_classifier_monaideploy.py\n",
    "\n",
    "# Copyright 2021-2023 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import EnsureChannelFirst, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([EnsureChannelFirst(channel_dim=\"no_channel\"), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "\n",
    "# @md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        # Use Commandline options over environment variables to init context.\n",
    "        app_context = Application.init_app_context(self.argv)\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's execute the app on the command line.\n",
    "\n",
    ":::{note}\n",
    "Since the environment variables have been set and contain the correct paths, it is not necessary to provide the command line options on running the application, though the following demonstrates the use of the options.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32minfo\u001b[m] [fragment.cpp:588] Loading extensions from configs...\n",
      "[2025-01-16 10:40:38,384] [INFO] (root) - Parsed args: Namespace(log_level='DEBUG', input=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/input'), output=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output'), model=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models'), workdir=None, argv=['mednist_app/mednist_classifier_monaideploy.py', '-i', 'input', '-o', 'output', '-m', 'models', '-l', 'DEBUG'])\n",
      "[2025-01-16 10:40:38,391] [INFO] (root) - AppContext object: AppContext(input_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/input, output_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output, model_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models, workdir=)\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:262] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1767] creating input IOSpec named 'output_folder'\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1767] creating input IOSpec named 'image'\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1767] creating input IOSpec named 'study_selected_series_list'\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1767] creating input IOSpec named 'text'\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2178] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2208] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2210] Waiting for completion...\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:191] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)\n",
      "AbdomenCT\n",
      "[2025-01-16 10:40:39,609] [DEBUG] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - Writing DICOM object...\n",
      "\n",
      "[2025-01-16 10:40:39,609] [DEBUG] (root) - Writing DICOM common modules...\n",
      "[2025-01-16 10:40:39,610] [WARNING] (pydicom) - 'Dataset.is_implicit_VR' will be removed in v4.0, set the Transfer Syntax UID or use the 'implicit_vr' argument with Dataset.save_as() or dcmwrite() instead\n",
      "[2025-01-16 10:40:39,610] [WARNING] (pydicom) - 'Dataset.is_little_endian' will be removed in v4.0, set the Transfer Syntax UID or use the 'little_endian' argument with Dataset.save_as() or dcmwrite() instead\n",
      "[2025-01-16 10:40:39,610] [WARNING] (pydicom) - Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/pydicom/valuerep.py:440: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warn_and_log(msg)\n",
      "[2025-01-16 10:40:39,611] [DEBUG] (root) - DICOM common modules written:\n",
      "Dataset.file_meta -------------------------------\n",
      "(0002,0000) File Meta Information Group Length  UL: 198\n",
      "(0002,0001) File Meta Information Version       OB: b'01'\n",
      "(0002,0002) Media Storage SOP Class UID         UI: Basic Text SR Storage\n",
      "(0002,0003) Media Storage SOP Instance UID      UI: 1.2.826.0.1.3680043.8.498.60677937641932107808557347299901104083\n",
      "(0002,0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n",
      "(0002,0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n",
      "(0002,0013) Implementation Version Name         SH: '2.0.0'\n",
      "-------------------------------------------------\n",
      "(0008,0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008,0012) Instance Creation Date              DA: '20250116'\n",
      "(0008,0013) Instance Creation Time              TM: '104039'\n",
      "(0008,0016) SOP Class UID                       UI: Basic Text SR Storage\n",
      "(0008,0018) SOP Instance UID                    UI: 1.2.826.0.1.3680043.8.498.60677937641932107808557347299901104083\n",
      "(0008,0020) Study Date                          DA: '20250116'\n",
      "(0008,0021) Series Date                         DA: '20250116'\n",
      "(0008,0023) Content Date                        DA: '20250116'\n",
      "(0008,002A) Acquisition DateTime                DT: '20250116104039'\n",
      "(0008,0030) Study Time                          TM: '104039'\n",
      "(0008,0031) Series Time                         TM: '104039'\n",
      "(0008,0033) Content Time                        TM: '104039'\n",
      "(0008,0050) Accession Number                    SH: ''\n",
      "(0008,0060) Modality                            CS: 'SR'\n",
      "(0008,0070) Manufacturer                        LO: 'MOANI Deploy App SDK'\n",
      "(0008,0090) Referring Physician's Name          PN: ''\n",
      "(0008,0201) Timezone Offset From UTC            SH: '-0800'\n",
      "(0008,1030) Study Description                   LO: 'AI results.'\n",
      "(0008,103E) Series Description                  LO: 'CAUTION: Not for Diagnostic Use, for research use only.'\n",
      "(0008,1090) Manufacturer's Model Name           LO: 'DICOM SR Writer'\n",
      "(0010,0010) Patient's Name                      PN: ''\n",
      "(0010,0020) Patient ID                          LO: ''\n",
      "(0010,0021) Issuer of Patient ID                LO: ''\n",
      "(0010,0030) Patient's Birth Date                DA: ''\n",
      "(0010,0040) Patient's Sex                       CS: ''\n",
      "(0018,0015) Body Part Examined                  CS: ''\n",
      "(0018,1020) Software Versions                   LO: '2.0.0'\n",
      "(0018,A001)  Contributing Equipment Sequence  1 item(s) ---- \n",
      "   (0008,0070) Manufacturer                        LO: 'MONAI WG Trainer'\n",
      "   (0008,1090) Manufacturer's Model Name           LO: 'MEDNIST Classifier'\n",
      "   (0018,1002) Device UID                          UI: xyz\n",
      "   (0018,1020) Software Versions                   LO: '0.1'\n",
      "   (0040,A170)  Purpose of Reference Code Sequence  1 item(s) ---- \n",
      "      (0008,0100) Code Value                          SH: 'Newcode1'\n",
      "      (0008,0102) Coding Scheme Designator            SH: '99IHE'\n",
      "      (0008,0104) Code Meaning                        LO: '\"Processing Algorithm'\n",
      "      ---------\n",
      "   ---------\n",
      "(0020,000D) Study Instance UID                  UI: 1.2.826.0.1.3680043.8.498.62792986904071080344578561194802396873\n",
      "(0020,000E) Series Instance UID                 UI: 1.2.826.0.1.3680043.8.498.57204416465564820510862751799072609586\n",
      "(0020,0010) Study ID                            SH: '1'\n",
      "(0020,0011) Series Number                       IS: '5022'\n",
      "(0020,0013) Instance Number                     IS: '1'\n",
      "(0040,1001) Requested Procedure ID              SH: ''\n",
      "[2025-01-16 10:40:39,612] [DEBUG] (root) - DICOM dataset to be written:Dataset.file_meta -------------------------------\n",
      "(0002,0000) File Meta Information Group Length  UL: 198\n",
      "(0002,0001) File Meta Information Version       OB: b'01'\n",
      "(0002,0002) Media Storage SOP Class UID         UI: Basic Text SR Storage\n",
      "(0002,0003) Media Storage SOP Instance UID      UI: 1.2.826.0.1.3680043.8.498.60677937641932107808557347299901104083\n",
      "(0002,0010) Transfer Syntax UID                 UI: Implicit VR Little Endian\n",
      "(0002,0012) Implementation Class UID            UI: 1.2.40.0.13.1.1.1\n",
      "(0002,0013) Implementation Version Name         SH: '2.0.0'\n",
      "-------------------------------------------------\n",
      "(0008,0005) Specific Character Set              CS: 'ISO_IR 100'\n",
      "(0008,0012) Instance Creation Date              DA: '20250116'\n",
      "(0008,0013) Instance Creation Time              TM: '104039'\n",
      "(0008,0016) SOP Class UID                       UI: Basic Text SR Storage\n",
      "(0008,0018) SOP Instance UID                    UI: 1.2.826.0.1.3680043.8.498.60677937641932107808557347299901104083\n",
      "(0008,0020) Study Date                          DA: '20250116'\n",
      "(0008,0021) Series Date                         DA: '20250116'\n",
      "(0008,0023) Content Date                        DA: '20250116'\n",
      "(0008,002A) Acquisition DateTime                DT: '20250116104039'\n",
      "(0008,0030) Study Time                          TM: '104039'\n",
      "(0008,0031) Series Time                         TM: '104039'\n",
      "(0008,0033) Content Time                        TM: '104039'\n",
      "(0008,0050) Accession Number                    SH: ''\n",
      "(0008,0060) Modality                            CS: 'SR'\n",
      "(0008,0070) Manufacturer                        LO: 'MOANI Deploy App SDK'\n",
      "(0008,0090) Referring Physician's Name          PN: ''\n",
      "(0008,0201) Timezone Offset From UTC            SH: '-0800'\n",
      "(0008,1030) Study Description                   LO: 'AI results.'\n",
      "(0008,103E) Series Description                  LO: 'Not for clinical use. The result is for research use only.'\n",
      "(0008,1090) Manufacturer's Model Name           LO: 'DICOM SR Writer'\n",
      "(0010,0010) Patient's Name                      PN: ''\n",
      "(0010,0020) Patient ID                          LO: ''\n",
      "(0010,0021) Issuer of Patient ID                LO: ''\n",
      "(0010,0030) Patient's Birth Date                DA: ''\n",
      "(0010,0040) Patient's Sex                       CS: ''\n",
      "(0018,0015) Body Part Examined                  CS: ''\n",
      "(0018,1020) Software Versions                   LO: '2.0.0'\n",
      "(0018,A001)  Contributing Equipment Sequence  1 item(s) ---- \n",
      "   (0008,0070) Manufacturer                        LO: 'MONAI WG Trainer'\n",
      "   (0008,1090) Manufacturer's Model Name           LO: 'MEDNIST Classifier'\n",
      "   (0018,1002) Device UID                          UI: xyz\n",
      "   (0018,1020) Software Versions                   LO: '0.1'\n",
      "   (0040,A170)  Purpose of Reference Code Sequence  1 item(s) ---- \n",
      "      (0008,0100) Code Value                          SH: 'Newcode1'\n",
      "      (0008,0102) Coding Scheme Designator            SH: '99IHE'\n",
      "      (0008,0104) Code Meaning                        LO: '\"Processing Algorithm'\n",
      "      ---------\n",
      "   ---------\n",
      "(0020,000D) Study Instance UID                  UI: 1.2.826.0.1.3680043.8.498.62792986904071080344578561194802396873\n",
      "(0020,000E) Series Instance UID                 UI: 1.2.826.0.1.3680043.8.498.57204416465564820510862751799072609586\n",
      "(0020,0010) Study ID                            SH: '1'\n",
      "(0020,0011) Series Number                       IS: '5022'\n",
      "(0020,0013) Instance Number                     IS: '1'\n",
      "(0040,1001) Requested Procedure ID              SH: ''\n",
      "(0040,A040) Value Type                          CS: 'CONTAINER'\n",
      "(0040,A043)  Concept Name Code Sequence  1 item(s) ---- \n",
      "   (0008,0100) Code Value                          SH: '18748-4'\n",
      "   (0008,0102) Coding Scheme Designator            SH: 'LN'\n",
      "   (0008,0104) Code Meaning                        LO: 'Diagnostic Imaging Report'\n",
      "   ---------\n",
      "(0040,A050) Continuity Of Content               CS: 'SEPARATE'\n",
      "(0040,A493) Verification Flag                   CS: 'UNVERIFIED'\n",
      "(0040,A730)  Content Sequence  1 item(s) ---- \n",
      "   (0040,A010) Relationship Type                   CS: 'CONTAINS'\n",
      "   (0040,A040) Value Type                          CS: 'TEXT'\n",
      "   (0040,A043)  Concept Name Code Sequence  1 item(s) ---- \n",
      "      (0008,0100) Code Value                          SH: '111412'\n",
      "      (0008,0102) Coding Scheme Designator            SH: 'DCM'\n",
      "      (0008,0104) Code Meaning                        LO: 'Narrative Summary'\n",
      "      ---------\n",
      "   (0040,A160) Text Value                          UT: 'AbdomenCT'\n",
      "   ---------\n",
      "[2025-01-16 10:40:39,612] [WARNING] (pydicom) - 'write_like_original' is deprecated and will be removed in v4.0, please use 'enforce_file_format' instead\n",
      "[2025-01-16 10:40:39,615] [INFO] (root) - Finished writing DICOM instance to file /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/1.2.826.0.1.3680043.8.498.60677937641932107808557347299901104083.dcm\n",
      "[2025-01-16 10:40:39,615] [INFO] (monai.deploy.operators.dicom_text_sr_writer_operator.DICOMTextSRWriterOperator) - DICOM SOP instance saved in /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/1.2.826.0.1.3680043.8.498.60677937641932107808557347299901104083.dcm\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:372] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:401] Scheduler finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2213] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:2221] Graph execution finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:292] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!python \"mednist_app/mednist_classifier_monaideploy.py\" -i {input_folder} -o {output_folder} -m {models_folder} -l DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat {output_folder}/output.json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional file required for packaging the app (creating MAP Docker image)\n",
    "\n",
    "In this version of the App SDK, we need to write out the configuration yaml file as well as the package requirements file, in the application folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/app.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/app.yaml\n",
    "%YAML 1.2\n",
    "---\n",
    "application:\n",
    "  title: MONAI Deploy App Package - MedNIST Classifier App\n",
    "  version: 1.0\n",
    "  inputFormats: [\"file\"]\n",
    "  outputFormats: [\"file\"]\n",
    "\n",
    "resources:\n",
    "  cpu: 1\n",
    "  gpu: 1\n",
    "  memory: 1Gi\n",
    "  gpuMemory: 1Gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/requirements.txt\n",
    "monai>=1.2.0\n",
    "Pillow>=8.4.0\n",
    "pydicom>=2.3.0\n",
    "highdicom>=0.18.2\n",
    "SimpleITK>=2.0.0\n",
    "setuptools>=59.5.0 # for pkg_resources\n",
    "holoscan==2.6.0  # avoid v2.7 and v2.8 for a known issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, we have built the application and prepared all necessary files for create the MONAI Application Package (MAP)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
