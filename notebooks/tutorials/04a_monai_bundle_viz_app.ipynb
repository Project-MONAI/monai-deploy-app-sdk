{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Deploy App with MONAI Deploy App SDK and MONAI Bundle\n",
    "\n",
    "This tutorial shows how to create an organ segmentation application for a PyTorch model that has been trained with MONAI and packaged in the [MONAI Bundle](https://docs.monai.io/en/latest/bundle_intro.html) format.\n",
    "\n",
    "Deploying AI models requires the integration with clinical imaging network, even if in a for-research-use setting. This means that the AI deploy application will need to support standards-based imaging protocols, and specifically for Radiological imaging, DICOM protocol.\n",
    "\n",
    "Typically, DICOM network communication, either in DICOM TCP/IP network protocol or DICOMWeb, would be handled by DICOM devices or services, e.g. MONAI Deploy Informatics Gateway, so the deploy application itself would only need to use DICOM Part 10 files as input and save the AI result in DICOM Part10 file(s). For segmentation use cases, the DICOM instance file for AI results could be a DICOM Segmentation object or a DICOM RT Structure Set, and for classification, DICOM Structure Report and/or DICOM Encapsulated PDF.\n",
    "\n",
    "When integrated with imaging networks and receiving DICOM instances from modalities and Picture Archiving and Communications System (PACS), an AI deploy application has to deal with a whole DICOM study with multiple series, whose images' spacing may not be the same as expected by the trained model. To address these cases consistently and efficiently, MONAI Deploy Application SDK provides classes, called operators, to parse DICOM studies, select specific series with application-defined rules, and convert the selected DICOM series into domain-specific image format along with meta-data representing the pertinent DICOM attributes. The image is then further processed in the pre-processing stage to normalize spacing, orientation, intensity,etc, before pixel data as Tensors are used for inference.\n",
    "\n",
    "In the following sections, we will demonstrate how to create a MONAI Deploy application package using the MONAI Deploy App SDK, and importantly, using the built-in MONAI Bundle Inference Operator to perform inference with the Spleen CT Segmentation PyTorch model in a MONAI Bundle.\n",
    "\n",
    ":::{note}\n",
    "For local testing, if there is a lack of DICOM Part 10 files, one can use open source programs, e.g. 3D Slicer, to convert a NIfTI file to a DICOM series.\n",
    "\n",
    "To make running this example simpler, the DICOM files and the [Spleen CT Segmentation MONAI Bundle](https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation), published in [MONAI Model Zoo](https://github.com/Project-MONAI/model-zoo), have been packaged and shared on Google Drive.\n",
    "\n",
    ":::\n",
    "\n",
    "## Creating Operators and connecting them in Application class\n",
    "\n",
    "We will implement an application that consists of five Operators:\n",
    "\n",
    "- **DICOMDataLoaderOperator**:\n",
    "    - **Input(dicom_files)**: a folder path ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "    - **Output(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "- **DICOMSeriesSelectorOperator**:\n",
    "    - **Input(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "    - **Input(selection_rules)**: a selection rule (Dict)\n",
    "    - **Output(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "- **DICOMSeriesToVolumeOperator**:\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **MonaiBundleInferenceOperator**:\n",
    "    - **Input(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output(pred)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **DICOMSegmentationWriterOperator**:\n",
    "    - **Input(seg_image)**: a segmentation image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(dicom_seg_instance)**: a file path ([`DataPath`](/modules/_autosummary/monai.deploy.core.domain.DataPath))\n",
    "\n",
    "\n",
    ":::{note}\n",
    "The `DICOMSegmentationWriterOperator` needs both the segmentation image as well as the original DICOM series meta-data in order to use the patient demographics and the DICOM Study level attributes.\n",
    ":::\n",
    "\n",
    "The workflow of the application is illustrated below.\n",
    "\n",
    "```{mermaid}\n",
    "%%{init: {\"theme\": \"base\", \"themeVariables\": { \"fontSize\": \"16px\"}} }%%\n",
    "\n",
    "classDiagram\n",
    "    direction TB\n",
    "\n",
    "    DICOMDataLoaderOperator --|> DICOMSeriesSelectorOperator : dicom_study_list...dicom_study_list\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSeriesToVolumeOperator : study_selected_series_list...study_selected_series_list\n",
    "    DICOMSeriesToVolumeOperator --|> MonaiBundleInferenceOperator : image...image\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSegmentationWriterOperator : study_selected_series_list...study_selected_series_list\n",
    "    MonaiBundleInferenceOperator --|> DICOMSegmentationWriterOperator : pred...seg_image\n",
    "\n",
    "\n",
    "    class DICOMDataLoaderOperator {\n",
    "        <in>dicom_files : DISK\n",
    "        dicom_study_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesSelectorOperator {\n",
    "        <in>dicom_study_list : IN_MEMORY\n",
    "        <in>selection_rules : IN_MEMORY\n",
    "        study_selected_series_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesToVolumeOperator {\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        image(out) IN_MEMORY\n",
    "    }\n",
    "    class MonaiBundleInferenceOperator {\n",
    "        <in>image : IN_MEMORY\n",
    "        pred(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSegmentationWriterOperator {\n",
    "        <in>seg_image : IN_MEMORY\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        dicom_seg_instance(out) DISK\n",
    "    }\n",
    "```\n",
    "\n",
    "### Setup environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MONAI and other necessary image processing packages for the application\n",
    "!python -c \"import monai\" || pip install --upgrade -q \"monai\"\n",
    "!python -c \"import torch\" || pip install -q \"torch>=1.12.0\"\n",
    "!python -c \"import numpy\" || pip install -q \"numpy>=1.21.6\"\n",
    "!python -c \"import nibabel\" || pip install -q \"nibabel>=3.2.1\"\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=2.3.0\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\"\n",
    "!python -c \"import SimpleITK\" || pip install -q \"SimpleITK>=2.0.0\"\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!python -c \"import holoscan\" || pip install --upgrade -q \"holoscan>=0.5.0\"\n",
    "!python -c \"import monai.deploy\" || pip install --upgrade -q \"monai-deploy-app-sdk\"\n",
    "\n",
    "# Install Clara Viz package\n",
    "!python -c \"import clara.viz\" || pip install --upgrade -q \"clara-viz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you may need to restart the Jupyter kernel to use the updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download/Extract input and model/bundle files from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (4.6.4)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (3.10.0)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: six in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (4.65.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from gdown) (4.12.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from beautifulsoup4->gdown) (2.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (2022.12.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\n",
      "To: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/ai_spleen_seg_bundle_data.zip\n",
      "100%|██████████████████████████████████████| 79.4M/79.4M [00:00<00:00, 80.9MB/s]\n",
      "Archive:  ai_spleen_seg_bundle_data.zip\n",
      "  inflating: dcm/1-001.dcm           \n",
      "  inflating: dcm/1-002.dcm           \n",
      "  inflating: dcm/1-003.dcm           \n",
      "  inflating: dcm/1-004.dcm           \n",
      "  inflating: dcm/1-005.dcm           \n",
      "  inflating: dcm/1-006.dcm           \n",
      "  inflating: dcm/1-007.dcm           \n",
      "  inflating: dcm/1-008.dcm           \n",
      "  inflating: dcm/1-009.dcm           \n",
      "  inflating: dcm/1-010.dcm           \n",
      "  inflating: dcm/1-011.dcm           \n",
      "  inflating: dcm/1-012.dcm           \n",
      "  inflating: dcm/1-013.dcm           \n",
      "  inflating: dcm/1-014.dcm           \n",
      "  inflating: dcm/1-015.dcm           \n",
      "  inflating: dcm/1-016.dcm           \n",
      "  inflating: dcm/1-017.dcm           \n",
      "  inflating: dcm/1-018.dcm           \n",
      "  inflating: dcm/1-019.dcm           \n",
      "  inflating: dcm/1-020.dcm           \n",
      "  inflating: dcm/1-021.dcm           \n",
      "  inflating: dcm/1-022.dcm           \n",
      "  inflating: dcm/1-023.dcm           \n",
      "  inflating: dcm/1-024.dcm           \n",
      "  inflating: dcm/1-025.dcm           \n",
      "  inflating: dcm/1-026.dcm           \n",
      "  inflating: dcm/1-027.dcm           \n",
      "  inflating: dcm/1-028.dcm           \n",
      "  inflating: dcm/1-029.dcm           \n",
      "  inflating: dcm/1-030.dcm           \n",
      "  inflating: dcm/1-031.dcm           \n",
      "  inflating: dcm/1-032.dcm           \n",
      "  inflating: dcm/1-033.dcm           \n",
      "  inflating: dcm/1-034.dcm           \n",
      "  inflating: dcm/1-035.dcm           \n",
      "  inflating: dcm/1-036.dcm           \n",
      "  inflating: dcm/1-037.dcm           \n",
      "  inflating: dcm/1-038.dcm           \n",
      "  inflating: dcm/1-039.dcm           \n",
      "  inflating: dcm/1-040.dcm           \n",
      "  inflating: dcm/1-041.dcm           \n",
      "  inflating: dcm/1-042.dcm           \n",
      "  inflating: dcm/1-043.dcm           \n",
      "  inflating: dcm/1-044.dcm           \n",
      "  inflating: dcm/1-045.dcm           \n",
      "  inflating: dcm/1-046.dcm           \n",
      "  inflating: dcm/1-047.dcm           \n",
      "  inflating: dcm/1-048.dcm           \n",
      "  inflating: dcm/1-049.dcm           \n",
      "  inflating: dcm/1-050.dcm           \n",
      "  inflating: dcm/1-051.dcm           \n",
      "  inflating: dcm/1-052.dcm           \n",
      "  inflating: dcm/1-053.dcm           \n",
      "  inflating: dcm/1-054.dcm           \n",
      "  inflating: dcm/1-055.dcm           \n",
      "  inflating: dcm/1-056.dcm           \n",
      "  inflating: dcm/1-057.dcm           \n",
      "  inflating: dcm/1-058.dcm           \n",
      "  inflating: dcm/1-059.dcm           \n",
      "  inflating: dcm/1-060.dcm           \n",
      "  inflating: dcm/1-061.dcm           \n",
      "  inflating: dcm/1-062.dcm           \n",
      "  inflating: dcm/1-063.dcm           \n",
      "  inflating: dcm/1-064.dcm           \n",
      "  inflating: dcm/1-065.dcm           \n",
      "  inflating: dcm/1-066.dcm           \n",
      "  inflating: dcm/1-067.dcm           \n",
      "  inflating: dcm/1-068.dcm           \n",
      "  inflating: dcm/1-069.dcm           \n",
      "  inflating: dcm/1-070.dcm           \n",
      "  inflating: dcm/1-071.dcm           \n",
      "  inflating: dcm/1-072.dcm           \n",
      "  inflating: dcm/1-073.dcm           \n",
      "  inflating: dcm/1-074.dcm           \n",
      "  inflating: dcm/1-075.dcm           \n",
      "  inflating: dcm/1-076.dcm           \n",
      "  inflating: dcm/1-077.dcm           \n",
      "  inflating: dcm/1-078.dcm           \n",
      "  inflating: dcm/1-079.dcm           \n",
      "  inflating: dcm/1-080.dcm           \n",
      "  inflating: dcm/1-081.dcm           \n",
      "  inflating: dcm/1-082.dcm           \n",
      "  inflating: dcm/1-083.dcm           \n",
      "  inflating: dcm/1-084.dcm           \n",
      "  inflating: dcm/1-085.dcm           \n",
      "  inflating: dcm/1-086.dcm           \n",
      "  inflating: dcm/1-087.dcm           \n",
      "  inflating: dcm/1-088.dcm           \n",
      "  inflating: dcm/1-089.dcm           \n",
      "  inflating: dcm/1-090.dcm           \n",
      "  inflating: dcm/1-091.dcm           \n",
      "  inflating: dcm/1-092.dcm           \n",
      "  inflating: dcm/1-093.dcm           \n",
      "  inflating: dcm/1-094.dcm           \n",
      "  inflating: dcm/1-095.dcm           \n",
      "  inflating: dcm/1-096.dcm           \n",
      "  inflating: dcm/1-097.dcm           \n",
      "  inflating: dcm/1-098.dcm           \n",
      "  inflating: dcm/1-099.dcm           \n",
      "  inflating: dcm/1-100.dcm           \n",
      "  inflating: dcm/1-101.dcm           \n",
      "  inflating: dcm/1-102.dcm           \n",
      "  inflating: dcm/1-103.dcm           \n",
      "  inflating: dcm/1-104.dcm           \n",
      "  inflating: dcm/1-105.dcm           \n",
      "  inflating: dcm/1-106.dcm           \n",
      "  inflating: dcm/1-107.dcm           \n",
      "  inflating: dcm/1-108.dcm           \n",
      "  inflating: dcm/1-109.dcm           \n",
      "  inflating: dcm/1-110.dcm           \n",
      "  inflating: dcm/1-111.dcm           \n",
      "  inflating: dcm/1-112.dcm           \n",
      "  inflating: dcm/1-113.dcm           \n",
      "  inflating: dcm/1-114.dcm           \n",
      "  inflating: dcm/1-115.dcm           \n",
      "  inflating: dcm/1-116.dcm           \n",
      "  inflating: dcm/1-117.dcm           \n",
      "  inflating: dcm/1-118.dcm           \n",
      "  inflating: dcm/1-119.dcm           \n",
      "  inflating: dcm/1-120.dcm           \n",
      "  inflating: dcm/1-121.dcm           \n",
      "  inflating: dcm/1-122.dcm           \n",
      "  inflating: dcm/1-123.dcm           \n",
      "  inflating: dcm/1-124.dcm           \n",
      "  inflating: dcm/1-125.dcm           \n",
      "  inflating: dcm/1-126.dcm           \n",
      "  inflating: dcm/1-127.dcm           \n",
      "  inflating: dcm/1-128.dcm           \n",
      "  inflating: dcm/1-129.dcm           \n",
      "  inflating: dcm/1-130.dcm           \n",
      "  inflating: dcm/1-131.dcm           \n",
      "  inflating: dcm/1-132.dcm           \n",
      "  inflating: dcm/1-133.dcm           \n",
      "  inflating: dcm/1-134.dcm           \n",
      "  inflating: dcm/1-135.dcm           \n",
      "  inflating: dcm/1-136.dcm           \n",
      "  inflating: dcm/1-137.dcm           \n",
      "  inflating: dcm/1-138.dcm           \n",
      "  inflating: dcm/1-139.dcm           \n",
      "  inflating: dcm/1-140.dcm           \n",
      "  inflating: dcm/1-141.dcm           \n",
      "  inflating: dcm/1-142.dcm           \n",
      "  inflating: dcm/1-143.dcm           \n",
      "  inflating: dcm/1-144.dcm           \n",
      "  inflating: dcm/1-145.dcm           \n",
      "  inflating: dcm/1-146.dcm           \n",
      "  inflating: dcm/1-147.dcm           \n",
      "  inflating: dcm/1-148.dcm           \n",
      "  inflating: dcm/1-149.dcm           \n",
      "  inflating: dcm/1-150.dcm           \n",
      "  inflating: dcm/1-151.dcm           \n",
      "  inflating: dcm/1-152.dcm           \n",
      "  inflating: dcm/1-153.dcm           \n",
      "  inflating: dcm/1-154.dcm           \n",
      "  inflating: dcm/1-155.dcm           \n",
      "  inflating: dcm/1-156.dcm           \n",
      "  inflating: dcm/1-157.dcm           \n",
      "  inflating: dcm/1-158.dcm           \n",
      "  inflating: dcm/1-159.dcm           \n",
      "  inflating: dcm/1-160.dcm           \n",
      "  inflating: dcm/1-161.dcm           \n",
      "  inflating: dcm/1-162.dcm           \n",
      "  inflating: dcm/1-163.dcm           \n",
      "  inflating: dcm/1-164.dcm           \n",
      "  inflating: dcm/1-165.dcm           \n",
      "  inflating: dcm/1-166.dcm           \n",
      "  inflating: dcm/1-167.dcm           \n",
      "  inflating: dcm/1-168.dcm           \n",
      "  inflating: dcm/1-169.dcm           \n",
      "  inflating: dcm/1-170.dcm           \n",
      "  inflating: dcm/1-171.dcm           \n",
      "  inflating: dcm/1-172.dcm           \n",
      "  inflating: dcm/1-173.dcm           \n",
      "  inflating: dcm/1-174.dcm           \n",
      "  inflating: dcm/1-175.dcm           \n",
      "  inflating: dcm/1-176.dcm           \n",
      "  inflating: dcm/1-177.dcm           \n",
      "  inflating: dcm/1-178.dcm           \n",
      "  inflating: dcm/1-179.dcm           \n",
      "  inflating: dcm/1-180.dcm           \n",
      "  inflating: dcm/1-181.dcm           \n",
      "  inflating: dcm/1-182.dcm           \n",
      "  inflating: dcm/1-183.dcm           \n",
      "  inflating: dcm/1-184.dcm           \n",
      "  inflating: dcm/1-185.dcm           \n",
      "  inflating: dcm/1-186.dcm           \n",
      "  inflating: dcm/1-187.dcm           \n",
      "  inflating: dcm/1-188.dcm           \n",
      "  inflating: dcm/1-189.dcm           \n",
      "  inflating: dcm/1-190.dcm           \n",
      "  inflating: dcm/1-191.dcm           \n",
      "  inflating: dcm/1-192.dcm           \n",
      "  inflating: dcm/1-193.dcm           \n",
      "  inflating: dcm/1-194.dcm           \n",
      "  inflating: dcm/1-195.dcm           \n",
      "  inflating: dcm/1-196.dcm           \n",
      "  inflating: dcm/1-197.dcm           \n",
      "  inflating: dcm/1-198.dcm           \n",
      "  inflating: dcm/1-199.dcm           \n",
      "  inflating: dcm/1-200.dcm           \n",
      "  inflating: dcm/1-201.dcm           \n",
      "  inflating: dcm/1-202.dcm           \n",
      "  inflating: dcm/1-203.dcm           \n",
      "  inflating: dcm/1-204.dcm           \n",
      "  inflating: model.ts                \n"
     ]
    }
   ],
   "source": [
    "# Download the test data and MONAI bundle zip file\n",
    "!pip install gdown\n",
    "!gdown \"https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\"\n",
    "\n",
    "# After downloading ai_spleen_bundle_data zip file from the web browser or using gdown,\n",
    "!unzip -o \"ai_spleen_seg_bundle_data.zip\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=dcm\n",
      "env: HOLOSCAN_MODEL_PATH=model.ts\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n",
      "1-001.dcm  1-031.dcm  1-061.dcm  1-091.dcm  1-121.dcm  1-151.dcm  1-181.dcm\n",
      "1-002.dcm  1-032.dcm  1-062.dcm  1-092.dcm  1-122.dcm  1-152.dcm  1-182.dcm\n",
      "1-003.dcm  1-033.dcm  1-063.dcm  1-093.dcm  1-123.dcm  1-153.dcm  1-183.dcm\n",
      "1-004.dcm  1-034.dcm  1-064.dcm  1-094.dcm  1-124.dcm  1-154.dcm  1-184.dcm\n",
      "1-005.dcm  1-035.dcm  1-065.dcm  1-095.dcm  1-125.dcm  1-155.dcm  1-185.dcm\n",
      "1-006.dcm  1-036.dcm  1-066.dcm  1-096.dcm  1-126.dcm  1-156.dcm  1-186.dcm\n",
      "1-007.dcm  1-037.dcm  1-067.dcm  1-097.dcm  1-127.dcm  1-157.dcm  1-187.dcm\n",
      "1-008.dcm  1-038.dcm  1-068.dcm  1-098.dcm  1-128.dcm  1-158.dcm  1-188.dcm\n",
      "1-009.dcm  1-039.dcm  1-069.dcm  1-099.dcm  1-129.dcm  1-159.dcm  1-189.dcm\n",
      "1-010.dcm  1-040.dcm  1-070.dcm  1-100.dcm  1-130.dcm  1-160.dcm  1-190.dcm\n",
      "1-011.dcm  1-041.dcm  1-071.dcm  1-101.dcm  1-131.dcm  1-161.dcm  1-191.dcm\n",
      "1-012.dcm  1-042.dcm  1-072.dcm  1-102.dcm  1-132.dcm  1-162.dcm  1-192.dcm\n",
      "1-013.dcm  1-043.dcm  1-073.dcm  1-103.dcm  1-133.dcm  1-163.dcm  1-193.dcm\n",
      "1-014.dcm  1-044.dcm  1-074.dcm  1-104.dcm  1-134.dcm  1-164.dcm  1-194.dcm\n",
      "1-015.dcm  1-045.dcm  1-075.dcm  1-105.dcm  1-135.dcm  1-165.dcm  1-195.dcm\n",
      "1-016.dcm  1-046.dcm  1-076.dcm  1-106.dcm  1-136.dcm  1-166.dcm  1-196.dcm\n",
      "1-017.dcm  1-047.dcm  1-077.dcm  1-107.dcm  1-137.dcm  1-167.dcm  1-197.dcm\n",
      "1-018.dcm  1-048.dcm  1-078.dcm  1-108.dcm  1-138.dcm  1-168.dcm  1-198.dcm\n",
      "1-019.dcm  1-049.dcm  1-079.dcm  1-109.dcm  1-139.dcm  1-169.dcm  1-199.dcm\n",
      "1-020.dcm  1-050.dcm  1-080.dcm  1-110.dcm  1-140.dcm  1-170.dcm  1-200.dcm\n",
      "1-021.dcm  1-051.dcm  1-081.dcm  1-111.dcm  1-141.dcm  1-171.dcm  1-201.dcm\n",
      "1-022.dcm  1-052.dcm  1-082.dcm  1-112.dcm  1-142.dcm  1-172.dcm  1-202.dcm\n",
      "1-023.dcm  1-053.dcm  1-083.dcm  1-113.dcm  1-143.dcm  1-173.dcm  1-203.dcm\n",
      "1-024.dcm  1-054.dcm  1-084.dcm  1-114.dcm  1-144.dcm  1-174.dcm  1-204.dcm\n",
      "1-025.dcm  1-055.dcm  1-085.dcm  1-115.dcm  1-145.dcm  1-175.dcm\n",
      "1-026.dcm  1-056.dcm  1-086.dcm  1-116.dcm  1-146.dcm  1-176.dcm\n",
      "1-027.dcm  1-057.dcm  1-087.dcm  1-117.dcm  1-147.dcm  1-177.dcm\n",
      "1-028.dcm  1-058.dcm  1-088.dcm  1-118.dcm  1-148.dcm  1-178.dcm\n",
      "1-029.dcm  1-059.dcm  1-089.dcm  1-119.dcm  1-149.dcm  1-179.dcm\n",
      "1-030.dcm  1-060.dcm  1-090.dcm  1-120.dcm  1-150.dcm  1-180.dcm\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH dcm\n",
    "%env HOLOSCAN_MODEL_PATH model.ts\n",
    "%env HOLOSCAN_OUTPUT_PATH output\n",
    "%ls $HOLOSCAN_INPUT_PATH"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up imports\n",
    "\n",
    "Let's import necessary classes/decorators to define Application and Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application\n",
    "from monai.deploy.core.domain import Image\n",
    "from monai.deploy.core.io_type import IOType\n",
    "from monai.deploy.logger import load_env_log_level\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.monai_bundle_inference_operator import (\n",
    "    BundleConfigNames,\n",
    "    IOMapping,\n",
    "    MonaiBundleInferenceOperator,\n",
    ")\n",
    "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n",
    "from monai.deploy.operators.clara_viz_operator import ClaraVizOperator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Input and Output for the Model Bundle Inference Operator\n",
    "\n",
    "The App SDK provides a `MonaiBundleInferenceOperator` class to perform inference with a MONAI Bundle, which is essentially a PyTorch model in TorchScript with additional metadata describing the model network and processing specification. This operator uses the MONAI utilities to parse a MONAI Bundle to automatically instantiate the objects required for input and output processing as well as inference, as such it depends on MONAI transforms, inferers, and in turn their dependencies.\n",
    "\n",
    "Each Operator class inherits from the base [Operator](/modules/_autosummary/monai.deploy.core.Operator) class, and its input/output properties are specified by using [@input](/modules/_autosummary/monai.deploy.core.input)/[@output](/modules/_autosummary/monai.deploy.core.output) decorators. For the `MonaiBundleInferenceOperator` class, the input/output need to be defined to match those of the model network, both in name and data type. For the current release, an `IOMapping` object is used to connect the operator input/output to those of the model network by using the same names. This is likely to change, to be automated, in the future releases once certain limitation in the App SDK is removed.\n",
    "\n",
    "The Spleen CT Segmentation model network has a named input, called \"image\", and the named output called \"pred\", and both are of image type, which can all be mapped to the App SDK [Image](/modules/_autosummary/monai.deploy.core.domain.Image). This piece of information is typically acquired by examining the model metadata `network_data_format` attribute in the bundle, as seen in this [example] (https://github.com/Project-MONAI/model-zoo/blob/dev/models/spleen_ct_segmentation/configs/metadata.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class, inheriting [Application](/modules/_autosummary/monai.deploy.core.Application) class.\n",
    "\n",
    "The requirements (resource and package dependency) for the App can be specified by using [@resource](/modules/_autosummary/monai.deploy.core.resource) and [@env](/modules/_autosummary/monai.deploy.core.env) decorators.\n",
    "\n",
    "Objects required for DICOM parsing, series selection, pixel data conversion to volume image, model specific inference, and the AI result specific DICOM Segmentation object writers are created. The execution pipeline, as a Directed Acyclic Graph, is then constructed by connecting these objects through <a href=\"../../modules/_autosummary/monai.deploy.core.Application.html#monai.deploy.core.Application.add_flow\">self.add_flow()</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AISpleenSegApp(Application):\n",
    "    \"\"\"Demonstrates inference with built-in MONAI Bundle inference operator with DICOM files as input/output\n",
    "\n",
    "    This application loads a set of DICOM instances, select the appropriate series, converts the series to\n",
    "    3D volume image, performs inference with the built-in MONAI Bundle inference operator, including pre-processing\n",
    "    and post-processing, save the segmentation image in a DICOM Seg OID in an instance file, and optionally the\n",
    "    surface mesh in STL format.\n",
    "\n",
    "    Pertinent MONAI Bundle:\n",
    "      https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation\n",
    "\n",
    "    Execution Time Estimate:\n",
    "      With a Nvidia GV100 32GB GPU, for an input DICOM Series of 515 instances, the execution time is around\n",
    "      25 seconds with saving both DICOM Seg and surface mesh STL file, and 15 seconds with DICOM Seg only.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        logging.info(f\"Begin {self.compose.__name__}\")\n",
    "\n",
    "        app_context = AppContext({})  # Let it figure out all the attributes without overriding\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        # Create the custom operator(s) as well as SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"study_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Create the inference operator that supports MONAI Bundle and automates the inference.\n",
    "        # The IOMapping labels match the input and prediction keys in the pre and post processing.\n",
    "        # The model_name is optional when the app has only one model.\n",
    "        # The bundle_path argument optionally can be set to an accessible bundle file path in the dev\n",
    "        # environment, so when the app is packaged into a MAP, the operator can complete the bundle parsing\n",
    "        # during init.\n",
    "\n",
    "        config_names = BundleConfigNames(config_names=[\"inference\"])  # Same as the default\n",
    "\n",
    "        bundle_spleen_seg_op = MonaiBundleInferenceOperator(\n",
    "            self,\n",
    "            input_mapping=[IOMapping(\"image\", Image, IOType.IN_MEMORY)],\n",
    "            output_mapping=[IOMapping(\"pred\", Image, IOType.IN_MEMORY)],\n",
    "            app_context=app_context,\n",
    "            bundle_config_names=config_names,\n",
    "            bundle_path=model_path,\n",
    "            name=\"bundle_spleen_seg_op\",\n",
    "        )\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue. The segment_label, algorithm_name,\n",
    "        # and algorithm_version are of DICOM VR LO type, limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=\"volumetric (3D) segmentation of the spleen from CT image\",\n",
    "                algorithm_family=codes.DCM.ArtificialIntelligence,\n",
    "                algorithm_version=\"0.3.2\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dicom_seg_writer\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, bundle_spleen_seg_op, {(\"image\", \"image\")})\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, dicom_seg_writer, {(\"pred\", \"seg_image\")})\n",
    "        # Create the surface mesh STL conversion operator and add it to the app execution flow, if needed, by\n",
    "        # uncommenting the following couple lines.\n",
    "        stl_conversion_op = STLConversionOperator(\n",
    "            self, output_file=app_output_path.joinpath(\"stl/spleen.stl\"), name=\"stl_conversion_op\"\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, stl_conversion_op, {(\"pred\", \"image\")})\n",
    "\n",
    "        # Create the ClaraViz operator and feed both the seg and input Image object to it\n",
    "        viz_op = ClaraVizOperator(self, name=\"clara_viz_op\")\n",
    "        self.add_flow(series_to_vol_op, viz_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(bundle_spleen_seg_op, viz_op, {(\"pred\", \"seg_image\")})\n",
    "\n",
    "        logging.info(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing app locally\n",
    "\n",
    "We can execute the app in the Jupyter notebook. Note that the DICOM files of the CT Abdomen series must be present in the `dcm` and the Torch Script model at `model.ts`. Please use the actual path in your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-05 12:08:18,085 - Begin __main__\n",
      "2023-05-05 12:08:18,125 - Begin run\n",
      "\u001b[0m2023-05-05 12:08:18.088 INFO  /workspace/holoscan-sdk/src/core/executors/gxf/gxf_executor.cpp@71: Creating context\u001b[0m\n",
      "2023-05-05 12:08:18,128 - Begin compose\n",
      "2023-05-05 12:08:18,162 - End compose\n",
      "\u001b[0m2023-05-05 12:08:18.165 INFO  gxf/std/greedy_scheduler.cpp@184: Scheduling 10 entities\u001b[0m\n",
      "2023-05-05 12:08:18,166 - No or invalid input path from the optional input port: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-05 12:08:18.127] [holoscan] [info] [gxf_executor.cpp:100] Loading extensions from configs...\n",
      "[2023-05-05 12:08:18.163] [holoscan] [info] [gxf_executor.cpp:291] Activating Graph...\n",
      "[2023-05-05 12:08:18.165] [holoscan] [info] [gxf_executor.cpp:293] Running Graph...\n",
      "[2023-05-05 12:08:18.165] [holoscan] [info] [gxf_executor.cpp:295] Waiting for completion...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-05 12:08:18,709 - Finding series for Selection named: CT Series\n",
      "2023-05-05 12:08:18,711 - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "2023-05-05 12:08:18,711 - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "2023-05-05 12:08:18,712 - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "2023-05-05 12:08:18,712 -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "2023-05-05 12:08:18,713 - Series attribute string value did not match. Try regEx.\n",
      "2023-05-05 12:08:18,714 - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "2023-05-05 12:08:18,714 -     Series attribute Modality value: CT\n",
      "2023-05-05 12:08:18,715 - Series attribute string value did not match. Try regEx.\n",
      "2023-05-05 12:08:18,716 - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "2023-05-05 12:08:18,716 -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "2023-05-05 12:08:18,717 - Series attribute string value did not match. Try regEx.\n",
      "2023-05-05 12:08:18,717 - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in http://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-05 12:08:26,887 - add plane #0 for segment #1\n",
      "2023-05-05 12:08:26,889 - add plane #1 for segment #1\n",
      "2023-05-05 12:08:26,891 - add plane #2 for segment #1\n",
      "2023-05-05 12:08:26,893 - add plane #3 for segment #1\n",
      "2023-05-05 12:08:26,894 - add plane #4 for segment #1\n",
      "2023-05-05 12:08:26,896 - add plane #5 for segment #1\n",
      "2023-05-05 12:08:26,898 - add plane #6 for segment #1\n",
      "2023-05-05 12:08:26,899 - add plane #7 for segment #1\n",
      "2023-05-05 12:08:26,901 - add plane #8 for segment #1\n",
      "2023-05-05 12:08:26,902 - add plane #9 for segment #1\n",
      "2023-05-05 12:08:26,904 - add plane #10 for segment #1\n",
      "2023-05-05 12:08:26,905 - add plane #11 for segment #1\n",
      "2023-05-05 12:08:26,907 - add plane #12 for segment #1\n",
      "2023-05-05 12:08:26,909 - add plane #13 for segment #1\n",
      "2023-05-05 12:08:26,910 - add plane #14 for segment #1\n",
      "2023-05-05 12:08:26,912 - add plane #15 for segment #1\n",
      "2023-05-05 12:08:26,914 - add plane #16 for segment #1\n",
      "2023-05-05 12:08:26,915 - add plane #17 for segment #1\n",
      "2023-05-05 12:08:26,917 - add plane #18 for segment #1\n",
      "2023-05-05 12:08:26,918 - add plane #19 for segment #1\n",
      "2023-05-05 12:08:26,920 - add plane #20 for segment #1\n",
      "2023-05-05 12:08:26,922 - add plane #21 for segment #1\n",
      "2023-05-05 12:08:26,923 - add plane #22 for segment #1\n",
      "2023-05-05 12:08:26,925 - add plane #23 for segment #1\n",
      "2023-05-05 12:08:26,926 - add plane #24 for segment #1\n",
      "2023-05-05 12:08:26,928 - add plane #25 for segment #1\n",
      "2023-05-05 12:08:26,929 - add plane #26 for segment #1\n",
      "2023-05-05 12:08:26,931 - add plane #27 for segment #1\n",
      "2023-05-05 12:08:26,933 - add plane #28 for segment #1\n",
      "2023-05-05 12:08:26,934 - add plane #29 for segment #1\n",
      "2023-05-05 12:08:26,936 - add plane #30 for segment #1\n",
      "2023-05-05 12:08:26,937 - add plane #31 for segment #1\n",
      "2023-05-05 12:08:26,939 - add plane #32 for segment #1\n",
      "2023-05-05 12:08:26,941 - add plane #33 for segment #1\n",
      "2023-05-05 12:08:26,943 - add plane #34 for segment #1\n",
      "2023-05-05 12:08:26,945 - add plane #35 for segment #1\n",
      "2023-05-05 12:08:26,947 - add plane #36 for segment #1\n",
      "2023-05-05 12:08:26,949 - add plane #37 for segment #1\n",
      "2023-05-05 12:08:26,951 - add plane #38 for segment #1\n",
      "2023-05-05 12:08:26,953 - add plane #39 for segment #1\n",
      "2023-05-05 12:08:26,955 - add plane #40 for segment #1\n",
      "2023-05-05 12:08:26,957 - add plane #41 for segment #1\n",
      "2023-05-05 12:08:26,959 - add plane #42 for segment #1\n",
      "2023-05-05 12:08:26,961 - add plane #43 for segment #1\n",
      "2023-05-05 12:08:26,963 - add plane #44 for segment #1\n",
      "2023-05-05 12:08:26,965 - add plane #45 for segment #1\n",
      "2023-05-05 12:08:26,967 - add plane #46 for segment #1\n",
      "2023-05-05 12:08:26,969 - add plane #47 for segment #1\n",
      "2023-05-05 12:08:26,971 - add plane #48 for segment #1\n",
      "2023-05-05 12:08:26,974 - add plane #49 for segment #1\n",
      "2023-05-05 12:08:26,976 - add plane #50 for segment #1\n",
      "2023-05-05 12:08:26,978 - add plane #51 for segment #1\n",
      "2023-05-05 12:08:26,980 - add plane #52 for segment #1\n",
      "2023-05-05 12:08:26,982 - add plane #53 for segment #1\n",
      "2023-05-05 12:08:26,984 - add plane #54 for segment #1\n",
      "2023-05-05 12:08:26,987 - add plane #55 for segment #1\n",
      "2023-05-05 12:08:26,989 - add plane #56 for segment #1\n",
      "2023-05-05 12:08:26,991 - add plane #57 for segment #1\n",
      "2023-05-05 12:08:26,993 - add plane #58 for segment #1\n",
      "2023-05-05 12:08:26,996 - add plane #59 for segment #1\n",
      "2023-05-05 12:08:26,999 - add plane #60 for segment #1\n",
      "2023-05-05 12:08:27,002 - add plane #61 for segment #1\n",
      "2023-05-05 12:08:27,004 - add plane #62 for segment #1\n",
      "2023-05-05 12:08:27,007 - add plane #63 for segment #1\n",
      "2023-05-05 12:08:27,009 - add plane #64 for segment #1\n",
      "2023-05-05 12:08:27,012 - add plane #65 for segment #1\n",
      "2023-05-05 12:08:27,014 - add plane #66 for segment #1\n",
      "2023-05-05 12:08:27,016 - add plane #67 for segment #1\n",
      "2023-05-05 12:08:27,019 - add plane #68 for segment #1\n",
      "2023-05-05 12:08:27,021 - add plane #69 for segment #1\n",
      "2023-05-05 12:08:27,024 - add plane #70 for segment #1\n",
      "2023-05-05 12:08:27,026 - add plane #71 for segment #1\n",
      "2023-05-05 12:08:27,028 - add plane #72 for segment #1\n",
      "2023-05-05 12:08:27,036 - add plane #73 for segment #1\n",
      "2023-05-05 12:08:27,040 - add plane #74 for segment #1\n",
      "2023-05-05 12:08:27,044 - add plane #75 for segment #1\n",
      "2023-05-05 12:08:27,048 - add plane #76 for segment #1\n",
      "2023-05-05 12:08:27,051 - add plane #77 for segment #1\n",
      "2023-05-05 12:08:27,054 - add plane #78 for segment #1\n",
      "2023-05-05 12:08:27,057 - add plane #79 for segment #1\n",
      "2023-05-05 12:08:27,060 - add plane #80 for segment #1\n",
      "2023-05-05 12:08:27,062 - add plane #81 for segment #1\n",
      "2023-05-05 12:08:27,065 - add plane #82 for segment #1\n",
      "2023-05-05 12:08:27,067 - add plane #83 for segment #1\n",
      "2023-05-05 12:08:27,070 - add plane #84 for segment #1\n",
      "2023-05-05 12:08:27,072 - add plane #85 for segment #1\n",
      "2023-05-05 12:08:27,074 - add plane #86 for segment #1\n",
      "2023-05-05 12:08:27,132 - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "2023-05-05 12:08:27,133 - copy attributes of module \"Specimen\"\n",
      "2023-05-05 12:08:27,134 - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "2023-05-05 12:08:27,134 - copy attributes of module \"Patient\"\n",
      "2023-05-05 12:08:27,135 - copy attributes of module \"Clinical Trial Subject\"\n",
      "2023-05-05 12:08:27,136 - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "2023-05-05 12:08:27,136 - copy attributes of module \"General Study\"\n",
      "2023-05-05 12:08:27,137 - copy attributes of module \"Patient Study\"\n",
      "2023-05-05 12:08:27,138 - copy attributes of module \"Clinical Trial Study\"\n",
      "2023-05-05 12:08:27,240 - Output will be saved in file output/stl/spleen.stl.\n",
      "2023-05-05 12:08:28,529 - 3D image\n",
      "2023-05-05 12:08:28,530 - Image ndarray shape:(204, 512, 512)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8544014b702343a4b21dce1fca093eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Widget(), VBox(children=(interactive(children=(Dropdown(description='View mode', index=2, option…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m2023-05-05 12:08:39.613 INFO  gxf/std/greedy_scheduler.cpp@343: Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\u001b[0m\n",
      "\u001b[0m2023-05-05 12:08:39.613 INFO  gxf/std/greedy_scheduler.cpp@367: Scheduler finished.\u001b[0m\n",
      "2023-05-05 12:08:39,614 - End run\n",
      "2023-05-05 12:08:39,616 - End __main__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-05 12:08:39.613] [holoscan] [info] [gxf_executor.cpp:297] Deactivating Graph...\n"
     ]
    }
   ],
   "source": [
    "load_env_log_level()\n",
    "logging.info(f\"Begin {__name__}\")\n",
    "AISpleenSegApp().run()\n",
    "logging.info(f\"End {__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the above Python code into Python files in an application folder.\n",
    "\n",
    "The application folder structure would look like below:\n",
    "\n",
    "```bash\n",
    "my_app\n",
    "├── __main__.py\n",
    "└── app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p my_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_app/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.py\n",
    "\n",
    "# Copyright 2021-2023 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application\n",
    "from monai.deploy.core.domain import Image\n",
    "from monai.deploy.core.io_type import IOType\n",
    "from monai.deploy.logger import load_env_log_level\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.monai_bundle_inference_operator import (\n",
    "    BundleConfigNames,\n",
    "    IOMapping,\n",
    "    MonaiBundleInferenceOperator,\n",
    ")\n",
    "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n",
    "from monai.deploy.operators.clara_viz_operator import ClaraVizOperator\n",
    "\n",
    "\n",
    "class AISpleenSegApp(Application):\n",
    "    \"\"\"Demonstrates inference with built-in MONAI Bundle inference operator with DICOM files as input/output\n",
    "\n",
    "    This application loads a set of DICOM instances, select the appropriate series, converts the series to\n",
    "    3D volume image, performs inference with the built-in MONAI Bundle inference operator, including pre-processing\n",
    "    and post-processing, save the segmentation image in a DICOM Seg OID in an instance file, and optionally the\n",
    "    surface mesh in STL format.\n",
    "\n",
    "    Pertinent MONAI Bundle:\n",
    "      https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation\n",
    "\n",
    "    Execution Time Estimate:\n",
    "      With a Nvidia GV100 32GB GPU, for an input DICOM Series of 515 instances, the execution time is around\n",
    "      25 seconds with saving both DICOM Seg and surface mesh STL file, and 15 seconds with DICOM Seg only.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        logging.info(f\"Begin {self.compose.__name__}\")\n",
    "\n",
    "        app_context = AppContext({})  # Let it figure out all the attributes without overriding\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        # Create the custom operator(s) as well as SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"study_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Create the inference operator that supports MONAI Bundle and automates the inference.\n",
    "        # The IOMapping labels match the input and prediction keys in the pre and post processing.\n",
    "        # The model_name is optional when the app has only one model.\n",
    "        # The bundle_path argument optionally can be set to an accessible bundle file path in the dev\n",
    "        # environment, so when the app is packaged into a MAP, the operator can complete the bundle parsing\n",
    "        # during init.\n",
    "\n",
    "        config_names = BundleConfigNames(config_names=[\"inference\"])  # Same as the default\n",
    "\n",
    "        bundle_spleen_seg_op = MonaiBundleInferenceOperator(\n",
    "            self,\n",
    "            input_mapping=[IOMapping(\"image\", Image, IOType.IN_MEMORY)],\n",
    "            output_mapping=[IOMapping(\"pred\", Image, IOType.IN_MEMORY)],\n",
    "            app_context=app_context,\n",
    "            bundle_config_names=config_names,\n",
    "            bundle_path=model_path,\n",
    "            name=\"bundle_spleen_seg_op\",\n",
    "        )\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue. The segment_label, algorithm_name,\n",
    "        # and algorithm_version are of DICOM VR LO type, limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=\"volumetric (3D) segmentation of the spleen from CT image\",\n",
    "                algorithm_family=codes.DCM.ArtificialIntelligence,\n",
    "                algorithm_version=\"0.3.2\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dicom_seg_writer\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, bundle_spleen_seg_op, {(\"image\", \"image\")})\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, dicom_seg_writer, {(\"pred\", \"seg_image\")})\n",
    "        # Create the surface mesh STL conversion operator and add it to the app execution flow, if needed, by\n",
    "        # uncommenting the following couple lines.\n",
    "        stl_conversion_op = STLConversionOperator(\n",
    "            self, output_file=app_output_path.joinpath(\"stl/spleen.stl\"), name=\"stl_conversion_op\"\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, stl_conversion_op, {(\"pred\", \"image\")})\n",
    "\n",
    "        # Create the ClaraViz operator and feed both the seg and input Image object to it\n",
    "        viz_op = ClaraVizOperator(self, name=\"clara_viz_op\")\n",
    "        self.add_flow(series_to_vol_op, viz_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(bundle_spleen_seg_op, viz_op, {(\"pred\", \"seg_image\")})\n",
    "\n",
    "        logging.info(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter.\n",
    "\n",
    "### \\_\\_main\\_\\_.py\n",
    "\n",
    "\\_\\_main\\_\\_.py is needed for <a href=\"../../developing_with_sdk/packaging_app.html#required-arguments\">MONAI Application Packager</a> to detect the main application code (`app.py`) when the application is executed with the application folder path (e.g., `python simple_imaging_app`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting my_app/__main__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/__main__.py\n",
    "from app import AISpleenSegApp\n",
    "\n",
    "import logging\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"test\")\n",
    "    AISpleenSegApp().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py\t__main__.py  __pycache__  spleen_seg_operator.py\n"
     ]
    }
   ],
   "source": [
    "!ls my_app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this time, let's execute the app in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m2023-05-05 12:31:39.129 INFO  /workspace/holoscan-sdk/src/core/executors/gxf/gxf_executor.cpp@71: Creating context\u001b[0m\n",
      "2023-05-05 12:31:39,152 - Begin run\n",
      "[2023-05-05 12:31:39.153] [holoscan] [\u001b[32minfo\u001b[m] [gxf_executor.cpp:100] Loading extensions from configs...\n",
      "2023-05-05 12:31:39,153 - Begin compose\n",
      "2023-05-05 12:31:39,184 - End compose\n",
      "[2023-05-05 12:31:39.185] [holoscan] [\u001b[32minfo\u001b[m] [gxf_executor.cpp:291] Activating Graph...\n",
      "[2023-05-05 12:31:39.186] [holoscan] [\u001b[32minfo\u001b[m] [gxf_executor.cpp:293] Running Graph...\n",
      "[2023-05-05 12:31:39.186] [holoscan] [\u001b[32minfo\u001b[m] [gxf_executor.cpp:295] Waiting for completion...\n",
      "\u001b[0m2023-05-05 12:31:39.186 INFO  gxf/std/greedy_scheduler.cpp@184: Scheduling 10 entities\u001b[0m\n",
      "2023-05-05 12:31:39,186 - No or invalid input path from the optional input port: None\n",
      "2023-05-05 12:31:39,565 - Finding series for Selection named: CT Series\n",
      "2023-05-05 12:31:39,565 - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "2023-05-05 12:31:39,566 - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "2023-05-05 12:31:39,566 - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "2023-05-05 12:31:39,566 -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "2023-05-05 12:31:39,566 - Series attribute string value did not match. Try regEx.\n",
      "2023-05-05 12:31:39,566 - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "2023-05-05 12:31:39,566 -     Series attribute Modality value: CT\n",
      "2023-05-05 12:31:39,566 - Series attribute string value did not match. Try regEx.\n",
      "2023-05-05 12:31:39,566 - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "2023-05-05 12:31:39,566 -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "2023-05-05 12:31:39,566 - Series attribute string value did not match. Try regEx.\n",
      "2023-05-05 12:31:39,566 - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in http://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  warnings.warn(\n",
      "2023-05-05 12:31:46,730 - add plane #0 for segment #1\n",
      "2023-05-05 12:31:46,732 - add plane #1 for segment #1\n",
      "2023-05-05 12:31:46,733 - add plane #2 for segment #1\n",
      "2023-05-05 12:31:46,734 - add plane #3 for segment #1\n",
      "2023-05-05 12:31:46,735 - add plane #4 for segment #1\n",
      "2023-05-05 12:31:46,736 - add plane #5 for segment #1\n",
      "2023-05-05 12:31:46,736 - add plane #6 for segment #1\n",
      "2023-05-05 12:31:46,737 - add plane #7 for segment #1\n",
      "2023-05-05 12:31:46,738 - add plane #8 for segment #1\n",
      "2023-05-05 12:31:46,739 - add plane #9 for segment #1\n",
      "2023-05-05 12:31:46,740 - add plane #10 for segment #1\n",
      "2023-05-05 12:31:46,741 - add plane #11 for segment #1\n",
      "2023-05-05 12:31:46,742 - add plane #12 for segment #1\n",
      "2023-05-05 12:31:46,743 - add plane #13 for segment #1\n",
      "2023-05-05 12:31:46,744 - add plane #14 for segment #1\n",
      "2023-05-05 12:31:46,745 - add plane #15 for segment #1\n",
      "2023-05-05 12:31:46,746 - add plane #16 for segment #1\n",
      "2023-05-05 12:31:46,747 - add plane #17 for segment #1\n",
      "2023-05-05 12:31:46,748 - add plane #18 for segment #1\n",
      "2023-05-05 12:31:46,749 - add plane #19 for segment #1\n",
      "2023-05-05 12:31:46,750 - add plane #20 for segment #1\n",
      "2023-05-05 12:31:46,751 - add plane #21 for segment #1\n",
      "2023-05-05 12:31:46,752 - add plane #22 for segment #1\n",
      "2023-05-05 12:31:46,753 - add plane #23 for segment #1\n",
      "2023-05-05 12:31:46,754 - add plane #24 for segment #1\n",
      "2023-05-05 12:31:46,755 - add plane #25 for segment #1\n",
      "2023-05-05 12:31:46,756 - add plane #26 for segment #1\n",
      "2023-05-05 12:31:46,757 - add plane #27 for segment #1\n",
      "2023-05-05 12:31:46,758 - add plane #28 for segment #1\n",
      "2023-05-05 12:31:46,759 - add plane #29 for segment #1\n",
      "2023-05-05 12:31:46,760 - add plane #30 for segment #1\n",
      "2023-05-05 12:31:46,761 - add plane #31 for segment #1\n",
      "2023-05-05 12:31:46,762 - add plane #32 for segment #1\n",
      "2023-05-05 12:31:46,763 - add plane #33 for segment #1\n",
      "2023-05-05 12:31:46,764 - add plane #34 for segment #1\n",
      "2023-05-05 12:31:46,765 - add plane #35 for segment #1\n",
      "2023-05-05 12:31:46,766 - add plane #36 for segment #1\n",
      "2023-05-05 12:31:46,767 - add plane #37 for segment #1\n",
      "2023-05-05 12:31:46,767 - add plane #38 for segment #1\n",
      "2023-05-05 12:31:46,768 - add plane #39 for segment #1\n",
      "2023-05-05 12:31:46,769 - add plane #40 for segment #1\n",
      "2023-05-05 12:31:46,770 - add plane #41 for segment #1\n",
      "2023-05-05 12:31:46,771 - add plane #42 for segment #1\n",
      "2023-05-05 12:31:46,772 - add plane #43 for segment #1\n",
      "2023-05-05 12:31:46,773 - add plane #44 for segment #1\n",
      "2023-05-05 12:31:46,774 - add plane #45 for segment #1\n",
      "2023-05-05 12:31:46,775 - add plane #46 for segment #1\n",
      "2023-05-05 12:31:46,776 - add plane #47 for segment #1\n",
      "2023-05-05 12:31:46,777 - add plane #48 for segment #1\n",
      "2023-05-05 12:31:46,778 - add plane #49 for segment #1\n",
      "2023-05-05 12:31:46,779 - add plane #50 for segment #1\n",
      "2023-05-05 12:31:46,780 - add plane #51 for segment #1\n",
      "2023-05-05 12:31:46,781 - add plane #52 for segment #1\n",
      "2023-05-05 12:31:46,782 - add plane #53 for segment #1\n",
      "2023-05-05 12:31:46,783 - add plane #54 for segment #1\n",
      "2023-05-05 12:31:46,784 - add plane #55 for segment #1\n",
      "2023-05-05 12:31:46,785 - add plane #56 for segment #1\n",
      "2023-05-05 12:31:46,786 - add plane #57 for segment #1\n",
      "2023-05-05 12:31:46,787 - add plane #58 for segment #1\n",
      "2023-05-05 12:31:46,788 - add plane #59 for segment #1\n",
      "2023-05-05 12:31:46,789 - add plane #60 for segment #1\n",
      "2023-05-05 12:31:46,790 - add plane #61 for segment #1\n",
      "2023-05-05 12:31:46,791 - add plane #62 for segment #1\n",
      "2023-05-05 12:31:46,792 - add plane #63 for segment #1\n",
      "2023-05-05 12:31:46,793 - add plane #64 for segment #1\n",
      "2023-05-05 12:31:46,794 - add plane #65 for segment #1\n",
      "2023-05-05 12:31:46,795 - add plane #66 for segment #1\n",
      "2023-05-05 12:31:46,796 - add plane #67 for segment #1\n",
      "2023-05-05 12:31:46,797 - add plane #68 for segment #1\n",
      "2023-05-05 12:31:46,798 - add plane #69 for segment #1\n",
      "2023-05-05 12:31:46,799 - add plane #70 for segment #1\n",
      "2023-05-05 12:31:46,800 - add plane #71 for segment #1\n",
      "2023-05-05 12:31:46,801 - add plane #72 for segment #1\n",
      "2023-05-05 12:31:46,802 - add plane #73 for segment #1\n",
      "2023-05-05 12:31:46,803 - add plane #74 for segment #1\n",
      "2023-05-05 12:31:46,804 - add plane #75 for segment #1\n",
      "2023-05-05 12:31:46,805 - add plane #76 for segment #1\n",
      "2023-05-05 12:31:46,806 - add plane #77 for segment #1\n",
      "2023-05-05 12:31:46,808 - add plane #78 for segment #1\n",
      "2023-05-05 12:31:46,809 - add plane #79 for segment #1\n",
      "2023-05-05 12:31:46,810 - add plane #80 for segment #1\n",
      "2023-05-05 12:31:46,811 - add plane #81 for segment #1\n",
      "2023-05-05 12:31:46,812 - add plane #82 for segment #1\n",
      "2023-05-05 12:31:46,813 - add plane #83 for segment #1\n",
      "2023-05-05 12:31:46,814 - add plane #84 for segment #1\n",
      "2023-05-05 12:31:46,815 - add plane #85 for segment #1\n",
      "2023-05-05 12:31:46,816 - add plane #86 for segment #1\n",
      "2023-05-05 12:31:46,864 - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "2023-05-05 12:31:46,865 - copy attributes of module \"Specimen\"\n",
      "2023-05-05 12:31:46,865 - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "2023-05-05 12:31:46,865 - copy attributes of module \"Patient\"\n",
      "2023-05-05 12:31:46,865 - copy attributes of module \"Clinical Trial Subject\"\n",
      "2023-05-05 12:31:46,865 - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "2023-05-05 12:31:46,865 - copy attributes of module \"General Study\"\n",
      "2023-05-05 12:31:46,865 - copy attributes of module \"Patient Study\"\n",
      "2023-05-05 12:31:46,865 - copy attributes of module \"Clinical Trial Study\"\n",
      "2023-05-05 12:31:46,961 - Output will be saved in file output/stl/spleen.stl.\n",
      "2023-05-05 12:31:48,267 - 3D image\n",
      "2023-05-05 12:31:48,267 - Image ndarray shape:(204, 512, 512)\n",
      "Exception occurred for operator: 'clara_viz_op'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/traitlets/traitlets.py\", line 656, in get\n",
      "    value = obj._trait_values[self.name]\n",
      "KeyError: 'layout'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/deploy/operators/clara_viz_operator.py\", line 114, in compute\n",
      "    widget = Widget()\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/clara/viz/widgets/widget.py\", line 79, in __init__\n",
      "    super(Widget, self).__init__(**kwargs)\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\", line 480, in __init__\n",
      "    self.open()\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\", line 493, in open\n",
      "    state, buffer_paths, buffers = _remove_buffers(self.get_state())\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\", line 591, in get_state\n",
      "    value = to_json(getattr(self, k), self)\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/traitlets/traitlets.py\", line 703, in __get__\n",
      "    return self.get(obj, cls)\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/traitlets/traitlets.py\", line 659, in get\n",
      "    default = obj.trait_defaults(self.name)\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/traitlets/traitlets.py\", line 1872, in trait_defaults\n",
      "    return self._get_trait_default_generator(names[0])(self)\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/traitlets/traitlets.py\", line 627, in default\n",
      "    return self.make_dynamic_default()\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/ipywidgets/widgets/trait_types.py\", line 168, in make_dynamic_default\n",
      "    return self.klass(*(self.default_args or ()),\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\", line 480, in __init__\n",
      "    self.open()\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/ipywidgets/widgets/widget.py\", line 511, in open\n",
      "    self.comm = create_comm(**args)\n",
      "  File \"/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/comm/__init__.py\", line 27, in _create_comm\n",
      "    raise NotImplementedError(\"Cannot \")\n",
      "NotImplementedError: Cannot \n",
      "\u001b[0m2023-05-05 12:31:56.585 INFO  gxf/std/greedy_scheduler.cpp@343: Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\u001b[0m\n",
      "\u001b[0m2023-05-05 12:31:56.585 INFO  gxf/std/greedy_scheduler.cpp@367: Scheduler finished.\u001b[0m\n",
      "[2023-05-05 12:31:56.585] [holoscan] [\u001b[32minfo\u001b[m] [gxf_executor.cpp:297] Deactivating Graph...\n",
      "2023-05-05 12:31:56,586 - End run\n"
     ]
    }
   ],
   "source": [
    "!python my_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.826.0.1.3680043.10.511.3.12261238603895552550823675908544610.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.12630758166938890127403819248199119.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.13096597901857940207245232021669675.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.13179553861865025383226235853759453.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.17388926533738991308007815250566978.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.23793490991542835187547578029858598.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.30270186454698610203395168618664023.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.30490464162936274579388472251736399.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.35280861260524240908880539194328489.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.36898062718290332296841229400741012.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.50905662781411471396234178786271734.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.58695380375390884831286990782807630.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.59477167967116171518347083763624890.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.63882181243080191729094928676268998.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.77716595761326802770604442020050161.dcm\n",
      "1.2.826.0.1.3680043.10.511.3.84287126190770137625836681970766531.dcm\n",
      "final_output.png\n",
      "stl\n"
     ]
    }
   ],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clara-Viz operators added in an application are used for interactive visualization, so the application shall not be packaged."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b4ab1155d0cd1042497eb40fd55b2d15caf4b3c0f9fbfcc7ba4404045d40f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
