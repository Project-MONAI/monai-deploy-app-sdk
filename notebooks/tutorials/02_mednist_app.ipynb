{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying a MedNIST Classifier App with MONAI Deploy App SDK\n",
    "\n",
    "This tutorial demos the process of packaging up a trained model using MONAI Deploy App SDK into an artifact which can be run as a local program performing inference, a workflow job doing the same, and a Docker containerized workflow execution.\n",
    "\n",
    "In this tutorial, we will train a MedNIST classifier like the [MONAI tutorial here](https://github.com/Project-MONAI/tutorials/blob/master/2d_classification/mednist_tutorial.ipynb) and then implement & package the inference application, executing the application locally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a MedNIST classifier model with MONAI Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages for MONAI Core\n",
    "!python -c \"import monai\" || pip install -q \"monai[pillow, tqdm]\"\n",
    "!python -c \"import ignite\" || pip install -q \"monai[ignite]\"\n",
    "!python -c \"import gdown\" || pip install -q \"monai[gdown]\"\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=1.4.2\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\"  # for the use of DICOM Writer operators\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!python -c \"import monai.deploy\" || pip install -q \"monai-deploy-app-sdk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0\n",
      "Numpy version: 1.24.4\n",
      "Pytorch version: 2.0.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: c33f1ba588ee00229a309000e888f9817b4f1934\n",
      "MONAI __file__: /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.1.0\n",
      "scikit-image version: 0.21.0\n",
      "Pillow version: 10.0.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: 4.7.1\n",
      "TorchVision version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "tqdm version: 4.65.0\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.5\n",
      "pandas version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import glob\n",
    "import PIL.Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from ignite.engine import Events\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.engines import SupervisedTrainer\n",
    "from monai.transforms import (\n",
    "    AddChannel,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    "    EnsureType,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "set_determinism(seed=0)\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download dataset\n",
    "\n",
    "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
    "the RSNA Bone Age Challenge(https://www.rsna.org/education/ai-resources-and-training/ai-image-challenge/rsna-pediatric-bone-age-challenge-2017),\n",
    "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
    "\n",
    "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
    "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
    "\n",
    "If you use the MedNIST dataset, please acknowledge the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp_ijj195_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1QsnnkvZyJPcbRoV_ArW8SnE1OTuoVbKE\n",
      "From (redirected): https://drive.google.com/uc?id=1QsnnkvZyJPcbRoV_ArW8SnE1OTuoVbKE&confirm=t&uuid=d974f3a4-5d30-48b6-9b6d-9459b32b4cac\n",
      "To: /tmp/tmp3aa3c3k6/MedNIST.tar.gz\n",
      "100%|██████████| 61.8M/61.8M [00:03<00:00, 19.1MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-03 20:42:12,748 - INFO - Downloaded: /tmp/tmp_ijj195_/MedNIST.tar.gz\n",
      "2023-08-03 20:42:12,856 - INFO - Verified 'MedNIST.tar.gz', md5: 0bc7306e7427e00ad1c5526a6677552d.\n",
      "2023-08-03 20:42:12,857 - INFO - Writing into directory: /tmp/tmp_ijj195_.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)\n",
    "\n",
    "resource = \"https://drive.google.com/uc?id=1QsnnkvZyJPcbRoV_ArW8SnE1OTuoVbKE\"\n",
    "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
    "\n",
    "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
    "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    download_and_extract(resource, compressed_file, root_dir, md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
      "Label counts: [10000, 8954, 10000, 10000, 10000, 10000]\n",
      "Total image count: 58954\n",
      "Image dimensions: 64 x 64\n"
     ]
    }
   ],
   "source": [
    "subdirs = sorted(glob.glob(f\"{data_dir}/*/\"))\n",
    "\n",
    "class_names = [os.path.basename(sd[:-1]) for sd in subdirs]\n",
    "image_files = [glob.glob(f\"{sb}/*\") for sb in subdirs]\n",
    "\n",
    "image_files_list = sum(image_files, [])\n",
    "image_class = sum(([i] * len(f) for i, f in enumerate(image_files)), [])\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {list(map(len, image_files))}\")\n",
    "print(f\"Total image count: {len(image_class)}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and train\n",
    "\n",
    "Here we'll create a transform sequence and train the network, omitting validation and testing since we know this does indeed work and it's not needed here:\n",
    "\n",
    "(train_transforms)="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "  warn_deprecated(obj, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "# just one dataset and loader, we won't bother with validation or testing \n",
    "train_ds = MedNISTDataset(image_files_list, image_class, train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=300, shuffle=True, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = DenseNet121(spatial_dims=2, in_channels=1, out_channels=len(class_names)).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(net.parameters(), 1e-5)\n",
    "max_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 Loss: 0.18928290903568268\n",
      "Epoch 2/5 Loss: 0.06710730493068695\n",
      "Epoch 3/5 Loss: 0.029032323509454727\n",
      "Epoch 4/5 Loss: 0.01877668686211109\n",
      "Epoch 5/5 Loss: 0.01939055137336254\n"
     ]
    }
   ],
   "source": [
    "def _prepare_batch(batch, device, non_blocking):\n",
    "    return tuple(b.to(device) for b in batch)\n",
    "\n",
    "\n",
    "trainer = SupervisedTrainer(device, max_epochs, train_loader, net, opt, loss_function, prepare_batch=_prepare_batch)\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def _print_loss(engine):\n",
    "    print(f\"Epoch {engine.state.epoch}/{engine.state.max_epochs} Loss: {engine.state.output[0]['loss']}\")\n",
    "\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network will be saved out here as a Torchscript object named `classifier.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.script(net).save(\"classifier.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing and Packaging Application with MONAI Deploy App SDK\n",
    "\n",
    "Based on the Torchscript model(`classifier.zip`), we will implement an application that process an input Jpeg image and write the prediction(classification) result as JSON file(`output.json`).\n",
    "\n",
    "### Creating Operators and connecting them in Application class\n",
    "\n",
    "We used the following [train transforms](train_transforms) as pre-transforms during the training.\n",
    "\n",
    "```{code-block} python\n",
    "---\n",
    "lineno-start: 1\n",
    "emphasize-lines: 3,4,5,9\n",
    "caption: |\n",
    "    Train transforms used in training\n",
    "---\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        AddChannel(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "        EnsureType(),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "`RandRotate`, `RandFlip`, and `RandZoom` transforms are used only for training and those are not necessary during the inference.\n",
    "\n",
    "In our inference application, we will define two operators:\n",
    "\n",
    "1. `LoadPILOperator` - Load a JPEG image from the input path and pass the loaded image object to the next operator.\n",
    "    - This Operator does similar job with `LoadImage(image_only=True)` transform in *train_transforms*, but handles only one image.\n",
    "    - **Input**: a file path (`Path`)\n",
    "    - **Output**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "2. `MedNISTClassifierOperator` - Pre-transform the given image by using MONAI's `Compose` class, feed to the Torchscript model (`classifier.zip`), and write the prediction into JSON file(`output.json`)\n",
    "    - Pre-transforms consist of three transforms -- `AddChannel`, `ScaleIntensity`, and `EnsureType`.\n",
    "    - **Input**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output**: a folder path that the prediction result(`output.json`) would be written (`DataPath`)\n",
    "\n",
    "The workflow of the application would look like this.\n",
    "\n",
    "```{mermaid}\n",
    "%%{init: {\"theme\": \"base\", \"themeVariables\": { \"fontSize\": \"16px\"}} }%%\n",
    "\n",
    "classDiagram\n",
    "    direction LR\n",
    "\n",
    "    LoadPILOperator --|> MedNISTClassifierOperator : image...image\n",
    "\n",
    "\n",
    "    class LoadPILOperator {\n",
    "        <in>image : DISK\n",
    "        image(out) IN_MEMORY\n",
    "    }\n",
    "    class MedNISTClassifierOperator {\n",
    "        <in>image : IN_MEMORY\n",
    "        output(out) DISK\n",
    "    }\n",
    "```\n",
    "\n",
    "\n",
    "#### Set up environment variables\n",
    "\n",
    "Before proceeding to the application building and packaging, we first need to set the well-known environment variables, because the application parses them for the input, output, and model folders. Defaults are used if these environment variable are absent.\n",
    "\n",
    "Set the environment variables corresponding to the extracted data path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001420.jpeg\n",
      "classifier.zip\n",
      "env: HOLOSCAN_INPUT_PATH=input\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n",
      "env: HOLOSCAN_MODEL_PATH=models\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"input\"\n",
    "output_foler = \"output\"\n",
    "models_folder = \"models\"\n",
    "\n",
    "# Choose a file as test input\n",
    "test_input_path = image_files[0][0]\n",
    "!rm -rf {input_folder} && mkdir -p {input_folder} && cp {test_input_path} {input_folder} && ls {input_folder}\n",
    "# Need to copy the model file to its own clean subfolder for pacakging, to workaround an issue in the Packager\n",
    "!rm -rf {models_folder} && mkdir -p {models_folder}/model && cp classifier.zip {models_folder}/model && ls {models_folder}/model\n",
    "\n",
    "%env HOLOSCAN_INPUT_PATH {input_folder}\n",
    "%env HOLOSCAN_OUTPUT_PATH {output_foler}\n",
    "%env HOLOSCAN_MODEL_PATH {models_folder}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup imports\n",
    "\n",
    "Let's import necessary classes/decorators and define `MEDNIST_CLASSES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Operator classes\n",
    "\n",
    "##### LoadPILOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MedNISTClassifierOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class inheriting `Application` class.\n",
    "\n",
    "`LoadPILOperator` is connected to `MedNISTClassifierOperator` by using `self.add_flow()` in `compose()` method of `App`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        app_context = AppContext({})  # Let it figure out all the attributes without overriding\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing app locally\n",
    "\n",
    "The test input file file, output path, and model have been prepared, and the paths set in the environment variables, so we can go ahead and execute the application Jupyter notebook with a clean output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[info] [gxf_executor.cpp:210] Creating context\n",
      "[info] [gxf_executor.cpp:1595] Loading extensions from configs...\n",
      "[info] [gxf_executor.cpp:1741] Activating Graph...\n",
      "[info] [gxf_executor.cpp:1771] Running Graph...\n",
      "[info] [gxf_executor.cpp:1773] Waiting for completion...\n",
      "[info] [gxf_executor.cpp:1774] Graph execution waiting. Fragment: \n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AbdomenCT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[info] [gxf_executor.cpp:1783] Graph execution deactivating. Fragment: \n",
      "[info] [gxf_executor.cpp:1784] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:1787] Graph execution finished. Fragment: \n",
      "[info] [gxf_executor.cpp:229] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "app = App().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat $HOLOSCAN_OUTPUT_PATH/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the whole application as a file(`mednist_classifier_monaideploy.py`) by concatenating code above, then add the following lines:\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    App()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p mednist_app\n",
    "!rm -rf mednist_app/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/mednist_classifier_monaideploy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/mednist_classifier_monaideploy.py\n",
    "\n",
    "# Copyright 2021-2023 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application, ConditionType, Fragment, Image, Operator, OperatorSpec\n",
    "from monai.deploy.operators.dicom_text_sr_writer_operator import DICOMTextSRWriterOperator, EquipmentInfo, ModelInfo\n",
    "from monai.transforms import AddChannel, Compose, EnsureType, ScaleIntensity\n",
    "\n",
    "MEDNIST_CLASSES = [\"AbdomenCT\", \"BreastMRI\", \"CXR\", \"ChestCT\", \"Hand\", \"HeadCT\"]\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"pillow\"])\n",
    "class LoadPILOperator(Operator):\n",
    "    \"\"\"Load image from the given input (DataPath) and set numpy array to the output (Image).\"\"\"\n",
    "\n",
    "    DEFAULT_INPUT_FOLDER = Path.cwd() / \"input\"\n",
    "    DEFAULT_OUTPUT_NAME = \"image\"\n",
    "\n",
    "    # For now, need to have the input folder as an instance attribute, set on init.\n",
    "    # If dynamically changing the input folder, per compute, then use a (optional) input port to convey the\n",
    "    # value of the input folder, which is then emitted by a upstream operator.\n",
    "    def __init__(\n",
    "        self,\n",
    "        fragment: Fragment,\n",
    "        *args,\n",
    "        input_folder: Path = DEFAULT_INPUT_FOLDER,\n",
    "        output_name: str = DEFAULT_OUTPUT_NAME,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an loader object with the input folder and the output port name overrides as needed.\n",
    "\n",
    "        Args:\n",
    "            fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "            input_folder (Path): Folder from which to load input file(s).\n",
    "                                 Defaults to `input` in the current working directory.\n",
    "            output_name (str): Name of the output port, which is an image object. Defaults to `image`.\n",
    "        \"\"\"\n",
    "\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        self.input_path = input_folder\n",
    "        self.index = 0\n",
    "        self.output_name_image = (\n",
    "            output_name.strip() if output_name and len(output_name.strip()) > 0 else LoadPILOperator.DEFAULT_OUTPUT_NAME\n",
    "        )\n",
    "\n",
    "        super().__init__(fragment, *args, **kwargs)\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the named input and output port(s)\"\"\"\n",
    "        spec.output(self.output_name_image)\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import numpy as np\n",
    "        from PIL import Image as PILImage\n",
    "\n",
    "        # Input path is stored in the object attribute, but could change to use a named port if need be.\n",
    "        input_path = self.input_path\n",
    "        if input_path.is_dir():\n",
    "            input_path = next(self.input_path.glob(\"*.*\"))  # take the first file\n",
    "\n",
    "        image = PILImage.open(input_path)\n",
    "        image = image.convert(\"L\")  # convert to greyscale image\n",
    "        image_arr = np.asarray(image)\n",
    "\n",
    "        output_image = Image(image_arr)  # create Image domain object with a numpy array\n",
    "        op_output.emit(output_image, self.output_name_image)  # cannot omit the name even if single output.\n",
    "\n",
    "\n",
    "# @md.env(pip_packages=[\"monai\"])\n",
    "class MedNISTClassifierOperator(Operator):\n",
    "    \"\"\"Classifies the given image and returns the class name.\n",
    "\n",
    "    Named inputs:\n",
    "        image: Image object for which to generate the classification.\n",
    "        output_folder: Optional, the path to save the results JSON file, overridingthe the one set on __init__\n",
    "\n",
    "    Named output:\n",
    "        result_text: The classification results in text.\n",
    "    \"\"\"\n",
    "\n",
    "    DEFAULT_OUTPUT_FOLDER = Path.cwd() / \"classification_results\"\n",
    "    # For testing the app directly, the model should be at the following path.\n",
    "    MODEL_LOCAL_PATH = Path(os.environ.get(\"HOLOSCAN_MODEL_PATH\", Path.cwd() / \"model/model.ts\"))\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        frament: Fragment,\n",
    "        *args,\n",
    "        app_context: AppContext,\n",
    "        model_name: Optional[str] = \"\",\n",
    "        model_path: Path = MODEL_LOCAL_PATH,\n",
    "        output_folder: Path = DEFAULT_OUTPUT_FOLDER,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Creates an instance with the reference back to the containing application/fragment.\n",
    "\n",
    "        fragment (Fragment): An instance of the Application class which is derived from Fragment.\n",
    "        model_name (str, optional): Name of the model. Default to \"\" for single model app.\n",
    "        model_path (Path): Path to the model file. Defaults to model/models.ts of current working dir.\n",
    "        output_folder (Path, optional): output folder for saving the classification results JSON file.\n",
    "        \"\"\"\n",
    "\n",
    "        # the names used for the model inference input and output\n",
    "        self._input_dataset_key = \"image\"\n",
    "        self._pred_dataset_key = \"pred\"\n",
    "\n",
    "        # The names used for the operator input and output\n",
    "        self.input_name_image = \"image\"\n",
    "        self.output_name_result = \"result_text\"\n",
    "\n",
    "        # The name of the optional input port for passing data to override the output folder path.\n",
    "        self.input_name_output_folder = \"output_folder\"\n",
    "\n",
    "        # The output folder set on the object can be overriden at each compute by data in the optional named input\n",
    "        self.output_folder = output_folder\n",
    "\n",
    "        # Need the name when there are multiple models loaded\n",
    "        self._model_name = model_name.strip() if isinstance(model_name, str) else \"\"\n",
    "        # Need the path to load the models when they are not loaded in the execution context\n",
    "        self.model_path = model_path\n",
    "        self.app_context = app_context\n",
    "        self.model = self._get_model(self.app_context, self.model_path, self._model_name)\n",
    "\n",
    "        # This needs to be at the end of the constructor.\n",
    "        super().__init__(frament, *args, **kwargs)\n",
    "\n",
    "    def _get_model(self, app_context: AppContext, model_path: Path, model_name: str):\n",
    "        \"\"\"Load the model with the given name from context or model path\n",
    "\n",
    "        Args:\n",
    "            app_context (AppContext): The application context object holding the model(s)\n",
    "            model_path (Path): The path to the model file, as a backup to load model directly\n",
    "            model_name (str): The name of the model, when multiples are loaded in the context\n",
    "        \"\"\"\n",
    "\n",
    "        if app_context.models:\n",
    "            # `app_context.models.get(model_name)` returns a model instance if exists.\n",
    "            # If model_name is not specified and only one model exists, it returns that model.\n",
    "            model = app_context.models.get(model_name)\n",
    "        else:\n",
    "            model = torch.jit.load(\n",
    "                MedNISTClassifierOperator.MODEL_LOCAL_PATH,\n",
    "                map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "            )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def setup(self, spec: OperatorSpec):\n",
    "        \"\"\"Set up the operator named input and named output, both are in-memory objects.\"\"\"\n",
    "\n",
    "        spec.input(self.input_name_image)\n",
    "        spec.input(self.input_name_output_folder).condition(ConditionType.NONE)  # Optional for overriding.\n",
    "        spec.output(self.output_name_result).condition(ConditionType.NONE)  # Not forcing a downstream receiver.\n",
    "\n",
    "    @property\n",
    "    def transform(self):\n",
    "        return Compose([AddChannel(), ScaleIntensity(), EnsureType()])\n",
    "\n",
    "    def compute(self, op_input, op_output, context):\n",
    "        import json\n",
    "\n",
    "        import torch\n",
    "\n",
    "        img = op_input.receive(self.input_name_image).asnumpy()  # (64, 64), uint8. Input validation can be added.\n",
    "        image_tensor = self.transform(img)  # (1, 64, 64), torch.float64\n",
    "        image_tensor = image_tensor[None].float()  # (1, 1, 64, 64), torch.float32\n",
    "\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        image_tensor = image_tensor.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "\n",
    "        _, output_classes = outputs.max(dim=1)\n",
    "\n",
    "        result = MEDNIST_CLASSES[output_classes[0]]  # get the class name\n",
    "        print(result)\n",
    "        op_output.emit(result, self.output_name_result)\n",
    "\n",
    "        # Get output folder, with value in optional input port overriding the obj attribute\n",
    "        output_folder_on_compute = op_input.receive(self.input_name_output_folder) or self.output_folder\n",
    "        Path.mkdir(output_folder_on_compute, parents=True, exist_ok=True)  # Let exception bubble up if raised.\n",
    "        output_path = output_folder_on_compute / \"output.json\"\n",
    "        with open(output_path, \"w\") as fp:\n",
    "            json.dump(result, fp)\n",
    "\n",
    "\n",
    "# @md.resource(cpu=1, gpu=1, memory=\"1Gi\")\n",
    "class App(Application):\n",
    "    \"\"\"Application class for the MedNIST classifier.\"\"\"\n",
    "\n",
    "    def compose(self):\n",
    "        app_context = AppContext({})  # Let it figure out all the attributes without overriding\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "        load_pil_op = LoadPILOperator(self, CountCondition(self, 1), input_folder=app_input_path, name=\"pil_loader_op\")\n",
    "        classifier_op = MedNISTClassifierOperator(\n",
    "            self, app_context=app_context, output_folder=app_output_path, model_path=model_path, name=\"classifier_op\"\n",
    "        )\n",
    "\n",
    "        my_model_info = ModelInfo(\"MONAI WG Trainer\", \"MEDNIST Classifier\", \"0.1\", \"xyz\")\n",
    "        my_equipment = EquipmentInfo(manufacturer=\"MOANI Deploy App SDK\", manufacturer_model=\"DICOM SR Writer\")\n",
    "        my_special_tags = {\"SeriesDescription\": \"Not for clinical use. The result is for research use only.\"}\n",
    "        dicom_sr_operator = DICOMTextSRWriterOperator(\n",
    "            self,\n",
    "            copy_tags=False,\n",
    "            model_info=my_model_info,\n",
    "            equipment_info=my_equipment,\n",
    "            custom_tags=my_special_tags,\n",
    "            output_folder=app_output_path,\n",
    "        )\n",
    "\n",
    "        self.add_flow(load_pil_op, classifier_op, {(\"image\", \"image\")})\n",
    "        self.add_flow(classifier_op, dicom_sr_operator, {(\"result_text\", \"text\")})\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    App().run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's execute the app in the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:210] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1595] Loading extensions from configs...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1741] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1771] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1773] Waiting for completion...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1774] Graph execution waiting. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)  # type: ignore\n",
      "AbdomenCT\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "  warnings.warn(msg)\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1783] Graph execution deactivating. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1784] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1787] Graph execution finished. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:229] Destroying context\n"
     ]
    }
   ],
   "source": [
    "!python \"mednist_app/mednist_classifier_monaideploy.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat $HOLOSCAN_OUTPUT_PATH/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packaging app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's package the app with <a href=\"../../developing_with_sdk/packaging_app.html\">MONAI Application Packager</a>.\n",
    "\n",
    "In this version of the App SDK, we need to write out the configuration yaml file as well as the package requirements file, in the application folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/app.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/app.yaml\n",
    "%YAML 1.2\n",
    "---\n",
    "application:\n",
    "  title: MONAI Deploy App Package - MedNIST Classifier App\n",
    "  version: 1.0\n",
    "  inputFormats: [\"file\"]\n",
    "  outputFormats: [\"file\"]\n",
    "\n",
    "resources:\n",
    "  cpu: 1\n",
    "  gpu: 1\n",
    "  memory: 1Gi\n",
    "  gpuMemory: 1Gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mednist_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile mednist_app/requirements.txt\n",
    "monai>=1.2.0\n",
    "Pillow>=8.4.0\n",
    "pydicom>=2.3.0\n",
    "highdicom>=0.18.2\n",
    "SimpleITK>=2.0.0\n",
    "setuptools>=59.5.0 # for pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n",
      "[2023-08-03 20:49:29,599] [INFO] (packager.parameters) - Application: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/mednist_app/mednist_classifier_monaideploy.py\n",
      "[2023-08-03 20:49:29,599] [INFO] (packager.parameters) - Detected application type: Python File\n",
      "[2023-08-03 20:49:29,599] [INFO] (packager) - Scanning for models in {models_path}...\n",
      "[2023-08-03 20:49:29,599] [DEBUG] (packager) - Model model=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model added.\n",
      "[2023-08-03 20:49:29,599] [INFO] (packager) - Reading application configuration from /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/mednist_app/app.yaml...\n",
      "[2023-08-03 20:49:29,601] [INFO] (packager) - Generating app.json...\n",
      "[2023-08-03 20:49:29,601] [INFO] (packager) - Generating pkg.json...\n",
      "[2023-08-03 20:49:29,601] [DEBUG] (common) - \n",
      "=============== Begin app.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app/mednist_classifier_monaideploy.py\\\"]\",\n",
      "    \"environment\": {\n",
      "        \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "        \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "        \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "        \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "        \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "        \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "        \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "        \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "        \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "        \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"path\": \"input/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"liveness\": null,\n",
      "    \"output\": {\n",
      "        \"path\": \"output/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"readiness\": null,\n",
      "    \"sdk\": \"monai-deploy\",\n",
      "    \"sdkVersion\": \"0.6.0\",\n",
      "    \"timeout\": 0,\n",
      "    \"version\": 1.0,\n",
      "    \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "================ End app.json ================\n",
      "                 \n",
      "[2023-08-03 20:49:29,602] [DEBUG] (common) - \n",
      "=============== Begin pkg.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "    \"modelRoot\": \"/opt/holoscan/models\",\n",
      "    \"models\": {\n",
      "        \"model\": \"/opt/holoscan/models\"\n",
      "    },\n",
      "    \"resources\": {\n",
      "        \"cpu\": 1,\n",
      "        \"gpu\": 1,\n",
      "        \"memory\": \"1Gi\",\n",
      "        \"gpuMemory\": \"1Gi\"\n",
      "    },\n",
      "    \"version\": 1.0\n",
      "}\n",
      "================ End pkg.json ================\n",
      "                 \n",
      "[2023-08-03 20:49:29,635] [DEBUG] (packager.builder) - \n",
      "========== Begin Dockerfile ==========\n",
      "\n",
      "\n",
      "FROM nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu\n",
      "\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "ENV TERM=xterm-256color\n",
      "\n",
      "ARG UNAME\n",
      "ARG UID\n",
      "ARG GID\n",
      "\n",
      "RUN mkdir -p /etc/holoscan/ \\\n",
      "        && mkdir -p /opt/holoscan/ \\\n",
      "        && mkdir -p /var/holoscan \\\n",
      "        && mkdir -p /opt/holoscan/app \\\n",
      "        && mkdir -p /var/holoscan/input \\\n",
      "        && mkdir -p /var/holoscan/output\n",
      "\n",
      "LABEL base=\"nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu\"\n",
      "LABEL tag=\"mednist_app:1.0\"\n",
      "LABEL org.opencontainers.image.title=\"MONAI Deploy App Package - MedNIST Classifier App\"\n",
      "LABEL org.opencontainers.image.version=\"1.0\"\n",
      "LABEL org.nvidia.holoscan=\"0.6.0\"\n",
      "\n",
      "ENV HOLOSCAN_ENABLE_HEALTH_CHECK=true\n",
      "ENV HOLOSCAN_INPUT_PATH=/var/holoscan/input\n",
      "ENV HOLOSCAN_OUTPUT_PATH=/var/holoscan/output\n",
      "ENV HOLOSCAN_WORKDIR=/var/holoscan\n",
      "ENV HOLOSCAN_APPLICATION=/opt/holoscan/app\n",
      "ENV HOLOSCAN_TIMEOUT=0\n",
      "ENV HOLOSCAN_MODEL_PATH=/opt/holoscan/models\n",
      "ENV HOLOSCAN_DOCS_PATH=/opt/holoscan/docs\n",
      "ENV HOLOSCAN_CONFIG_PATH=/var/holoscan/app.yaml\n",
      "ENV HOLOSCAN_APP_MANIFEST_PATH=/etc/holoscan/app.json\n",
      "ENV HOLOSCAN_PKG_MANIFEST_PATH=/etc/holoscan/pkg.json\n",
      "ENV HOLOSCAN_LOGS_PATH=/var/holoscan/logs\n",
      "ENV PATH=/root/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/libtorch/1.13.1/lib/:/opt/nvidia/holoscan/lib\n",
      "\n",
      "RUN apt-get update \\\n",
      "    && apt-get install -y curl jq \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "ENV PYTHONPATH=\"/opt/holoscan/app:$PYTHONPATH\"\n",
      "\n",
      "\n",
      "\n",
      "RUN groupadd -g $GID $UNAME\n",
      "RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME\n",
      "RUN chown -R holoscan /var/holoscan \n",
      "RUN chown -R holoscan /var/holoscan/input \n",
      "RUN chown -R holoscan /var/holoscan/output \n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "# Copy HAP/MAP tool script\n",
      "COPY ./tools /var/holoscan/tools\n",
      "RUN chmod +x /var/holoscan/tools\n",
      "\n",
      "\n",
      "# Copy gRPC health probe\n",
      "\n",
      "USER $UNAME\n",
      "\n",
      "ENV PATH=/root/.local/bin:/home/holoscan/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "\n",
      "COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "\n",
      "# Install Holoscan from PyPI org\n",
      "RUN pip install holoscan==0.6.0\n",
      "\n",
      "\n",
      "# Copy user-specified MONAI Deploy SDK file\n",
      "COPY ./monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl\n",
      "RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "COPY ./models  /opt/holoscan/models\n",
      "\n",
      "COPY ./map/app.json /etc/holoscan/app.json\n",
      "COPY ./app.config /var/holoscan/app.yaml\n",
      "COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "\n",
      "COPY ./app /opt/holoscan/app\n",
      "\n",
      "ENTRYPOINT [\"/var/holoscan/tools\"]\n",
      "=========== End Dockerfile ===========\n",
      "\n",
      "[2023-08-03 20:49:29,636] [INFO] (packager.builder) - \n",
      "===============================================================================\n",
      "Building image for:                 x64-workstation\n",
      "    Architecture:                   linux/amd64\n",
      "    Base Image:                     nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu\n",
      "    Build Image:                    N/A  \n",
      "    Cache:                          Enabled\n",
      "    Configuration:                  dgpu\n",
      "    Holoiscan SDK Package:          pypi.org\n",
      "    MONAI Deploy App SDK Package:   /home/mqin/src/monai-deploy-app-sdk/dist/monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl\n",
      "    gRPC Health Probe:              N/A\n",
      "    SDK Version:                    0.6.0\n",
      "    SDK:                            monai-deploy\n",
      "    Tag:                            mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    \n",
      "[2023-08-03 20:49:30,337] [INFO] (common) - Using existing Docker BuildKit builder `holoscan_app_builder`\n",
      "[2023-08-03 20:49:30,338] [DEBUG] (packager.builder) - Building Holoscan Application Package: tag=mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "#1 [internal] load .dockerignore\n",
      "#1 transferring context: 1.79kB 0.0s done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load build definition from Dockerfile\n",
      "#2 transferring dockerfile: 2.67kB done\n",
      "#2 DONE 0.1s\n",
      "\n",
      "#3 [internal] load metadata for nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu\n",
      "#3 DONE 0.8s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 importing cache manifest from local:9585092855700183608\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 importing cache manifest from nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu\n",
      "#6 DONE 0.9s\n",
      "\n",
      "#7 [ 1/22] FROM nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu@sha256:9653f80f241fd542f25afbcbcf7a0d02ed7e5941c79763e69def5b1e6d9fb7bc\n",
      "#7 resolve nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu@sha256:9653f80f241fd542f25afbcbcf7a0d02ed7e5941c79763e69def5b1e6d9fb7bc\n",
      "#7 resolve nvcr.io/nvidia/clara-holoscan/holoscan:v0.6.0-dgpu@sha256:9653f80f241fd542f25afbcbcf7a0d02ed7e5941c79763e69def5b1e6d9fb7bc 0.1s done\n",
      "#7 DONE 0.1s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 transferring context: 28.78MB 0.2s done\n",
      "#4 DONE 0.3s\n",
      "\n",
      "#8 [ 6/22] RUN chown -R holoscan /var/holoscan\n",
      "#8 CACHED\n",
      "\n",
      "#9 [12/22] COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "#9 CACHED\n",
      "\n",
      "#10 [10/22] COPY ./tools /var/holoscan/tools\n",
      "#10 CACHED\n",
      "\n",
      "#11 [15/22] RUN pip install holoscan==0.6.0\n",
      "#11 CACHED\n",
      "\n",
      "#12 [16/22] COPY ./monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl\n",
      "#12 CACHED\n",
      "\n",
      "#13 [ 7/22] RUN chown -R holoscan /var/holoscan/input\n",
      "#13 CACHED\n",
      "\n",
      "#14 [ 4/22] RUN groupadd -g 1000 holoscan\n",
      "#14 CACHED\n",
      "\n",
      "#15 [14/22] RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "#15 CACHED\n",
      "\n",
      "#16 [11/22] RUN chmod +x /var/holoscan/tools\n",
      "#16 CACHED\n",
      "\n",
      "#17 [ 5/22] RUN useradd -rm -d /home/holoscan -s /bin/bash -g 1000 -G sudo -u 1000 holoscan\n",
      "#17 CACHED\n",
      "\n",
      "#18 [ 9/22] WORKDIR /var/holoscan\n",
      "#18 CACHED\n",
      "\n",
      "#19 [ 8/22] RUN chown -R holoscan /var/holoscan/output\n",
      "#19 CACHED\n",
      "\n",
      "#20 [ 2/22] RUN mkdir -p /etc/holoscan/         && mkdir -p /opt/holoscan/         && mkdir -p /var/holoscan         && mkdir -p /opt/holoscan/app         && mkdir -p /var/holoscan/input         && mkdir -p /var/holoscan/output\n",
      "#20 CACHED\n",
      "\n",
      "#21 [ 3/22] RUN apt-get update     && apt-get install -y curl jq     && rm -rf /var/lib/apt/lists/*\n",
      "#21 CACHED\n",
      "\n",
      "#22 [13/22] RUN pip install --upgrade pip\n",
      "#22 CACHED\n",
      "\n",
      "#23 [17/22] RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 6.29MB / 2.40GB 0.2s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 130.02MB / 2.40GB 2.7s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 251.66MB / 2.40GB 5.1s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 374.34MB / 2.40GB 7.7s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 497.03MB / 2.40GB 10.2s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 629.15MB / 2.40GB 12.9s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 758.12MB / 2.40GB 15.5s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 880.80MB / 2.40GB 18.0s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.00GB / 2.40GB 20.6s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.13GB / 2.40GB 23.1s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.26GB / 2.40GB 25.4s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.38GB / 2.40GB 27.9s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.51GB / 2.40GB 30.3s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.63GB / 2.40GB 32.9s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.76GB / 2.40GB 35.7s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 1.89GB / 2.40GB 38.4s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 2.02GB / 2.40GB 41.0s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 2.14GB / 2.40GB 43.4s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 2.26GB / 2.40GB 45.8s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 2.38GB / 2.40GB 48.2s\n",
      "#23 sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 2.40GB / 2.40GB 49.8s done\n",
      "#23 extracting sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523\n",
      "#23 extracting sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 57.5s done\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 5.24MB / 105.68MB 0.2s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 13.63MB / 105.68MB 0.3s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 22.02MB / 105.68MB 0.5s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 29.36MB / 105.68MB 0.6s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 35.65MB / 105.68MB 0.8s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 44.04MB / 105.68MB 0.9s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 51.38MB / 105.68MB 1.1s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 59.77MB / 105.68MB 1.2s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 67.15MB / 105.68MB 1.4s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 75.50MB / 105.68MB 1.5s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 82.84MB / 105.68MB 1.7s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 89.13MB / 105.68MB 1.8s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 97.52MB / 105.68MB 2.0s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 105.68MB / 105.68MB 2.1s\n",
      "#23 sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 105.68MB / 105.68MB 2.4s done\n",
      "#23 extracting sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded\n",
      "#23 extracting sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded 2.9s done\n",
      "#23 sha256:55e32cef42f992f9c914515dc95457ad65a501d20fb8face7a82d51a620e8d0c 149.04kB / 149.04kB 0.0s done\n",
      "#23 extracting sha256:55e32cef42f992f9c914515dc95457ad65a501d20fb8face7a82d51a620e8d0c 0.0s done\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 6.29MB / 48.57MB 0.2s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 13.63MB / 48.57MB 0.3s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 22.02MB / 48.57MB 0.5s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 29.36MB / 48.57MB 0.6s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 35.65MB / 48.57MB 0.8s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 42.99MB / 48.57MB 0.9s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 48.57MB / 48.57MB 1.1s\n",
      "#23 sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 48.57MB / 48.57MB 1.1s done\n",
      "#23 extracting sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56\n",
      "#23 extracting sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 2.2s done\n",
      "#23 CACHED\n",
      "\n",
      "#24 [18/22] COPY ./models  /opt/holoscan/models\n",
      "#24 DONE 3.1s\n",
      "\n",
      "#25 [19/22] COPY ./map/app.json /etc/holoscan/app.json\n",
      "#25 DONE 0.1s\n",
      "\n",
      "#26 [20/22] COPY ./app.config /var/holoscan/app.yaml\n",
      "#26 DONE 0.1s\n",
      "\n",
      "#27 [21/22] COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "#27 DONE 0.1s\n",
      "\n",
      "#28 [22/22] COPY ./app /opt/holoscan/app\n",
      "#28 DONE 0.1s\n",
      "\n",
      "#29 exporting to docker image format\n",
      "#29 exporting layers\n",
      "#29 exporting layers 1.1s done\n",
      "#29 exporting manifest sha256:c788c08ceb970d2b6c8a36eaf5d5809a959ed6ac92e387bf964a3b4998d3f2af 0.0s done\n",
      "#29 exporting config sha256:d22d232013f038d48c43d4caa2246268674e9c6c81083f7ab6c3f37ec7ce31e2 0.0s done\n",
      "#29 sending tarball\n",
      "#29 ...\n",
      "\n",
      "#30 importing to docker\n",
      "#30 DONE 1.3s\n",
      "\n",
      "#29 exporting to docker image format\n",
      "#29 sending tarball 52.6s done\n",
      "#29 DONE 53.8s\n",
      "\n",
      "#31 exporting content cache\n",
      "#31 preparing build cache for export\n",
      "#31 writing layer sha256:0709800848b4584780b40e7e81200689870e890c38b54e96b65cd0a3b1942f2d done\n",
      "#31 writing layer sha256:0ce020987cfa5cd1654085af3bb40779634eb3d792c4a4d6059036463ae0040d done\n",
      "#31 writing layer sha256:0f65089b284381bf795d15b1a186e2a8739ea957106fa526edef0d738e7cda70 done\n",
      "#31 writing layer sha256:12a47450a9f9cc5d4edab65d0f600dbbe8b23a1663b0b3bb2c481d40e074b580 done\n",
      "#31 writing layer sha256:1338fe24653eba781a71bd79902b5b905624589983ce80c816a09bda7b89e3bd\n",
      "#31 writing layer sha256:1338fe24653eba781a71bd79902b5b905624589983ce80c816a09bda7b89e3bd 0.6s done\n",
      "#31 writing layer sha256:1477e9e55f1216fe4085565e21baa742149b480d35141f298402b1e766fb58d3 0.0s done\n",
      "#31 writing layer sha256:1de965777e2e37c7fabe00bdbf3d0203ca83ed30a71a5479c3113fe4fc48c4bb done\n",
      "#31 writing layer sha256:24b5aa2448e920814dd67d7d3c0169b2cdacb13c4048d74ded3b4317843b13ff done\n",
      "#31 writing layer sha256:2d42104dbf0a7cc962b791f6ab4f45a803f8a36d296f996aca180cfb2f3e30d0 done\n",
      "#31 writing layer sha256:2fa1ce4fa3fec6f9723380dc0536b7c361d874add0baaddc4bbf2accac82d2ff\n",
      "#31 writing layer sha256:2fa1ce4fa3fec6f9723380dc0536b7c361d874add0baaddc4bbf2accac82d2ff done\n",
      "#31 writing layer sha256:38794be1b5dc99645feabf89b22cd34fb5bdffb5164ad920e7df94f353efe9c0 done\n",
      "#31 writing layer sha256:38f963dc57c1e7b68a738fe39ed9f9345df7188111a047e2163a46648d7f1d88 done\n",
      "#31 writing layer sha256:3e7e4c9bc2b136814c20c04feb4eea2b2ecf972e20182d88759931130cfb4181 done\n",
      "#31 writing layer sha256:3fd77037ad585442cd82d64e337f49a38ddba50432b2a1e563a48401d25c79e6 done\n",
      "#31 writing layer sha256:41814ed91034b30ac9c44dfc604a4bade6138005ccf682372c02e0bead66dbc0 done\n",
      "#31 writing layer sha256:45893188359aca643d5918c9932da995364dc62013dfa40c075298b1baabece3 done\n",
      "#31 writing layer sha256:49bc651b19d9e46715c15c41b7c0daa007e8e25f7d9518f04f0f06592799875a done\n",
      "#31 writing layer sha256:4aeb0049534a685f9b8d851171ca3ee850fc1609d85e651ebdb0508d8d1e9403 0.0s done\n",
      "#31 writing layer sha256:4c12db5118d8a7d909e4926d69a2192d2b3cd8b110d49c7504a4f701258c1ccc done\n",
      "#31 writing layer sha256:4cc43a803109d6e9d1fd35495cef9b1257035f5341a2db54f7a1940815b6cc65 done\n",
      "#31 writing layer sha256:4d32b49e2995210e8937f0898327f196d3fcc52486f0be920e8b2d65f150a7ab done\n",
      "#31 writing layer sha256:4d6fe980bad9cd7b2c85a478c8033cae3d098a81f7934322fb64658b0c8f9854 done\n",
      "#31 writing layer sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 done\n",
      "#31 writing layer sha256:5150182f1ff123399b300ca469e00f6c4d82e1b9b72652fb8ee7eab370245236 done\n",
      "#31 writing layer sha256:55e32cef42f992f9c914515dc95457ad65a501d20fb8face7a82d51a620e8d0c done\n",
      "#31 writing layer sha256:595c38fa102c61c3dda19bdab70dcd26a0e50465b986d022a84fa69023a05d0f done\n",
      "#31 writing layer sha256:59d451175f6950740e26d38c322da0ef67cb59da63181eb32996f752ba8a2f17 done\n",
      "#31 writing layer sha256:5ad1f2004580e415b998124ea394e9d4072a35d70968118c779f307204d6bd17 done\n",
      "#31 writing layer sha256:62598eafddf023e7f22643485f4321cbd51ff7eee743b970db12454fd3c8c675 done\n",
      "#31 writing layer sha256:63d7e616a46987136f4cc9eba95db6f6327b4854cfe3c7e20fed6db0c966e380 done\n",
      "#31 writing layer sha256:6939d591a6b09b14a437e5cd2d6082a52b6d76bec4f72d960440f097721da34f done\n",
      "#31 writing layer sha256:698318e5a60e5e0d48c45bf992f205a9532da567fdfe94bd59be2e192975dd6f done\n",
      "#31 writing layer sha256:6ddc1d0f91833b36aac1c6f0c8cea005c87d94bab132d46cc06d9b060a81cca3 done\n",
      "#31 writing layer sha256:74ac1f5a47c0926bff1e997bb99985a09926f43bd0895cb27ceb5fa9e95f8720 done\n",
      "#31 writing layer sha256:7577973918dd30e764733a352a93f418000bc3181163ca451b2307492c1a6ba9 done\n",
      "#31 writing layer sha256:806c67c703b35fc283718dc9a3a7062a0303aabbea1395b138e66c10cd915f56 done\n",
      "#31 writing layer sha256:886c886d8a09d8befb92df75dd461d4f97b77d7cff4144c4223b0d2f6f2c17f2 done\n",
      "#31 writing layer sha256:8a7451db9b4b817b3b33904abddb7041810a4ffe8ed4a034307d45d9ae9b3f2a done\n",
      "#31 writing layer sha256:916f4054c6e7f10de4fd7c08ffc75fa23ebecca4eceb8183cb1023b33b1696c9 done\n",
      "#31 writing layer sha256:9463aa3f56275af97693df69478a2dc1d171f4e763ca6f7b6f370a35e605c154 done\n",
      "#31 writing layer sha256:955fd173ed884230c2eded4542d10a97384b408537be6bbb7c4ae09ccd6fb2d0 done\n",
      "#31 writing layer sha256:99ef644a0c84a569b9692a76e0c6a1c3e9dedae5d551087be684b6bc1bea6f22 done\n",
      "#31 writing layer sha256:9c42a4ee99755f441251e6043b2cbba16e49818a88775e7501ec17e379ce3cfd done\n",
      "#31 writing layer sha256:9c63be0a86e3dc4168db3814bf464e40996afda0031649d9faa8ff7568c3154f done\n",
      "#31 writing layer sha256:9e04bda98b05554953459b5edef7b2b14d32f1a00b979a23d04b6eb5c191e66b done\n",
      "#31 writing layer sha256:a4a0c690bc7da07e592514dccaa26098a387e8457f69095e922b6d73f7852502 done\n",
      "#31 writing layer sha256:a4aafbc094d78a85bef41036173eb816a53bcd3e2564594a32f542facdf2aba6 done\n",
      "#31 writing layer sha256:ae36a4d38b76948e39a5957025c984a674d2de18ce162a8caaa536e6f06fccea done\n",
      "#31 writing layer sha256:b2fa40114a4a0725c81b327df89c0c3ed5c05ca9aa7f1157394d5096cf5460ce done\n",
      "#31 writing layer sha256:b48a5fafcaba74eb5d7e7665601509e2889285b50a04b5b639a23f8adc818157 done\n",
      "#31 writing layer sha256:b8ec9058cfc8057a4989af89add416b6d4c425cb3e3a4542281d3b188ef8d97f 0.0s done\n",
      "#31 writing layer sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523\n",
      "#31 preparing build cache for export 1.3s done\n",
      "#31 writing layer sha256:b9874c0e107000cd0157c2f6c12f6b095ec79e92b293ef581984b94c75080523 done\n",
      "#31 writing layer sha256:c86976a083599e36a6441f36f553627194d05ea82bb82a78682e718fe62fccf6 done\n",
      "#31 writing layer sha256:cb506fbdedc817e3d074f609e2edbf9655aacd7784610a1bbac52f2d7be25438 done\n",
      "#31 writing layer sha256:d2a6fe65a1f84edb65b63460a75d1cac1aa48b72789006881b0bcfd54cd01ffd done\n",
      "#31 writing layer sha256:d674572cae0440d01b016bd1a6cf88924f6067f38858706ad4856d78993a0a6e done\n",
      "#31 writing layer sha256:d709c3fc82181d7bc3561f087363554add07059d1fc1fa014d3da3f9092a7524 0.0s done\n",
      "#31 writing layer sha256:d8d16d6af76dc7c6b539422a25fdad5efb8ada5a8188069fcd9d113e3b783304 done\n",
      "#31 writing layer sha256:ddc2ade4f6fe866696cb638c8a102cb644fa842c2ca578392802b3e0e5e3bcb7 done\n",
      "#31 writing layer sha256:e2cfd7f6244d6f35befa6bda1caa65f1786cecf3f00ef99d7c9a90715ce6a03c done\n",
      "#31 writing layer sha256:e94a4481e9334ff402bf90628594f64a426672debbdfb55f1290802e52013907 done\n",
      "#31 writing layer sha256:eaf45e9f32d1f5a9983945a1a9f8dedbb475bc0f578337610e00b4dedec87c20 done\n",
      "#31 writing layer sha256:eb411bef39c013c9853651e68f00965dbd826d829c4e478884a2886976e9c989 done\n",
      "#31 writing layer sha256:edfe4a95eb6bd3142aeda941ab871ffcc8c19cf50c33561c210ba8ead2424759 done\n",
      "#31 writing layer sha256:ef4466d6f927d29d404df9c5af3ef5733c86fa14e008762c90110b963978b1e7 done\n",
      "#31 writing layer sha256:f20d17e4fd485b1a37bb580c6b5e8b8d707b382d387df57004086b8036ddaded done\n",
      "#31 writing layer sha256:f346e3ecdf0bee048fa1e3baf1d3128ff0283b903f03e97524944949bd8882e5 done\n",
      "#31 writing layer sha256:f3f9a00a1ce9aadda250aacb3e66a932676badc5d8519c41517fdf7ea14c13ed done\n",
      "#31 writing layer sha256:fd849d9bd8889edd43ae38e9f21a912430c8526b2c18f3057a3b2cd74eb27b31 done\n",
      "#31 writing config sha256:23fbbd00b006000bbd87f5dfe7e12fe71203e710a83580e1ee63125c214ff4d5 0.0s done\n",
      "#31 writing manifest sha256:7b8dadf0182c3fbe7dede6a29963defd6eff4efa3a6b8e81e5f2dceaaf023210 0.0s done\n",
      "#31 DONE 1.3s\n",
      "[2023-08-03 20:52:32,339] [INFO] (packager) - Build Summary:\n",
      "\n",
      "Platform: x64-workstation/dgpu\n",
      "    Status:     Succeeded\n",
      "    Docker Tag: mednist_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Tarball:    None\n"
     ]
    }
   ],
   "source": [
    "tag_prefix = \"mednist_app\"\n",
    "# Note, once App SDK v0.6 is published, options starting after \"-l DEBUG\" need to be removed, so will be the variables for the options.\n",
    "sdk_wheel = \"/home/mqin/src/monai-deploy-app-sdk/dist/monai_deploy_app_sdk-0.5.1+7.g9fa1185.dirty-py3-none-any.whl\"\n",
    "\n",
    "!monai-deploy package \"mednist_app/mednist_classifier_monaideploy.py\" -m {models_folder} -c \"mednist_app/app.yaml\" -t {tag_prefix}:1.0 --platform x64-workstation -l DEBUG --sdk-version 0.6.0 --monai-deploy-sdk-file {sdk_wheel}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "Building a MONAI Application Package (Docker image) can take time. Use `-l DEBUG` option if you want to see the progress.\n",
    "\n",
    ":::\n",
    "\n",
    "We can see that the Docker image is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mednist_app-x64-workstation-dgpu-linux-amd64              1.0                        d22d232013f0   59 seconds ago   15.4GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep {tag_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing packaged app locally\n",
    "\n",
    "We can choose to display and export the MAP manifests, but in this example, we will just run the MAP through <a href=\"../../developing_with_sdk/executing_packaged_app_locally.html\">MONAI Application Runner</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.8/site-packages/pydantic/_internal/_config.py:269: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "  warnings.warn(message, UserWarning)\n",
      "[2023-08-03 20:52:37,269] [INFO] (runner) - Checking dependencies...\n",
      "[2023-08-03 20:52:37,269] [INFO] (runner) - --> Verifying if \"docker\" is installed...\n",
      "\n",
      "[2023-08-03 20:52:37,270] [INFO] (runner) - --> Verifying if \"docker-buildx\" is installed...\n",
      "\n",
      "[2023-08-03 20:52:37,270] [INFO] (runner) - --> Verifying if \"mednist_app-x64-workstation-dgpu-linux-amd64:1.0\" is available...\n",
      "\n",
      "[2023-08-03 20:52:37,348] [INFO] (runner) - Reading HAP/MAP manifest...\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.56kB to /tmp/tmp4dplyjgr/app.json\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.05kB to /tmp/tmp4dplyjgr/pkg.json\n",
      "[2023-08-03 20:52:37,733] [INFO] (runner) - --> Verifying if \"nvidia-ctk\" is installed...\n",
      "\n",
      "[2023-08-03 20:52:37,954] [INFO] (common) - Launching container (96d09cbab602) using image 'mednist_app-x64-workstation-dgpu-linux-amd64:1.0'...\n",
      "    container name:      determined_maxwell\n",
      "    host name:           mingq-dt\n",
      "    network:             host\n",
      "    user:                1000:1000\n",
      "    ulimits:             memlock=-1:-1, stack=67108864:67108864\n",
      "    cap_add:             CAP_SYS_PTRACE\n",
      "    ipc mode:            host\n",
      "    shared memory size:  67108864\n",
      "    devices:             \n",
      "2023-08-04 03:52:38 [INFO] Launching application python3 /opt/holoscan/app/mednist_classifier_monaideploy.py ...\n",
      "\n",
      "[info] [app_driver.cpp:1025] Launching the driver/health checking service\n",
      "\n",
      "[info] [gxf_executor.cpp:210] Creating context\n",
      "\n",
      "[info] [server.cpp:73] Health checking server listening on 0.0.0.0:8777\n",
      "\n",
      "[info] [gxf_executor.cpp:1595] Loading extensions from configs...\n",
      "\n",
      "[info] [gxf_executor.cpp:1741] Activating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1771] Running Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1773] Waiting for completion...\n",
      "\n",
      "[info] [gxf_executor.cpp:1774] Graph execution waiting. Fragment: \n",
      "\n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 3 entities\n",
      "\n",
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "\n",
      "[info] [gxf_executor.cpp:1783] Graph execution deactivating. Fragment: \n",
      "\n",
      "[info] [gxf_executor.cpp:1784] Deactivating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1787] Graph execution finished. Fragment: \n",
      "\n",
      "[info] [gxf_executor.cpp:229] Destroying context\n",
      "\n",
      "/home/holoscan/.local/lib/python3.8/site-packages/monai/utils/deprecate_utils.py:111: FutureWarning: <class 'monai.transforms.utility.array.AddChannel'>: Class `AddChannel` has been deprecated since version 0.8. It will be removed in version 1.3. please use MetaTensor data type and monai.transforms.EnsureChannelFirst instead with `channel_dim='no_channel'`.\n",
      "\n",
      "  warn_deprecated(obj, msg, warning_category)\n",
      "\n",
      "/home/holoscan/.local/lib/python3.8/site-packages/monai/data/meta_tensor.py:116: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "\n",
      "  return torch.as_tensor(x, *args, **_kwargs).as_subclass(cls)  # type: ignore\n",
      "\n",
      "/home/holoscan/.local/lib/python3.8/site-packages/pydicom/valuerep.py:443: UserWarning: Invalid value for VR UI: 'xyz'. Please see <https://dicom.nema.org/medical/dicom/current/output/html/part05.html#table_6.2-1> for allowed values for each VR.\n",
      "\n",
      "  warnings.warn(msg)\n",
      "\n",
      "AbdomenCT\n",
      "\n",
      "[2023-08-03 20:52:51,293] [INFO] (common) - Container 'determined_maxwell'(96d09cbab602) exited.\n"
     ]
    }
   ],
   "source": [
    "# Clear the output folder and run the MAP. The input is expected to be a folder.\n",
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!monai-deploy run -i$HOLOSCAN_INPUT_PATH -o $HOLOSCAN_OUTPUT_PATH mednist_app-x64-workstation-dgpu-linux-amd64:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"AbdomenCT\""
     ]
    }
   ],
   "source": [
    "!cat $HOLOSCAN_OUTPUT_PATH/output.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Please execute the following script once the exercise is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data files which is in the temporary folder\n",
    "if directory is None:\n",
    "    shutil.rmtree(root_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
