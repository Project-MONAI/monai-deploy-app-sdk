{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Deploy App with MONAI Deploy App SDK and MONAI Bundle\n",
    "\n",
    "This tutorial shows how to create an application for organ segmentation using a PyTorch model that has been trained with MONAI and packaged in the [MONAI Bundle](https://docs.monai.io/en/latest/bundle_intro.html) format.\n",
    "\n",
    "Deploying AI models requires the integration with clinical imaging network, even if just in a for-research-use setting. This means that the AI deploy application will need to support standards-based imaging protocols, and specifically for Radiological imaging, DICOM protocol.\n",
    "\n",
    "Typically, DICOM network communication, either in DICOM TCP/IP network protocol or DICOMWeb, would be handled by DICOM devices or services, e.g. MONAI Deploy Informatics Gateway, so the deploy application itself would only need to use DICOM Part 10 files as input and save the AI result in DICOM Part10 file(s). For segmentation use cases, the DICOM instance file for AI results could be a DICOM Segmentation object or a DICOM RT Structure Set, and for classification, DICOM Structure Report and/or DICOM Encapsulated PDF.\n",
    "\n",
    "DICOM instances received from modalities and Picture Archiving and Communications System (PACS) are often times the whole DICOM study, so an AI deploy application has to deal with a whole DICOM study with multiple series, whose images' spacing may not be the same as expected by the trained model. To address these cases consistently and efficiently, MONAI Deploy Application SDK provides classes, called operators, to parse DICOM studies, select specific series with application-defined rules, and convert the selected DICOM series into domain-specific image format along with meta-data representing the pertinent DICOM attributes. The image is then further processed in the pre-processing stage to normalize spacing, orientation, intensity, etc., before pixel data as Tensors are used for inference.\n",
    "\n",
    "In the following sections, we will demonstrate how to create a MONAI Deploy application package using the MONAI Deploy App SDK, and importantly, using the built-in MONAI Bundle Inference Operator to perform inference with the Spleen CT Segmentation PyTorch model in a MONAI Bundle.\n",
    "\n",
    ":::{note}\n",
    "For local testing, if there is a lack of DICOM Part 10 files, one can use open source programs, e.g. 3D Slicer, to convert a NIfTI file to a DICOM series.\n",
    "\n",
    "To make running this example simpler, the DICOM files and the [Spleen CT Segmentation MONAI Bundle](https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation), published in [MONAI Model Zoo](https://github.com/Project-MONAI/model-zoo), have been packaged and shared on Google Drive.\n",
    "\n",
    ":::\n",
    "\n",
    "## Creating Operators and connecting them in Application class\n",
    "\n",
    "We will implement an application that consists of five Operators:\n",
    "\n",
    "- **DICOMDataLoaderOperator**:\n",
    "    - **Input(dicom_files)**: a folder path (`Path`)\n",
    "    - **Output(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "- **DICOMSeriesSelectorOperator**:\n",
    "    - **Input(dicom_study_list)**: a list of DICOM studies in memory (List[[`DICOMStudy`](/modules/_autosummary/monai.deploy.core.domain.DICOMStudy)])\n",
    "    - **Input(selection_rules)**: a selection rule (Dict)\n",
    "    - **Output(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "- **DICOMSeriesToVolumeOperator**:\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **MonaiBundleInferenceOperator**:\n",
    "    - **Input(image)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Output(pred)**: an image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "- **DICOMSegmentationWriterOperator**:\n",
    "    - **Input(seg_image)**: a segmentation image object in memory ([`Image`](/modules/_autosummary/monai.deploy.core.domain.Image))\n",
    "    - **Input(study_selected_series_list)**: a DICOM series object in memory ([`StudySelectedSeries`](/modules/_autosummary/monai.deploy.core.domain.StudySelectedSeries))\n",
    "    - **Output(dicom_seg_instance)**: a file path (`Path`)\n",
    "\n",
    "\n",
    ":::{note}\n",
    "The `DICOMSegmentationWriterOperator` needs both the segmentation image as well as the original DICOM series meta-data in order to use the patient demographics and the DICOM Study level attributes.\n",
    ":::\n",
    "\n",
    "The workflow of the application is illustrated below.\n",
    "\n",
    "```{mermaid}\n",
    "%%{init: {\"theme\": \"base\", \"themeVariables\": { \"fontSize\": \"16px\"}} }%%\n",
    "\n",
    "classDiagram\n",
    "    direction TB\n",
    "\n",
    "    DICOMDataLoaderOperator --|> DICOMSeriesSelectorOperator : dicom_study_list...dicom_study_list\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSeriesToVolumeOperator : study_selected_series_list...study_selected_series_list\n",
    "    DICOMSeriesToVolumeOperator --|> MonaiBundleInferenceOperator : image...image\n",
    "    DICOMSeriesSelectorOperator --|> DICOMSegmentationWriterOperator : study_selected_series_list...study_selected_series_list\n",
    "    MonaiBundleInferenceOperator --|> DICOMSegmentationWriterOperator : pred...seg_image\n",
    "\n",
    "\n",
    "    class DICOMDataLoaderOperator {\n",
    "        <in>dicom_files : DISK\n",
    "        dicom_study_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesSelectorOperator {\n",
    "        <in>dicom_study_list : IN_MEMORY\n",
    "        <in>selection_rules : IN_MEMORY\n",
    "        study_selected_series_list(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSeriesToVolumeOperator {\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        image(out) IN_MEMORY\n",
    "    }\n",
    "    class MonaiBundleInferenceOperator {\n",
    "        <in>image : IN_MEMORY\n",
    "        pred(out) IN_MEMORY\n",
    "    }\n",
    "    class DICOMSegmentationWriterOperator {\n",
    "        <in>seg_image : IN_MEMORY\n",
    "        <in>study_selected_series_list : IN_MEMORY\n",
    "        dicom_seg_instance(out) DISK\n",
    "    }\n",
    "```\n",
    "\n",
    "### Setup environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MONAI and other necessary image processing packages for the application\n",
    "!python -c \"import monai\" || pip install --upgrade -q \"monai\"\n",
    "!python -c \"import torch\" || pip install -q \"torch>=1.12.0\"\n",
    "!python -c \"import numpy\" || pip install -q \"numpy>=1.21.6\"\n",
    "!python -c \"import nibabel\" || pip install -q \"nibabel>=3.2.1\"\n",
    "!python -c \"import pydicom\" || pip install -q \"pydicom>=2.3.0\"\n",
    "!python -c \"import highdicom\" || pip install -q \"highdicom>=0.18.2\"\n",
    "!python -c \"import SimpleITK\" || pip install -q \"SimpleITK>=2.0.0\"\n",
    "\n",
    "# Install MONAI Deploy App SDK package\n",
    "!python -c \"import holoscan\" || pip install --upgrade -q \"holoscan>=0.6.0\"\n",
    "!python -c \"import monai.deploy\" || pip install -q \"monai-deploy-app-sdk\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you may need to restart the Jupyter kernel to use the updated packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download/Extract input and model/bundle files from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (3.13.3)\n",
      "Requirement already satisfied: requests[socks] in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (2.28.2)\n",
      "Requirement already satisfied: tqdm in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from gdown) (4.66.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\n",
      "From (redirected): https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ&confirm=t&uuid=e406b570-c957-4c12-9dc1-df625c4fb575\n",
      "To: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/ai_spleen_seg_bundle_data.zip\n",
      "100%|███████████████████████████████████████| 79.4M/79.4M [00:00<00:00, 115MB/s]\n",
      "Archive:  ai_spleen_seg_bundle_data.zip\n",
      "  inflating: dcm/1-001.dcm           \n",
      "  inflating: dcm/1-002.dcm           \n",
      "  inflating: dcm/1-003.dcm           \n",
      "  inflating: dcm/1-004.dcm           \n",
      "  inflating: dcm/1-005.dcm           \n",
      "  inflating: dcm/1-006.dcm           \n",
      "  inflating: dcm/1-007.dcm           \n",
      "  inflating: dcm/1-008.dcm           \n",
      "  inflating: dcm/1-009.dcm           \n",
      "  inflating: dcm/1-010.dcm           \n",
      "  inflating: dcm/1-011.dcm           \n",
      "  inflating: dcm/1-012.dcm           \n",
      "  inflating: dcm/1-013.dcm           \n",
      "  inflating: dcm/1-014.dcm           \n",
      "  inflating: dcm/1-015.dcm           \n",
      "  inflating: dcm/1-016.dcm           \n",
      "  inflating: dcm/1-017.dcm           \n",
      "  inflating: dcm/1-018.dcm           \n",
      "  inflating: dcm/1-019.dcm           \n",
      "  inflating: dcm/1-020.dcm           \n",
      "  inflating: dcm/1-021.dcm           \n",
      "  inflating: dcm/1-022.dcm           \n",
      "  inflating: dcm/1-023.dcm           \n",
      "  inflating: dcm/1-024.dcm           \n",
      "  inflating: dcm/1-025.dcm           \n",
      "  inflating: dcm/1-026.dcm           \n",
      "  inflating: dcm/1-027.dcm           \n",
      "  inflating: dcm/1-028.dcm           \n",
      "  inflating: dcm/1-029.dcm           \n",
      "  inflating: dcm/1-030.dcm           \n",
      "  inflating: dcm/1-031.dcm           \n",
      "  inflating: dcm/1-032.dcm           \n",
      "  inflating: dcm/1-033.dcm           \n",
      "  inflating: dcm/1-034.dcm           \n",
      "  inflating: dcm/1-035.dcm           \n",
      "  inflating: dcm/1-036.dcm           \n",
      "  inflating: dcm/1-037.dcm           \n",
      "  inflating: dcm/1-038.dcm           \n",
      "  inflating: dcm/1-039.dcm           \n",
      "  inflating: dcm/1-040.dcm           \n",
      "  inflating: dcm/1-041.dcm           \n",
      "  inflating: dcm/1-042.dcm           \n",
      "  inflating: dcm/1-043.dcm           \n",
      "  inflating: dcm/1-044.dcm           \n",
      "  inflating: dcm/1-045.dcm           \n",
      "  inflating: dcm/1-046.dcm           \n",
      "  inflating: dcm/1-047.dcm           \n",
      "  inflating: dcm/1-048.dcm           \n",
      "  inflating: dcm/1-049.dcm           \n",
      "  inflating: dcm/1-050.dcm           \n",
      "  inflating: dcm/1-051.dcm           \n",
      "  inflating: dcm/1-052.dcm           \n",
      "  inflating: dcm/1-053.dcm           \n",
      "  inflating: dcm/1-054.dcm           \n",
      "  inflating: dcm/1-055.dcm           \n",
      "  inflating: dcm/1-056.dcm           \n",
      "  inflating: dcm/1-057.dcm           \n",
      "  inflating: dcm/1-058.dcm           \n",
      "  inflating: dcm/1-059.dcm           \n",
      "  inflating: dcm/1-060.dcm           \n",
      "  inflating: dcm/1-061.dcm           \n",
      "  inflating: dcm/1-062.dcm           \n",
      "  inflating: dcm/1-063.dcm           \n",
      "  inflating: dcm/1-064.dcm           \n",
      "  inflating: dcm/1-065.dcm           \n",
      "  inflating: dcm/1-066.dcm           \n",
      "  inflating: dcm/1-067.dcm           \n",
      "  inflating: dcm/1-068.dcm           \n",
      "  inflating: dcm/1-069.dcm           \n",
      "  inflating: dcm/1-070.dcm           \n",
      "  inflating: dcm/1-071.dcm           \n",
      "  inflating: dcm/1-072.dcm           \n",
      "  inflating: dcm/1-073.dcm           \n",
      "  inflating: dcm/1-074.dcm           \n",
      "  inflating: dcm/1-075.dcm           \n",
      "  inflating: dcm/1-076.dcm           \n",
      "  inflating: dcm/1-077.dcm           \n",
      "  inflating: dcm/1-078.dcm           \n",
      "  inflating: dcm/1-079.dcm           \n",
      "  inflating: dcm/1-080.dcm           \n",
      "  inflating: dcm/1-081.dcm           \n",
      "  inflating: dcm/1-082.dcm           \n",
      "  inflating: dcm/1-083.dcm           \n",
      "  inflating: dcm/1-084.dcm           \n",
      "  inflating: dcm/1-085.dcm           \n",
      "  inflating: dcm/1-086.dcm           \n",
      "  inflating: dcm/1-087.dcm           \n",
      "  inflating: dcm/1-088.dcm           \n",
      "  inflating: dcm/1-089.dcm           \n",
      "  inflating: dcm/1-090.dcm           \n",
      "  inflating: dcm/1-091.dcm           \n",
      "  inflating: dcm/1-092.dcm           \n",
      "  inflating: dcm/1-093.dcm           \n",
      "  inflating: dcm/1-094.dcm           \n",
      "  inflating: dcm/1-095.dcm           \n",
      "  inflating: dcm/1-096.dcm           \n",
      "  inflating: dcm/1-097.dcm           \n",
      "  inflating: dcm/1-098.dcm           \n",
      "  inflating: dcm/1-099.dcm           \n",
      "  inflating: dcm/1-100.dcm           \n",
      "  inflating: dcm/1-101.dcm           \n",
      "  inflating: dcm/1-102.dcm           \n",
      "  inflating: dcm/1-103.dcm           \n",
      "  inflating: dcm/1-104.dcm           \n",
      "  inflating: dcm/1-105.dcm           \n",
      "  inflating: dcm/1-106.dcm           \n",
      "  inflating: dcm/1-107.dcm           \n",
      "  inflating: dcm/1-108.dcm           \n",
      "  inflating: dcm/1-109.dcm           \n",
      "  inflating: dcm/1-110.dcm           \n",
      "  inflating: dcm/1-111.dcm           \n",
      "  inflating: dcm/1-112.dcm           \n",
      "  inflating: dcm/1-113.dcm           \n",
      "  inflating: dcm/1-114.dcm           \n",
      "  inflating: dcm/1-115.dcm           \n",
      "  inflating: dcm/1-116.dcm           \n",
      "  inflating: dcm/1-117.dcm           \n",
      "  inflating: dcm/1-118.dcm           \n",
      "  inflating: dcm/1-119.dcm           \n",
      "  inflating: dcm/1-120.dcm           \n",
      "  inflating: dcm/1-121.dcm           \n",
      "  inflating: dcm/1-122.dcm           \n",
      "  inflating: dcm/1-123.dcm           \n",
      "  inflating: dcm/1-124.dcm           \n",
      "  inflating: dcm/1-125.dcm           \n",
      "  inflating: dcm/1-126.dcm           \n",
      "  inflating: dcm/1-127.dcm           \n",
      "  inflating: dcm/1-128.dcm           \n",
      "  inflating: dcm/1-129.dcm           \n",
      "  inflating: dcm/1-130.dcm           \n",
      "  inflating: dcm/1-131.dcm           \n",
      "  inflating: dcm/1-132.dcm           \n",
      "  inflating: dcm/1-133.dcm           \n",
      "  inflating: dcm/1-134.dcm           \n",
      "  inflating: dcm/1-135.dcm           \n",
      "  inflating: dcm/1-136.dcm           \n",
      "  inflating: dcm/1-137.dcm           \n",
      "  inflating: dcm/1-138.dcm           \n",
      "  inflating: dcm/1-139.dcm           \n",
      "  inflating: dcm/1-140.dcm           \n",
      "  inflating: dcm/1-141.dcm           \n",
      "  inflating: dcm/1-142.dcm           \n",
      "  inflating: dcm/1-143.dcm           \n",
      "  inflating: dcm/1-144.dcm           \n",
      "  inflating: dcm/1-145.dcm           \n",
      "  inflating: dcm/1-146.dcm           \n",
      "  inflating: dcm/1-147.dcm           \n",
      "  inflating: dcm/1-148.dcm           \n",
      "  inflating: dcm/1-149.dcm           \n",
      "  inflating: dcm/1-150.dcm           \n",
      "  inflating: dcm/1-151.dcm           \n",
      "  inflating: dcm/1-152.dcm           \n",
      "  inflating: dcm/1-153.dcm           \n",
      "  inflating: dcm/1-154.dcm           \n",
      "  inflating: dcm/1-155.dcm           \n",
      "  inflating: dcm/1-156.dcm           \n",
      "  inflating: dcm/1-157.dcm           \n",
      "  inflating: dcm/1-158.dcm           \n",
      "  inflating: dcm/1-159.dcm           \n",
      "  inflating: dcm/1-160.dcm           \n",
      "  inflating: dcm/1-161.dcm           \n",
      "  inflating: dcm/1-162.dcm           \n",
      "  inflating: dcm/1-163.dcm           \n",
      "  inflating: dcm/1-164.dcm           \n",
      "  inflating: dcm/1-165.dcm           \n",
      "  inflating: dcm/1-166.dcm           \n",
      "  inflating: dcm/1-167.dcm           \n",
      "  inflating: dcm/1-168.dcm           \n",
      "  inflating: dcm/1-169.dcm           \n",
      "  inflating: dcm/1-170.dcm           \n",
      "  inflating: dcm/1-171.dcm           \n",
      "  inflating: dcm/1-172.dcm           \n",
      "  inflating: dcm/1-173.dcm           \n",
      "  inflating: dcm/1-174.dcm           \n",
      "  inflating: dcm/1-175.dcm           \n",
      "  inflating: dcm/1-176.dcm           \n",
      "  inflating: dcm/1-177.dcm           \n",
      "  inflating: dcm/1-178.dcm           \n",
      "  inflating: dcm/1-179.dcm           \n",
      "  inflating: dcm/1-180.dcm           \n",
      "  inflating: dcm/1-181.dcm           \n",
      "  inflating: dcm/1-182.dcm           \n",
      "  inflating: dcm/1-183.dcm           \n",
      "  inflating: dcm/1-184.dcm           \n",
      "  inflating: dcm/1-185.dcm           \n",
      "  inflating: dcm/1-186.dcm           \n",
      "  inflating: dcm/1-187.dcm           \n",
      "  inflating: dcm/1-188.dcm           \n",
      "  inflating: dcm/1-189.dcm           \n",
      "  inflating: dcm/1-190.dcm           \n",
      "  inflating: dcm/1-191.dcm           \n",
      "  inflating: dcm/1-192.dcm           \n",
      "  inflating: dcm/1-193.dcm           \n",
      "  inflating: dcm/1-194.dcm           \n",
      "  inflating: dcm/1-195.dcm           \n",
      "  inflating: dcm/1-196.dcm           \n",
      "  inflating: dcm/1-197.dcm           \n",
      "  inflating: dcm/1-198.dcm           \n",
      "  inflating: dcm/1-199.dcm           \n",
      "  inflating: dcm/1-200.dcm           \n",
      "  inflating: dcm/1-201.dcm           \n",
      "  inflating: dcm/1-202.dcm           \n",
      "  inflating: dcm/1-203.dcm           \n",
      "  inflating: dcm/1-204.dcm           \n",
      "  inflating: model.ts                \n",
      "model.ts\n"
     ]
    }
   ],
   "source": [
    "# Download the test data and MONAI bundle zip file\n",
    "!pip install gdown\n",
    "!gdown \"https://drive.google.com/uc?id=1Uds8mEvdGNYUuvFpTtCQ8gNU97bAPCaQ\"\n",
    "\n",
    "# After downloading ai_spleen_bundle_data zip file from the web browser or using gdown,\n",
    "!unzip -o \"ai_spleen_seg_bundle_data.zip\"\n",
    "\n",
    "# Need to copy the model.ts file to its own clean subfolder for pacakging, to workaround an issue in the Packager\n",
    "models_folder = \"models\"\n",
    "!rm -rf {models_folder} && mkdir -p {models_folder}/model && cp model.ts {models_folder}/model && ls {models_folder}/model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOLOSCAN_INPUT_PATH=dcm\n",
      "env: HOLOSCAN_MODEL_PATH=models\n",
      "env: HOLOSCAN_OUTPUT_PATH=output\n"
     ]
    }
   ],
   "source": [
    "%env HOLOSCAN_INPUT_PATH dcm\n",
    "%env HOLOSCAN_MODEL_PATH {models_folder}\n",
    "%env HOLOSCAN_OUTPUT_PATH output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up imports\n",
    "\n",
    "Let's import necessary classes/decorators to define Application and Operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application\n",
    "from monai.deploy.core.domain import Image\n",
    "from monai.deploy.core.io_type import IOType\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.monai_bundle_inference_operator import (\n",
    "    BundleConfigNames,\n",
    "    IOMapping,\n",
    "    MonaiBundleInferenceOperator,\n",
    ")\n",
    "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Input and Output for the Model Bundle Inference Operator\n",
    "\n",
    "The App SDK provides a `MonaiBundleInferenceOperator` class to perform inference with a MONAI Bundle, which is essentially a PyTorch model in TorchScript with additional metadata describing the model network and processing specification. This operator uses the MONAI utilities to parse a MONAI Bundle to automatically instantiate the objects required for input and output processing as well as inference, as such it depends on MONAI transforms, inferers, and in turn their dependencies.\n",
    "\n",
    "Each Operator class inherits from the base `Operator` base class, and its input/output properties are specified in the `setup` function (as opposed to using decorators `@input`and `@output` in Version 0.5 and below).\n",
    "\n",
    "For the `MonaiBundleInferenceOperator` class, the input/output need to be defined to match those of the model network, both in name and data type. For the current release, an `IOMapping` object is used to connect the operator input/output to those of the model network by using the same names. This is likely to change, to be automated, in the future releases once certain limitation in the App SDK is removed.\n",
    "\n",
    "The Spleen CT Segmentation model network has a named input, called \"image\", and the named output called \"pred\", and both are of image type, which can all be mapped to the App SDK [Image](/modules/_autosummary/monai.deploy.core.domain.Image). This piece of information is typically acquired by examining the model metadata `network_data_format` attribute in the bundle, as seen in this [example] (https://github.com/Project-MONAI/model-zoo/blob/dev/models/spleen_ct_segmentation/configs/metadata.json)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Application class\n",
    "\n",
    "Our application class would look like below.\n",
    "\n",
    "It defines `App` class, inheriting the base `Application` class.\n",
    "\n",
    "Objects required for DICOM parsing, series selection, pixel data conversion to volume image, model specific inference, and the AI result specific DICOM Segmentation object writers are created. The execution pipeline, as a Directed Acyclic Graph, is then constructed by connecting these objects through `self.add_flow()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AISpleenSegApp(Application):\n",
    "    \"\"\"Demonstrates inference with built-in MONAI Bundle inference operator with DICOM files as input/output\n",
    "\n",
    "    This application loads a set of DICOM instances, select the appropriate series, converts the series to\n",
    "    3D volume image, performs inference with the built-in MONAI Bundle inference operator, including pre-processing\n",
    "    and post-processing, save the segmentation image in a DICOM Seg OID in an instance file, and optionally the\n",
    "    surface mesh in STL format.\n",
    "\n",
    "    Pertinent MONAI Bundle:\n",
    "      https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation\n",
    "\n",
    "    Execution Time Estimate:\n",
    "      With a Nvidia GV100 32GB GPU, for an input DICOM Series of 515 instances, the execution time is around\n",
    "      25 seconds with saving both DICOM Seg and surface mesh STL file, and 15 seconds with DICOM Seg only.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        logging.info(f\"Begin {self.compose.__name__}\")\n",
    "\n",
    "        app_context = Application.init_app_context({})  # Do not pass argv in Jupyter Notebook\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        # Create the custom operator(s) as well as SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"study_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Create the inference operator that supports MONAI Bundle and automates the inference.\n",
    "        # The IOMapping labels match the input and prediction keys in the pre and post processing.\n",
    "        # The model_name is optional when the app has only one model.\n",
    "        # The bundle_path argument optionally can be set to an accessible bundle file path in the dev\n",
    "        # environment, so when the app is packaged into a MAP, the operator can complete the bundle parsing\n",
    "        # during init.\n",
    "\n",
    "        config_names = BundleConfigNames(config_names=[\"inference\"])  # Same as the default\n",
    "\n",
    "        bundle_spleen_seg_op = MonaiBundleInferenceOperator(\n",
    "            self,\n",
    "            input_mapping=[IOMapping(\"image\", Image, IOType.IN_MEMORY)],\n",
    "            output_mapping=[IOMapping(\"pred\", Image, IOType.IN_MEMORY)],\n",
    "            app_context=app_context,\n",
    "            bundle_config_names=config_names,\n",
    "            bundle_path=model_path,\n",
    "            name=\"bundle_spleen_seg_op\",\n",
    "        )\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue. The segment_label, algorithm_name,\n",
    "        # and algorithm_version are of DICOM VR LO type, limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=\"volumetric (3D) segmentation of the spleen from CT image\",\n",
    "                algorithm_family=codes.DCM.ArtificialIntelligence,\n",
    "                algorithm_version=\"0.3.2\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dicom_seg_writer\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, bundle_spleen_seg_op, {(\"image\", \"image\")})\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, dicom_seg_writer, {(\"pred\", \"seg_image\")})\n",
    "        # Create the surface mesh STL conversion operator and add it to the app execution flow, if needed, by\n",
    "        # uncommenting the following couple lines.\n",
    "        stl_conversion_op = STLConversionOperator(\n",
    "            self, output_file=app_output_path.joinpath(\"stl/spleen.stl\"), name=\"stl_conversion_op\"\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, stl_conversion_op, {(\"pred\", \"image\")})\n",
    "\n",
    "        logging.info(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing app locally\n",
    "\n",
    "We can execute the app in the Jupyter notebook. Note that the DICOM files of the CT Abdomen series must be present in the `dcm` folder and the Torch Script model, `model.ts`, also in the folder as pointed to by the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-10 15:03:17,151] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=[])\n",
      "[2024-04-10 15:03:17,160] [INFO] (root) - AppContext object: AppContext(input_path=dcm, output_path=output, model_path=models, workdir=)\n",
      "[2024-04-10 15:03:17,167] [INFO] (root) - End compose\n",
      "[info] [gxf_executor.cpp:211] Creating context\n",
      "[info] [gxf_executor.cpp:1674] Loading extensions from configs...\n",
      "[info] [gxf_executor.cpp:1864] Activating Graph...\n",
      "[info] [gxf_executor.cpp:1894] Running Graph...\n",
      "[info] [gxf_executor.cpp:1896] Waiting for completion...\n",
      "[info] [gxf_executor.cpp:1897] Graph execution waiting. Fragment: \n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 8 entities\n",
      "[2024-04-10 15:03:17,216] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "[2024-04-10 15:03:17,807] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "[2024-04-10 15:03:17,809] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "[2024-04-10 15:03:17,809] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-10 15:03:17,810] [INFO] (root) - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "[2024-04-10 15:03:17,811] [INFO] (root) -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "[2024-04-10 15:03:17,812] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-10 15:03:17,813] [INFO] (root) - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "[2024-04-10 15:03:17,813] [INFO] (root) -     Series attribute Modality value: CT\n",
      "[2024-04-10 15:03:17,814] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-10 15:03:17,815] [INFO] (root) - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "[2024-04-10 15:03:17,815] [INFO] (root) -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "[2024-04-10 15:03:17,816] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-10 15:03:17,817] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-10 15:03:18,040] [INFO] (root) - Parsing from bundle_path: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model/model.ts\n",
      "[2024-04-10 15:03:24,142] [INFO] (monai.deploy.operators.stl_conversion_operator.STLConversionOperator) - Output will be saved in file output/stl/spleen.stl.\n",
      "[2024-04-10 15:03:25,752] [INFO] (monai.deploy.operators.stl_conversion_operator.SpatialImage) - 3D image\n",
      "[2024-04-10 15:03:25,753] [INFO] (monai.deploy.operators.stl_conversion_operator.STLConverter) - Image ndarray shape:(204, 512, 512)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  warnings.warn(\n",
      "[2024-04-10 15:03:36,659] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-10 15:03:36,660] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "[2024-04-10 15:03:36,661] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-10 15:03:36,663] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "[2024-04-10 15:03:36,664] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "[2024-04-10 15:03:36,665] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-10 15:03:36,666] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "[2024-04-10 15:03:36,667] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "[2024-04-10 15:03:36,668] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[info] [gxf_executor.cpp:1906] Graph execution deactivating. Fragment: \n",
      "[info] [gxf_executor.cpp:1907] Deactivating Graph...\n",
      "[info] [gxf_executor.cpp:1910] Graph execution finished. Fragment: \n",
      "[2024-04-10 15:03:36,762] [INFO] (__main__.AISpleenSegApp) - End run\n",
      "[2024-04-10 15:03:36,763] [INFO] (root) - End __main__\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "logging.info(f\"Begin {__name__}\")\n",
    "AISpleenSegApp().run()\n",
    "logging.info(f\"End {__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the application is verified inside Jupyter notebook, we can write the above Python code into Python files in an application folder.\n",
    "\n",
    "The application folder structure would look like below:\n",
    "\n",
    "```bash\n",
    "my_app\n",
    "├── __main__.py\n",
    "└── app.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an application folder\n",
    "!mkdir -p my_app && rm -rf my_app/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.py\n",
    "\n",
    "# Copyright 2021-2023 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Required for setting SegmentDescription attributes. Direct import as this is not part of App SDK package.\n",
    "from pydicom.sr.codedict import codes\n",
    "\n",
    "from monai.deploy.conditions import CountCondition\n",
    "from monai.deploy.core import AppContext, Application\n",
    "from monai.deploy.core.domain import Image\n",
    "from monai.deploy.core.io_type import IOType\n",
    "from monai.deploy.operators.dicom_data_loader_operator import DICOMDataLoaderOperator\n",
    "from monai.deploy.operators.dicom_seg_writer_operator import DICOMSegmentationWriterOperator, SegmentDescription\n",
    "from monai.deploy.operators.dicom_series_selector_operator import DICOMSeriesSelectorOperator\n",
    "from monai.deploy.operators.dicom_series_to_volume_operator import DICOMSeriesToVolumeOperator\n",
    "from monai.deploy.operators.monai_bundle_inference_operator import (\n",
    "    BundleConfigNames,\n",
    "    IOMapping,\n",
    "    MonaiBundleInferenceOperator,\n",
    ")\n",
    "from monai.deploy.operators.stl_conversion_operator import STLConversionOperator\n",
    "\n",
    "\n",
    "class AISpleenSegApp(Application):\n",
    "    \"\"\"Demonstrates inference with built-in MONAI Bundle inference operator with DICOM files as input/output\n",
    "\n",
    "    This application loads a set of DICOM instances, select the appropriate series, converts the series to\n",
    "    3D volume image, performs inference with the built-in MONAI Bundle inference operator, including pre-processing\n",
    "    and post-processing, save the segmentation image in a DICOM Seg OID in an instance file, and optionally the\n",
    "    surface mesh in STL format.\n",
    "\n",
    "    Pertinent MONAI Bundle:\n",
    "      https://github.com/Project-MONAI/model-zoo/tree/dev/models/spleen_ct_segmentation\n",
    "\n",
    "    Execution Time Estimate:\n",
    "      With a Nvidia GV100 32GB GPU, for an input DICOM Series of 515 instances, the execution time is around\n",
    "      25 seconds with saving both DICOM Seg and surface mesh STL file, and 15 seconds with DICOM Seg only.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"Creates an application instance.\"\"\"\n",
    "        self._logger = logging.getLogger(\"{}.{}\".format(__name__, type(self).__name__))\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        # This method calls the base class to run. Can be omitted if simply calling through.\n",
    "        self._logger.info(f\"Begin {self.run.__name__}\")\n",
    "        super().run(*args, **kwargs)\n",
    "        self._logger.info(f\"End {self.run.__name__}\")\n",
    "\n",
    "    def compose(self):\n",
    "        \"\"\"Creates the app specific operators and chain them up in the processing DAG.\"\"\"\n",
    "\n",
    "        logging.info(f\"Begin {self.compose.__name__}\")\n",
    "\n",
    "        # Use Commandline options over environment variables to init context.\n",
    "        app_context = Application.init_app_context(self.argv)\n",
    "        app_input_path = Path(app_context.input_path)\n",
    "        app_output_path = Path(app_context.output_path)\n",
    "        model_path = Path(app_context.model_path)\n",
    "\n",
    "        # Create the custom operator(s) as well as SDK built-in operator(s).\n",
    "        study_loader_op = DICOMDataLoaderOperator(\n",
    "            self, CountCondition(self, 1), input_folder=app_input_path, name=\"study_loader_op\"\n",
    "        )\n",
    "        series_selector_op = DICOMSeriesSelectorOperator(self, rules=Sample_Rules_Text, name=\"series_selector_op\")\n",
    "        series_to_vol_op = DICOMSeriesToVolumeOperator(self, name=\"series_to_vol_op\")\n",
    "\n",
    "        # Create the inference operator that supports MONAI Bundle and automates the inference.\n",
    "        # The IOMapping labels match the input and prediction keys in the pre and post processing.\n",
    "        # The model_name is optional when the app has only one model.\n",
    "        # The bundle_path argument optionally can be set to an accessible bundle file path in the dev\n",
    "        # environment, so when the app is packaged into a MAP, the operator can complete the bundle parsing\n",
    "        # during init.\n",
    "\n",
    "        config_names = BundleConfigNames(config_names=[\"inference\"])  # Same as the default\n",
    "\n",
    "        bundle_spleen_seg_op = MonaiBundleInferenceOperator(\n",
    "            self,\n",
    "            input_mapping=[IOMapping(\"image\", Image, IOType.IN_MEMORY)],\n",
    "            output_mapping=[IOMapping(\"pred\", Image, IOType.IN_MEMORY)],\n",
    "            app_context=app_context,\n",
    "            bundle_config_names=config_names,\n",
    "            bundle_path=model_path,\n",
    "            name=\"bundle_spleen_seg_op\",\n",
    "        )\n",
    "\n",
    "        # Create DICOM Seg writer providing the required segment description for each segment with\n",
    "        # the actual algorithm and the pertinent organ/tissue. The segment_label, algorithm_name,\n",
    "        # and algorithm_version are of DICOM VR LO type, limited to 64 chars.\n",
    "        # https://dicom.nema.org/medical/dicom/current/output/chtml/part05/sect_6.2.html\n",
    "        segment_descriptions = [\n",
    "            SegmentDescription(\n",
    "                segment_label=\"Spleen\",\n",
    "                segmented_property_category=codes.SCT.Organ,\n",
    "                segmented_property_type=codes.SCT.Spleen,\n",
    "                algorithm_name=\"volumetric (3D) segmentation of the spleen from CT image\",\n",
    "                algorithm_family=codes.DCM.ArtificialIntelligence,\n",
    "                algorithm_version=\"0.3.2\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        custom_tags = {\"SeriesDescription\": \"AI generated Seg, not for clinical use.\"}\n",
    "\n",
    "        dicom_seg_writer = DICOMSegmentationWriterOperator(\n",
    "            self,\n",
    "            segment_descriptions=segment_descriptions,\n",
    "            custom_tags=custom_tags,\n",
    "            output_folder=app_output_path,\n",
    "            name=\"dicom_seg_writer\",\n",
    "        )\n",
    "\n",
    "        # Create the processing pipeline, by specifying the source and destination operators, and\n",
    "        # ensuring the output from the former matches the input of the latter, in both name and type.\n",
    "        self.add_flow(study_loader_op, series_selector_op, {(\"dicom_study_list\", \"dicom_study_list\")})\n",
    "        self.add_flow(\n",
    "            series_selector_op, series_to_vol_op, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(series_to_vol_op, bundle_spleen_seg_op, {(\"image\", \"image\")})\n",
    "        # Note below the dicom_seg_writer requires two inputs, each coming from a source operator.\n",
    "        self.add_flow(\n",
    "            series_selector_op, dicom_seg_writer, {(\"study_selected_series_list\", \"study_selected_series_list\")}\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, dicom_seg_writer, {(\"pred\", \"seg_image\")})\n",
    "        # Create the surface mesh STL conversion operator and add it to the app execution flow, if needed, by\n",
    "        # uncommenting the following couple lines.\n",
    "        stl_conversion_op = STLConversionOperator(\n",
    "            self, output_file=app_output_path.joinpath(\"stl/spleen.stl\"), name=\"stl_conversion_op\"\n",
    "        )\n",
    "        self.add_flow(bundle_spleen_seg_op, stl_conversion_op, {(\"pred\", \"image\")})\n",
    "\n",
    "        logging.info(f\"End {self.compose.__name__}\")\n",
    "\n",
    "\n",
    "# This is a sample series selection rule in JSON, simply selecting CT series.\n",
    "# If the study has more than 1 CT series, then all of them will be selected.\n",
    "# Please see more detail in DICOMSeriesSelectorOperator.\n",
    "Sample_Rules_Text = \"\"\"\n",
    "{\n",
    "    \"selections\": [\n",
    "        {\n",
    "            \"name\": \"CT Series\",\n",
    "            \"conditions\": {\n",
    "                \"StudyDescription\": \"(.*?)\",\n",
    "                \"Modality\": \"(?i)CT\",\n",
    "                \"SeriesDescription\": \"(.*?)\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()\n",
    "```\n",
    "\n",
    "The above lines are needed to execute the application code by using `python` interpreter.\n",
    "\n",
    "### \\_\\_main\\_\\_.py\n",
    "\n",
    "\\_\\_main\\_\\_.py is needed for <a href=\"../../developing_with_sdk/packaging_app.html#required-arguments\">MONAI Application Packager</a> to detect the main application code (`app.py`) when the application is executed with the application folder path (e.g., `python simple_imaging_app`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/__main__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/__main__.py\n",
    "from app import AISpleenSegApp\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    AISpleenSegApp().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app.py\t__main__.py\n"
     ]
    }
   ],
   "source": [
    "!ls my_app"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, let's execute the app in the command line.\n",
    "\n",
    ":::{note}\n",
    "Since the environment variables have been set and contain the correct paths, it is not necessary to provide the command line options on running the application. The following command demonstrates the use of the options.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 15:03:41,411] [INFO] (root) - Parsed args: Namespace(log_level=None, input=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/dcm'), output=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output'), model=PosixPath('/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models'), workdir=None, argv=['my_app', '-i', 'dcm', '-o', 'output', '-m', 'models'])\n",
      "[2024-04-10 15:03:41,413] [INFO] (root) - AppContext object: AppContext(input_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/dcm, output_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output, model_path=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models, workdir=)\n",
      "[2024-04-10 15:03:41,414] [INFO] (root) - End compose\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:211] Creating context\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1674] Loading extensions from configs...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1864] Activating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1894] Running Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1896] Waiting for completion...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1897] Graph execution waiting. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:190] Scheduling 8 entities\n",
      "[2024-04-10 15:03:41,449] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "[2024-04-10 15:03:41,784] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "[2024-04-10 15:03:41,784] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "  # of series: 1\n",
      "[2024-04-10 15:03:41,784] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-10 15:03:41,784] [INFO] (root) - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "[2024-04-10 15:03:41,784] [INFO] (root) -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "[2024-04-10 15:03:41,784] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) -     Series attribute Modality value: CT\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "[2024-04-10 15:03:41,785] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "[2024-04-10 15:03:42,204] [INFO] (root) - Parsing from bundle_path: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model/model.ts\n",
      "[2024-04-10 15:03:48,123] [INFO] (monai.deploy.operators.stl_conversion_operator.STLConversionOperator) - Output will be saved in file /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/output/stl/spleen.stl.\n",
      "[2024-04-10 15:03:49,607] [INFO] (monai.deploy.operators.stl_conversion_operator.SpatialImage) - 3D image\n",
      "[2024-04-10 15:03:49,607] [INFO] (monai.deploy.operators.stl_conversion_operator.STLConverter) - Image ndarray shape:(204, 512, 512)\n",
      "/home/mqin/src/monai-deploy-app-sdk/.venv/lib/python3.10/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "  warnings.warn(\n",
      "[2024-04-10 15:03:59,411] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "[2024-04-10 15:03:59,412] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "[\u001b[32minfo\u001b[m] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1906] Graph execution deactivating. Fragment: \n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1907] Deactivating Graph...\n",
      "[\u001b[32minfo\u001b[m] [gxf_executor.cpp:1910] Graph execution finished. Fragment: \n",
      "[2024-04-10 15:03:59,498] [INFO] (app.AISpleenSegApp) - End run\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!python my_app -i dcm -o output -m models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.826.0.1.3680043.10.511.3.39077956786032602526223766812104927.dcm  stl\n"
     ]
    }
   ],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging app\n",
    "\n",
    "Let's package the app with [MONAI Application Packager](/developing_with_sdk/packaging_app).\n",
    "\n",
    "In this version of the App SDK, we need to write out the configuration yaml file as well as the package requirements file, in the application folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/app.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/app.yaml\n",
    "%YAML 1.2\n",
    "---\n",
    "application:\n",
    "  title: MONAI Deploy App Package - MONAI Bundle AI App\n",
    "  version: 1.0\n",
    "  inputFormats: [\"file\"]\n",
    "  outputFormats: [\"file\"]\n",
    "\n",
    "resources:\n",
    "  cpu: 1\n",
    "  gpu: 1\n",
    "  memory: 1Gi\n",
    "  gpuMemory: 6Gi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing my_app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile my_app/requirements.txt\n",
    "highdicom>=0.18.2\n",
    "monai>=1.0\n",
    "nibabel>=3.2.1\n",
    "numpy>=1.21.6\n",
    "pydicom>=2.3.0\n",
    "setuptools>=59.5.0 # for pkg_resources\n",
    "SimpleITK>=2.0.0\n",
    "torch>=1.12.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the CLI package command to build the MONAI Application Package (MAP) container image based on a supported base image.\n",
    "\n",
    ":::{note}\n",
    "Building a MONAI Application Package (Docker image) can take time. Use `-l DEBUG` option to see the progress.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 15:04:01,696] [INFO] (packager.parameters) - Application: /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/my_app\n",
      "[2024-04-10 15:04:01,697] [INFO] (packager.parameters) - Detected application type: Python Module\n",
      "[2024-04-10 15:04:01,697] [INFO] (packager) - Scanning for models in /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models...\n",
      "[2024-04-10 15:04:01,697] [DEBUG] (packager) - Model model=/home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/models/model added.\n",
      "[2024-04-10 15:04:01,697] [INFO] (packager) - Reading application configuration from /home/mqin/src/monai-deploy-app-sdk/notebooks/tutorials/my_app/app.yaml...\n",
      "[2024-04-10 15:04:01,701] [INFO] (packager) - Generating app.json...\n",
      "[2024-04-10 15:04:01,701] [INFO] (packager) - Generating pkg.json...\n",
      "[2024-04-10 15:04:01,714] [DEBUG] (common) - \n",
      "=============== Begin app.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app\\\"]\",\n",
      "    \"environment\": {\n",
      "        \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "        \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "        \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "        \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "        \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "        \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "        \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "        \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "        \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "        \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "    },\n",
      "    \"input\": {\n",
      "        \"path\": \"input/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"liveness\": null,\n",
      "    \"output\": {\n",
      "        \"path\": \"output/\",\n",
      "        \"formats\": null\n",
      "    },\n",
      "    \"readiness\": null,\n",
      "    \"sdk\": \"monai-deploy\",\n",
      "    \"sdkVersion\": \"0.5.1\",\n",
      "    \"timeout\": 0,\n",
      "    \"version\": 1.0,\n",
      "    \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "================ End app.json ================\n",
      "                 \n",
      "[2024-04-10 15:04:01,715] [DEBUG] (common) - \n",
      "=============== Begin pkg.json ===============\n",
      "{\n",
      "    \"apiVersion\": \"1.0.0\",\n",
      "    \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "    \"modelRoot\": \"/opt/holoscan/models\",\n",
      "    \"models\": {\n",
      "        \"model\": \"/opt/holoscan/models/model\"\n",
      "    },\n",
      "    \"resources\": {\n",
      "        \"cpu\": 1,\n",
      "        \"gpu\": 1,\n",
      "        \"memory\": \"1Gi\",\n",
      "        \"gpuMemory\": \"6Gi\"\n",
      "    },\n",
      "    \"version\": 1.0,\n",
      "    \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "================ End pkg.json ================\n",
      "                 \n",
      "[2024-04-10 15:04:01,749] [DEBUG] (packager.builder) - \n",
      "========== Begin Dockerfile ==========\n",
      "\n",
      "\n",
      "FROM nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "\n",
      "ENV DEBIAN_FRONTEND=noninteractive\n",
      "ENV TERM=xterm-256color\n",
      "\n",
      "ARG UNAME\n",
      "ARG UID\n",
      "ARG GID\n",
      "\n",
      "RUN mkdir -p /etc/holoscan/ \\\n",
      "        && mkdir -p /opt/holoscan/ \\\n",
      "        && mkdir -p /var/holoscan \\\n",
      "        && mkdir -p /opt/holoscan/app \\\n",
      "        && mkdir -p /var/holoscan/input \\\n",
      "        && mkdir -p /var/holoscan/output\n",
      "\n",
      "LABEL base=\"nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\"\n",
      "LABEL tag=\"my_app:1.0\"\n",
      "LABEL org.opencontainers.image.title=\"MONAI Deploy App Package - MONAI Bundle AI App\"\n",
      "LABEL org.opencontainers.image.version=\"1.0\"\n",
      "LABEL org.nvidia.holoscan=\"1.0.3\"\n",
      "LABEL org.monai.deploy.app-sdk=\"0.5.1\"\n",
      "\n",
      "\n",
      "ENV HOLOSCAN_ENABLE_HEALTH_CHECK=true\n",
      "ENV HOLOSCAN_INPUT_PATH=/var/holoscan/input\n",
      "ENV HOLOSCAN_OUTPUT_PATH=/var/holoscan/output\n",
      "ENV HOLOSCAN_WORKDIR=/var/holoscan\n",
      "ENV HOLOSCAN_APPLICATION=/opt/holoscan/app\n",
      "ENV HOLOSCAN_TIMEOUT=0\n",
      "ENV HOLOSCAN_MODEL_PATH=/opt/holoscan/models\n",
      "ENV HOLOSCAN_DOCS_PATH=/opt/holoscan/docs\n",
      "ENV HOLOSCAN_CONFIG_PATH=/var/holoscan/app.yaml\n",
      "ENV HOLOSCAN_APP_MANIFEST_PATH=/etc/holoscan/app.json\n",
      "ENV HOLOSCAN_PKG_MANIFEST_PATH=/etc/holoscan/pkg.json\n",
      "ENV HOLOSCAN_LOGS_PATH=/var/holoscan/logs\n",
      "ENV PATH=/root/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/libtorch/1.13.1/lib/:/opt/nvidia/holoscan/lib\n",
      "\n",
      "RUN apt-get update \\\n",
      "    && apt-get install -y curl jq \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "ENV PYTHONPATH=\"/opt/holoscan/app:$PYTHONPATH\"\n",
      "\n",
      "\n",
      "\n",
      "RUN groupadd -f -g $GID $UNAME\n",
      "RUN useradd -rm -d /home/$UNAME -s /bin/bash -g $GID -G sudo -u $UID $UNAME\n",
      "RUN chown -R holoscan /var/holoscan \n",
      "RUN chown -R holoscan /var/holoscan/input \n",
      "RUN chown -R holoscan /var/holoscan/output \n",
      "\n",
      "# Set the working directory\n",
      "WORKDIR /var/holoscan\n",
      "\n",
      "# Copy HAP/MAP tool script\n",
      "COPY ./tools /var/holoscan/tools\n",
      "RUN chmod +x /var/holoscan/tools\n",
      "\n",
      "\n",
      "# Copy gRPC health probe\n",
      "\n",
      "USER $UNAME\n",
      "\n",
      "ENV PATH=/root/.local/bin:/home/holoscan/.local/bin:/opt/nvidia/holoscan:$PATH\n",
      "\n",
      "COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "\n",
      "RUN pip install --upgrade pip\n",
      "RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "\n",
      "# Install Holoscan from PyPI only when sdk_type is Holoscan. \n",
      "# For MONAI Deploy, the APP SDK will install it unless user specifies the Holoscan SDK file.\n",
      "\n",
      "# Copy user-specified MONAI Deploy SDK file\n",
      "COPY ./monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "COPY ./models  /opt/holoscan/models\n",
      "\n",
      "COPY ./map/app.json /etc/holoscan/app.json\n",
      "COPY ./app.config /var/holoscan/app.yaml\n",
      "COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "\n",
      "COPY ./app /opt/holoscan/app\n",
      "\n",
      "ENTRYPOINT [\"/var/holoscan/tools\"]\n",
      "=========== End Dockerfile ===========\n",
      "\n",
      "[2024-04-10 15:04:01,749] [INFO] (packager.builder) - \n",
      "===============================================================================\n",
      "Building image for:                 x64-workstation\n",
      "    Architecture:                   linux/amd64\n",
      "    Base Image:                     nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "    Build Image:                    N/A\n",
      "    Cache:                          Enabled\n",
      "    Configuration:                  dgpu\n",
      "    Holoscan SDK Package:           pypi.org\n",
      "    MONAI Deploy App SDK Package:   /home/mqin/src/monai-deploy-app-sdk/dist/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "    gRPC Health Probe:              N/A\n",
      "    SDK Version:                    1.0.3\n",
      "    SDK:                            monai-deploy\n",
      "    Tag:                            my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    \n",
      "[2024-04-10 15:04:02,349] [INFO] (common) - Using existing Docker BuildKit builder `holoscan_app_builder`\n",
      "[2024-04-10 15:04:02,349] [DEBUG] (packager.builder) - Building Holoscan Application Package: tag=my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "#0 building with \"holoscan_app_builder\" instance using docker-container driver\n",
      "\n",
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 2.80kB done\n",
      "#1 DONE 0.1s\n",
      "\n",
      "#2 [internal] load metadata for nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "#2 DONE 0.4s\n",
      "\n",
      "#3 [internal] load .dockerignore\n",
      "#3 transferring context: 1.79kB done\n",
      "#3 DONE 0.1s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 importing cache manifest from local:18341943591062161743\n",
      "#5 inferred cache manifest type: application/vnd.oci.image.index.v1+json done\n",
      "#5 DONE 0.0s\n",
      "\n",
      "#6 [ 1/21] FROM nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu@sha256:50343c616bf910e2a7651abb59db7833933e82cce64c3c4885f938d7e4af6155\n",
      "#6 resolve nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu@sha256:50343c616bf910e2a7651abb59db7833933e82cce64c3c4885f938d7e4af6155 0.0s done\n",
      "#6 DONE 0.1s\n",
      "\n",
      "#7 importing cache manifest from nvcr.io/nvidia/clara-holoscan/holoscan:v1.0.3-dgpu\n",
      "#7 inferred cache manifest type: application/vnd.docker.distribution.manifest.list.v2+json done\n",
      "#7 DONE 0.7s\n",
      "\n",
      "#4 [internal] load build context\n",
      "#4 transferring context: 19.56MB 0.1s done\n",
      "#4 DONE 0.2s\n",
      "\n",
      "#8 [ 8/21] RUN chown -R holoscan /var/holoscan/output\n",
      "#8 CACHED\n",
      "\n",
      "#9 [13/21] RUN pip install --upgrade pip\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 4/21] RUN groupadd -f -g 1000 holoscan\n",
      "#10 CACHED\n",
      "\n",
      "#11 [ 5/21] RUN useradd -rm -d /home/holoscan -s /bin/bash -g 1000 -G sudo -u 1000 holoscan\n",
      "#11 CACHED\n",
      "\n",
      "#12 [10/21] COPY ./tools /var/holoscan/tools\n",
      "#12 CACHED\n",
      "\n",
      "#13 [ 6/21] RUN chown -R holoscan /var/holoscan\n",
      "#13 CACHED\n",
      "\n",
      "#14 [ 2/21] RUN mkdir -p /etc/holoscan/         && mkdir -p /opt/holoscan/         && mkdir -p /var/holoscan         && mkdir -p /opt/holoscan/app         && mkdir -p /var/holoscan/input         && mkdir -p /var/holoscan/output\n",
      "#14 CACHED\n",
      "\n",
      "#15 [12/21] COPY ./pip/requirements.txt /tmp/requirements.txt\n",
      "#15 CACHED\n",
      "\n",
      "#16 [ 9/21] WORKDIR /var/holoscan\n",
      "#16 CACHED\n",
      "\n",
      "#17 [ 7/21] RUN chown -R holoscan /var/holoscan/input\n",
      "#17 CACHED\n",
      "\n",
      "#18 [11/21] RUN chmod +x /var/holoscan/tools\n",
      "#18 CACHED\n",
      "\n",
      "#19 [ 3/21] RUN apt-get update     && apt-get install -y curl jq     && rm -rf /var/lib/apt/lists/*\n",
      "#19 CACHED\n",
      "\n",
      "#20 [14/21] RUN pip install --no-cache-dir --user -r /tmp/requirements.txt\n",
      "#20 CACHED\n",
      "\n",
      "#21 [15/21] COPY ./monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "#21 DONE 0.2s\n",
      "\n",
      "#22 [16/21] RUN pip install /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "#22 0.845 Defaulting to user installation because normal site-packages is not writeable\n",
      "#22 0.979 Processing /tmp/monai_deploy_app_sdk-0.5.1+25.g31e4165.dirty-py3-none-any.whl\n",
      "#22 0.993 Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (1.23.5)\n",
      "#22 1.183 Collecting holoscan~=1.0 (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.336   Downloading holoscan-1.0.3-cp310-cp310-manylinux_2_35_x86_64.whl.metadata (4.1 kB)\n",
      "#22 1.412 Collecting colorama>=0.4.1 (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.416   Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "#22 1.507 Collecting typeguard>=3.0.0 (from monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.512   Downloading typeguard-4.2.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "#22 1.611 Collecting pip==23.3.2 (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.615   Downloading pip-23.3.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "#22 1.632 Requirement already satisfied: cupy-cuda12x==12.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (12.2.0)\n",
      "#22 1.635 Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2.2.1)\n",
      "#22 1.638 Requirement already satisfied: python-on-whales==0.60.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (0.60.1)\n",
      "#22 1.641 Requirement already satisfied: Jinja2==3.1.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.1.2)\n",
      "#22 1.643 Requirement already satisfied: packaging==23.1 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (23.1)\n",
      "#22 1.644 Requirement already satisfied: pyyaml==6.0 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (6.0)\n",
      "#22 1.645 Requirement already satisfied: requests==2.28.2 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2.28.2)\n",
      "#22 1.646 Requirement already satisfied: psutil==5.9.6 in /usr/local/lib/python3.10/dist-packages (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (5.9.6)\n",
      "#22 1.757 Collecting wheel-axle-runtime<1.0 (from holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty)\n",
      "#22 1.763   Downloading wheel_axle_runtime-0.0.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "#22 1.806 Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x==12.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (0.8.2)\n",
      "#22 1.813 Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.1.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2.1.3)\n",
      "#22 1.829 Requirement already satisfied: pydantic<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (1.10.14)\n",
      "#22 1.829 Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (4.66.1)\n",
      "#22 1.830 Requirement already satisfied: typer>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (0.9.0)\n",
      "#22 1.831 Requirement already satisfied: typing-extensions in /home/holoscan/.local/lib/python3.10/site-packages (from python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (4.10.0)\n",
      "#22 1.839 Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.3.2)\n",
      "#22 1.840 Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.6)\n",
      "#22 1.841 Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (1.26.18)\n",
      "#22 1.842 Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.28.2->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (2023.11.17)\n",
      "#22 1.860 Requirement already satisfied: filelock in /home/holoscan/.local/lib/python3.10/site-packages (from wheel-axle-runtime<1.0->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (3.13.3)\n",
      "#22 1.895 Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.1->python-on-whales==0.60.1->holoscan~=1.0->monai-deploy-app-sdk==0.5.1+25.g31e4165.dirty) (8.1.7)\n",
      "#22 1.939 Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "#22 3.052 Downloading holoscan-1.0.3-cp310-cp310-manylinux_2_35_x86_64.whl (33.6 MB)\n",
      "#22 7.685    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.6/33.6 MB 7.3 MB/s eta 0:00:00\n",
      "#22 7.692 Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
      "#22 7.738    ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 52.2 MB/s eta 0:00:00\n",
      "#22 7.745 Downloading typeguard-4.2.1-py3-none-any.whl (34 kB)\n",
      "#22 7.771 Downloading wheel_axle_runtime-0.0.5-py3-none-any.whl (12 kB)\n",
      "#22 8.166 Installing collected packages: wheel-axle-runtime, typeguard, pip, colorama, holoscan, monai-deploy-app-sdk\n",
      "#22 8.245   Attempting uninstall: pip\n",
      "#22 8.248     Found existing installation: pip 24.0\n",
      "#22 8.310     Uninstalling pip-24.0:\n",
      "#22 8.744       Successfully uninstalled pip-24.0\n",
      "#22 10.41 Successfully installed colorama-0.4.6 holoscan-1.0.3 monai-deploy-app-sdk-0.5.1+25.g31e4165.dirty pip-23.3.2 typeguard-4.2.1 wheel-axle-runtime-0.0.5\n",
      "#22 DONE 11.1s\n",
      "\n",
      "#23 [17/21] COPY ./models  /opt/holoscan/models\n",
      "#23 DONE 0.2s\n",
      "\n",
      "#24 [18/21] COPY ./map/app.json /etc/holoscan/app.json\n",
      "#24 DONE 0.1s\n",
      "\n",
      "#25 [19/21] COPY ./app.config /var/holoscan/app.yaml\n",
      "#25 DONE 0.1s\n",
      "\n",
      "#26 [20/21] COPY ./map/pkg.json /etc/holoscan/pkg.json\n",
      "#26 DONE 0.1s\n",
      "\n",
      "#27 [21/21] COPY ./app /opt/holoscan/app\n",
      "#27 DONE 0.1s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 exporting layers\n",
      "#28 exporting layers 6.0s done\n",
      "#28 exporting manifest sha256:3b3b2102892c64900945ca4d84a328af1fb7350c84cb4d85ecee3b94f48ed85c 0.0s done\n",
      "#28 exporting config sha256:d6463325d6640490c117da76b90d02687331b2ee1e486047f7c4c968023c3d89 0.0s done\n",
      "#28 sending tarball\n",
      "#28 ...\n",
      "\n",
      "#29 importing to docker\n",
      "#29 loading layer a292666cef7b 32.77kB / 125.57kB\n",
      "#29 loading layer 23d575e38e71 557.06kB / 73.97MB\n",
      "#29 loading layer 23d575e38e71 71.86MB / 73.97MB 2.2s\n",
      "#29 loading layer 601aae96dba4 196.61kB / 17.81MB\n",
      "#29 loading layer 8973e59624ba 492B / 492B\n",
      "#29 loading layer 2c4cefc4de42 313B / 313B\n",
      "#29 loading layer 450f1c5db7b9 301B / 301B\n",
      "#29 loading layer e08583daa6d7 3.30kB / 3.30kB\n",
      "#29 loading layer 2c4cefc4de42 313B / 313B 1.4s done\n",
      "#29 loading layer a292666cef7b 32.77kB / 125.57kB 4.5s done\n",
      "#29 loading layer 23d575e38e71 71.86MB / 73.97MB 4.4s done\n",
      "#29 loading layer 601aae96dba4 196.61kB / 17.81MB 1.8s done\n",
      "#29 loading layer 8973e59624ba 492B / 492B 1.5s done\n",
      "#29 loading layer 450f1c5db7b9 301B / 301B 1.4s done\n",
      "#29 loading layer e08583daa6d7 3.30kB / 3.30kB 1.3s done\n",
      "#29 DONE 4.5s\n",
      "\n",
      "#28 exporting to docker image format\n",
      "#28 sending tarball 67.2s done\n",
      "#28 DONE 73.2s\n",
      "\n",
      "#30 exporting cache to client directory\n",
      "#30 preparing build cache for export\n",
      "#30 writing layer sha256:00bb4c1319ba1a33ac3edcb3aa1240d8abcb8d0383c6267ed8028d3b6228a8a4\n",
      "#30 writing layer sha256:00bb4c1319ba1a33ac3edcb3aa1240d8abcb8d0383c6267ed8028d3b6228a8a4 done\n",
      "#30 writing layer sha256:014cff740c9ec6e9a30d0b859219a700ae880eb385d62095d348f5ea136d6015 done\n",
      "#30 writing layer sha256:0a1756432df4a4350712d8ae5c003f1526bd2180800b3ae6301cfc9ccf370254 done\n",
      "#30 writing layer sha256:0a77dcbd0e648ddc4f8e5230ade8fdb781d99e24fa4f13ca96a360c7f7e6751f done\n",
      "#30 writing layer sha256:0bf3a16e4f3f9ec99796b99e331a5c62472bc9377925e1fdc05f64709ed09895 0.0s done\n",
      "#30 writing layer sha256:0ec682bf99715a9f88631226f3749e2271b8b9f254528ef61f65ed829984821c done\n",
      "#30 writing layer sha256:1133dfcee0e851b490d17b3567f50c4b25ba5750da02ba4b3f3630655d0b1a7b done\n",
      "#30 writing layer sha256:1294b2835667d633f938174d9fecb18a60bbbebb6fb49788a1f939893a25d1af done\n",
      "#30 writing layer sha256:16a03c6e0373b62f9713416da0229bb7ce2585183141081d3ea8427ad2e84408 done\n",
      "#30 writing layer sha256:183aa7032b52e859f5de3dac98da7c8398ed5f8a984d74865561f126c0eecef2 0.0s done\n",
      "#30 writing layer sha256:20d331454f5fb557f2692dfbdbe092c718fd2cb55d5db9d661b62228dacca5c2 done\n",
      "#30 writing layer sha256:2232aeb26b5b7ea57227e9a5b84da4fb229624d7bc976a5f7ce86d9c8653d277 done\n",
      "#30 writing layer sha256:238f69a43816e481f0295995fcf5fe74d59facf0f9f99734c8d0a2fb140630e0 done\n",
      "#30 writing layer sha256:2ad84487f9d4d31cd1e0a92697a5447dd241935253d036b272ef16d31620c1e7 done\n",
      "#30 writing layer sha256:2bb73464628bd4a136c4937f42d522c847bea86b2215ae734949e24c1caf450e done\n",
      "#30 writing layer sha256:3e3e04011ebdba380ab129f0ee390626cb2a600623815ca756340c18bedb9517 done\n",
      "#30 writing layer sha256:42619ce4a0c9e54cfd0ee41a8e5f27d58b3f51becabd1ac6de725fbe6c42b14a done\n",
      "#30 writing layer sha256:43a21fb6c76bd2b3715cc09d9f8c3865dc61c51dd9e2327b429f5bec8fff85d1 done\n",
      "#30 writing layer sha256:4482079b5d33963eb55191bf404b70095535d4a8e2b64dab7373500515f896b4\n",
      "#30 writing layer sha256:4482079b5d33963eb55191bf404b70095535d4a8e2b64dab7373500515f896b4 0.4s done\n",
      "#30 writing layer sha256:49bdc9abf8a437ccff67cc11490ba52c976577992909856a86be872a34d3b950\n",
      "#30 writing layer sha256:49bdc9abf8a437ccff67cc11490ba52c976577992909856a86be872a34d3b950 done\n",
      "#30 writing layer sha256:4b691ba9f48b41eaa0c754feba8366f1c030464fcbc55eeffa6c86675990933a done\n",
      "#30 writing layer sha256:4d04a8db404f16c2704fa10739cb6745a0187713a21a6ef0deb34b48629b54c1 done\n",
      "#30 writing layer sha256:4f4fb700ef54461cfa02571ae0db9a0dc1e0cdb5577484a6d75e68dc38e8acc1 done\n",
      "#30 writing layer sha256:5275a41be8f6691a490c0a15589e0910c73bf971169ad33a850ef570d37f63dd done\n",
      "#30 writing layer sha256:52fbfeaf78318d843054ce2bfb5bfc9f71278939a815f6035ab5b14573ad017b done\n",
      "#30 writing layer sha256:5792b18b6f162bae61ff5840cdb9e8567e6847a56ac886f940b47e7271c529a7 done\n",
      "#30 writing layer sha256:57f244836ad318f9bbb3b29856ae1a5b31038bfbb9b43d2466d51c199eb55041 done\n",
      "#30 writing layer sha256:5b5b131e0f20db4cb8e568b623a95f8fc16ed1c6b322a9366df70b59a881f24f done\n",
      "#30 writing layer sha256:5ccb787d371fd3697122101438ddd0f55b537832e9756d2c51ab1d8158710ac5 done\n",
      "#30 writing layer sha256:5ea668ffc2fc267d241dbf17ca283bc879643a189be4f7e3d9034a82fc64a1ea done\n",
      "#30 writing layer sha256:62452179df7c18e292f141d4aec29e6aba9ff8270c893731169fc6f41dc07631 done\n",
      "#30 writing layer sha256:6630c387f5f2115bca2e646fd0c2f64e1f3d5431c2e050abe607633883eda230 done\n",
      "#30 writing layer sha256:69af4b756272a77f683a8d118fd5ca55c03ad5f1bacc673b463f54d16b833da5 done\n",
      "#30 writing layer sha256:6ae1f1fb92c0cb2b6e219f687b08c8e511501a7af696c943ca20d119eba7cd02 done\n",
      "#30 writing layer sha256:6deb3d550b15a5e099c0b3d0cbc242e351722ca16c058d3a6c28ba1a02824d0f done\n",
      "#30 writing layer sha256:6e80a527af94a864094c4f9116c2d29d3d7548ec8388579d9cf3f8a39a4b8178\n",
      "#30 writing layer sha256:6e80a527af94a864094c4f9116c2d29d3d7548ec8388579d9cf3f8a39a4b8178 1.3s done\n",
      "#30 writing layer sha256:7386814d57100e2c7389fbf4e16f140f5c549d31434c62c3884a85a3ee5cd2a7\n",
      "#30 writing layer sha256:7386814d57100e2c7389fbf4e16f140f5c549d31434c62c3884a85a3ee5cd2a7 done\n",
      "#30 writing layer sha256:7852b73ea931e3a8d3287ee7ef3cf4bad068e44f046583bfc2b81336fb299284 done\n",
      "#30 writing layer sha256:7e73869c74822e4539e104a3d2aff853f4622cd0bb873576db1db53c9e91f621 done\n",
      "#30 writing layer sha256:7eae142b38745fe88962874372374deb672998600264a17e638c010b79e6b535 done\n",
      "#30 writing layer sha256:7f2e5ab2c599fa36698918d3e73c991d8616fff9037077cd230529e7cd1c5e0e done\n",
      "#30 writing layer sha256:82a3436133b2b17bb407c7fe488932aa0ca55411f23ab55c34a6134b287c6a27 done\n",
      "#30 writing layer sha256:90eae6faa5cc5ba62f12c25915cdfb1a7a51abfba0d05cb5818c3f908f4e345f done\n",
      "#30 writing layer sha256:9ac855545fa90ed2bf3b388fdff9ef06ac9427b0c0fca07c9e59161983d8827e done\n",
      "#30 writing layer sha256:9d19ee268e0d7bcf6716e6658ee1b0384a71d6f2f9aa1ae2085610cf7c7b316f done\n",
      "#30 writing layer sha256:a10c8d7d2714eabf661d1f43a1ccb87a51748cbb9094d5bc0b713e2481b5d329 done\n",
      "#30 writing layer sha256:a1748eee9d376f97bd19225ba61dfada9986f063f4fc429e435f157abb629fc6 done\n",
      "#30 writing layer sha256:a68f4e0ec09ec3b78cb4cf8e4511d658e34e7b6f676d7806ad9703194ff17604 done\n",
      "#30 writing layer sha256:a8e4decc8f7289623b8fd7b9ba1ca555b5a755ebdbf81328d68209f148d9e602 done\n",
      "#30 writing layer sha256:afde1c269453ce68a0f2b54c1ba8c5ecddeb18a19e5618a4acdef1f0fe3921af done\n",
      "#30 writing layer sha256:b48a5fafcaba74eb5d7e7665601509e2889285b50a04b5b639a23f8adc818157 done\n",
      "#30 writing layer sha256:ba9f7c75e4dd7942b944679995365aab766d3677da2e69e1d74472f471a484dd done\n",
      "#30 writing layer sha256:bc42865e1c27a9b1bee751f3c99ad2c12a906d32aca396ace7a07231c9cafbd1 done\n",
      "#30 writing layer sha256:bdfc73b2a0fa11b4086677e117a2f9feb6b4ffeccb23a3d58a30543339607e31 done\n",
      "#30 writing layer sha256:c175bb235295e50de2961fa1e1a2235c57e6eba723a914287dfc26d3be0eac11 done\n",
      "#30 writing layer sha256:c98533d2908f36a5e9b52faae83809b3b6865b50e90e2817308acfc64cd3655f done\n",
      "#30 writing layer sha256:cb6c95b33bc30dd285c5b3cf99a05281b8f12decae1c932ab64bd58f56354021 done\n",
      "#30 writing layer sha256:d6b5d6e098aacb316146a428c6b5aef9692011c6dce0932e3bbfbf27a514b7ed done\n",
      "#30 writing layer sha256:d7da5c5e9a40c476c4b3188a845e3276dedfd752e015ea5113df5af64d4d43f7 done\n",
      "#30 writing layer sha256:e4297ff4df6f7a8f25cb109e5b24483c314c2e72b8e824f9669173919fc159c9 0.0s done\n",
      "#30 writing layer sha256:e4aedc686433c0ec5e676e6cc54a164345f7016aa0eb714f00c07e11664a1168 done\n",
      "#30 writing layer sha256:e5d9fee7e7dacd6052fe7c78ac5738f1fb693aa068f7c6064c70e98941288a52 0.0s done\n",
      "#30 writing layer sha256:e8640a108802cd7519cc53dceb74f7a5c94b562662f1c3c040c2aa6571acf0f3 0.0s done\n",
      "#30 writing layer sha256:e8acb678f16bc0c369d5cf9c184f2d3a1c773986816526e5e3e9c0354f7e757f\n",
      "#30 preparing build cache for export 2.5s done\n",
      "#30 writing layer sha256:e8acb678f16bc0c369d5cf9c184f2d3a1c773986816526e5e3e9c0354f7e757f done\n",
      "#30 writing layer sha256:e9225f7ab6606813ec9acba98a064826ebfd6713a9645a58cd068538af1ecddb done\n",
      "#30 writing layer sha256:f33546e75bf1a7d9dc9e21b9a2c54c9d09b24790ad7a4192a8509002ceb14688 done\n",
      "#30 writing layer sha256:f608e2fbff86e98627b7e462057e7d2416522096d73fe4664b82fe6ce8a4047d done\n",
      "#30 writing layer sha256:f7702077ced42a1ee35e7f5e45f72634328ff3bcfe3f57735ba80baa5ec45daf done\n",
      "#30 writing layer sha256:fa66a49172c6e821a1bace57c007c01da10cbc61507c44f8cdfeed8c4e5febab done\n",
      "#30 writing config sha256:386c66fca187580548b7c0d95c25fecfb72f326f30df509c9860b977d7e32763 0.0s done\n",
      "#30 writing cache manifest sha256:ebd62b21fd87e8654814f8093dffbbf555dced752810b2798c59b2b1a08ce0fd 0.0s done\n",
      "#30 DONE 2.5s\n",
      "[2024-04-10 15:05:33,378] [INFO] (packager) - Build Summary:\n",
      "\n",
      "Platform: x64-workstation/dgpu\n",
      "    Status:     Succeeded\n",
      "    Docker Tag: my_app-x64-workstation-dgpu-linux-amd64:1.0\n",
      "    Tarball:    None\n"
     ]
    }
   ],
   "source": [
    "tag_prefix = \"my_app\"\n",
    "\n",
    "!monai-deploy package my_app -m {models_folder} -c my_app/app.yaml -t {tag_prefix}:1.0 --platform x64-workstation -l DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the MAP Docker image is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_app-x64-workstation-dgpu-linux-amd64                                                   1.0                        d6463325d664   About a minute ago   17.5GB\n"
     ]
    }
   ],
   "source": [
    "!docker image ls | grep {tag_prefix}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can choose to display and inspect the MAP manifests by running the container with the `show` command.\n",
    "Furthermore, we can also extract the manifests and other contents in the MAP by using the `extract` command while mapping specific folder to the host's (we know that our MAP is compliant and supports these commands).\n",
    "\n",
    ":::{note}\n",
    "The host folder for storing the extracted content must first be created by the user, and if it has been created by Docker on running the container, the folder needs to be deleted and re-created.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display manifests and extract MAP contents to the host folder, ./export\n",
      "\n",
      "============================== app.json ==============================\n",
      "{\n",
      "  \"apiVersion\": \"1.0.0\",\n",
      "  \"command\": \"[\\\"python3\\\", \\\"/opt/holoscan/app\\\"]\",\n",
      "  \"environment\": {\n",
      "    \"HOLOSCAN_APPLICATION\": \"/opt/holoscan/app\",\n",
      "    \"HOLOSCAN_INPUT_PATH\": \"input/\",\n",
      "    \"HOLOSCAN_OUTPUT_PATH\": \"output/\",\n",
      "    \"HOLOSCAN_WORKDIR\": \"/var/holoscan\",\n",
      "    \"HOLOSCAN_MODEL_PATH\": \"/opt/holoscan/models\",\n",
      "    \"HOLOSCAN_CONFIG_PATH\": \"/var/holoscan/app.yaml\",\n",
      "    \"HOLOSCAN_APP_MANIFEST_PATH\": \"/etc/holoscan/app.json\",\n",
      "    \"HOLOSCAN_PKG_MANIFEST_PATH\": \"/etc/holoscan/pkg.json\",\n",
      "    \"HOLOSCAN_DOCS_PATH\": \"/opt/holoscan/docs\",\n",
      "    \"HOLOSCAN_LOGS_PATH\": \"/var/holoscan/logs\"\n",
      "  },\n",
      "  \"input\": {\n",
      "    \"path\": \"input/\",\n",
      "    \"formats\": null\n",
      "  },\n",
      "  \"liveness\": null,\n",
      "  \"output\": {\n",
      "    \"path\": \"output/\",\n",
      "    \"formats\": null\n",
      "  },\n",
      "  \"readiness\": null,\n",
      "  \"sdk\": \"monai-deploy\",\n",
      "  \"sdkVersion\": \"0.5.1\",\n",
      "  \"timeout\": 0,\n",
      "  \"version\": 1,\n",
      "  \"workingDirectory\": \"/var/holoscan\"\n",
      "}\n",
      "\n",
      "============================== pkg.json ==============================\n",
      "{\n",
      "  \"apiVersion\": \"1.0.0\",\n",
      "  \"applicationRoot\": \"/opt/holoscan/app\",\n",
      "  \"modelRoot\": \"/opt/holoscan/models\",\n",
      "  \"models\": {\n",
      "    \"model\": \"/opt/holoscan/models/model\"\n",
      "  },\n",
      "  \"resources\": {\n",
      "    \"cpu\": 1,\n",
      "    \"gpu\": 1,\n",
      "    \"memory\": \"1Gi\",\n",
      "    \"gpuMemory\": \"6Gi\"\n",
      "  },\n",
      "  \"version\": 1,\n",
      "  \"platformConfig\": \"dgpu\"\n",
      "}\n",
      "\n",
      "2024-04-10 22:05:37 [INFO] Copying application from /opt/holoscan/app to /var/run/holoscan/export/app\n",
      "\n",
      "2024-04-10 22:05:37 [INFO] Copying application manifest file from /etc/holoscan/app.json to /var/run/holoscan/export/config/app.json\n",
      "2024-04-10 22:05:37 [INFO] Copying pkg manifest file from /etc/holoscan/pkg.json to /var/run/holoscan/export/config/pkg.json\n",
      "2024-04-10 22:05:37 [INFO] Copying application configuration from /var/holoscan/app.yaml to /var/run/holoscan/export/config/app.yaml\n",
      "\n",
      "2024-04-10 22:05:37 [INFO] Copying models from /opt/holoscan/models to /var/run/holoscan/export/models\n",
      "\n",
      "2024-04-10 22:05:37 [INFO] Copying documentation from /opt/holoscan/docs/ to /var/run/holoscan/export/docs\n",
      "2024-04-10 22:05:37 [INFO] '/opt/holoscan/docs/' cannot be found.\n",
      "\n",
      "app  config  models\n"
     ]
    }
   ],
   "source": [
    "!echo \"Display manifests and extract MAP contents to the host folder, ./export\"\n",
    "!docker run --rm {tag_prefix}-x64-workstation-dgpu-linux-amd64:1.0 show\n",
    "!rm -rf `pwd`/export && mkdir -p `pwd`/export\n",
    "!docker run --rm -v `pwd`/export/:/var/run/holoscan/export/ {tag_prefix}-x64-workstation-dgpu-linux-amd64:1.0 extract\n",
    "!ls `pwd`/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing packaged app locally\n",
    "\n",
    "The packaged app can be run locally through [MONAI Application Runner](/developing_with_sdk/executing_packaged_app_locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-10 15:05:39,448] [INFO] (runner) - Checking dependencies...\n",
      "[2024-04-10 15:05:39,448] [INFO] (runner) - --> Verifying if \"docker\" is installed...\n",
      "\n",
      "[2024-04-10 15:05:39,449] [INFO] (runner) - --> Verifying if \"docker-buildx\" is installed...\n",
      "\n",
      "[2024-04-10 15:05:39,449] [INFO] (runner) - --> Verifying if \"my_app-x64-workstation-dgpu-linux-amd64:1.0\" is available...\n",
      "\n",
      "[2024-04-10 15:05:39,511] [INFO] (runner) - Reading HAP/MAP manifest...\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.56kB to /tmp/tmpba1clh6t/app.json\n",
      "\u001b[sPreparing to copy...\u001b[?25l\u001b[u\u001b[2KCopying from container - 0B\u001b[?25h\u001b[u\u001b[2KSuccessfully copied 2.05kB to /tmp/tmpba1clh6t/pkg.json\n",
      "[2024-04-10 15:05:39,743] [INFO] (runner) - --> Verifying if \"nvidia-ctk\" is installed...\n",
      "\n",
      "[2024-04-10 15:05:39,744] [INFO] (runner) - --> Verifying \"nvidia-ctk\" version...\n",
      "\n",
      "[2024-04-10 15:05:40,086] [INFO] (common) - Launching container (1d77a7676232) using image 'my_app-x64-workstation-dgpu-linux-amd64:1.0'...\n",
      "    container name:      festive_hermann\n",
      "    host name:           mingq-dt\n",
      "    network:             host\n",
      "    user:                1000:1000\n",
      "    ulimits:             memlock=-1:-1, stack=67108864:67108864\n",
      "    cap_add:             CAP_SYS_PTRACE\n",
      "    ipc mode:            host\n",
      "    shared memory size:  67108864\n",
      "    devices:             \n",
      "    group_add:           44\n",
      "2024-04-10 22:05:40 [INFO] Launching application python3 /opt/holoscan/app ...\n",
      "\n",
      "[2024-04-10 22:05:45,192] [INFO] (root) - Parsed args: Namespace(log_level=None, input=None, output=None, model=None, workdir=None, argv=['/opt/holoscan/app'])\n",
      "\n",
      "[2024-04-10 22:05:45,195] [INFO] (root) - AppContext object: AppContext(input_path=/var/holoscan/input, output_path=/var/holoscan/output, model_path=/opt/holoscan/models, workdir=/var/holoscan)\n",
      "\n",
      "[2024-04-10 22:05:45,197] [INFO] (root) - End compose\n",
      "\n",
      "[info] [app_driver.cpp:1161] Launching the driver/health checking service\n",
      "\n",
      "[info] [gxf_executor.cpp:211] Creating context\n",
      "\n",
      "[info] [server.cpp:87] Health checking server listening on 0.0.0.0:8777\n",
      "\n",
      "[info] [gxf_executor.cpp:1674] Loading extensions from configs...\n",
      "\n",
      "[info] [gxf_executor.cpp:1864] Activating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1894] Running Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1896] Waiting for completion...\n",
      "\n",
      "[info] [gxf_executor.cpp:1897] Graph execution waiting. Fragment: \n",
      "\n",
      "[info] [greedy_scheduler.cpp:190] Scheduling 8 entities\n",
      "\n",
      "[2024-04-10 22:05:45,297] [INFO] (monai.deploy.operators.dicom_data_loader_operator.DICOMDataLoaderOperator) - No or invalid input path from the optional input port: None\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) - Finding series for Selection named: CT Series\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) - Searching study, : 1.3.6.1.4.1.14519.5.2.1.7085.2626.822645453932810382886582736291\n",
      "\n",
      "  # of series: 1\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) - Working on series, instance UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) - On attribute: 'StudyDescription' to match value: '(.*?)'\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) -     Series attribute StudyDescription value: CT ABDOMEN W IV CONTRAST\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) - On attribute: 'Modality' to match value: '(?i)CT'\n",
      "\n",
      "[2024-04-10 22:05:46,131] [INFO] (root) -     Series attribute Modality value: CT\n",
      "\n",
      "[2024-04-10 22:05:46,132] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "\n",
      "[2024-04-10 22:05:46,132] [INFO] (root) - On attribute: 'SeriesDescription' to match value: '(.*?)'\n",
      "\n",
      "[2024-04-10 22:05:46,132] [INFO] (root) -     Series attribute SeriesDescription value: ABD/PANC 3.0 B31f\n",
      "\n",
      "[2024-04-10 22:05:46,132] [INFO] (root) - Series attribute string value did not match. Try regEx.\n",
      "\n",
      "[2024-04-10 22:05:46,132] [INFO] (root) - Selected Series, UID: 1.3.6.1.4.1.14519.5.2.1.7085.2626.119403521930927333027265674239\n",
      "\n",
      "[2024-04-10 22:05:46,349] [INFO] (root) - Parsing from bundle_path: /opt/holoscan/models/model/model.ts\n",
      "\n",
      "[2024-04-10 22:05:49,959] [INFO] (monai.deploy.operators.stl_conversion_operator.STLConversionOperator) - Output will be saved in file /var/holoscan/output/stl/spleen.stl.\n",
      "\n",
      "[2024-04-10 22:05:51,433] [INFO] (monai.deploy.operators.stl_conversion_operator.SpatialImage) - 3D image\n",
      "\n",
      "[2024-04-10 22:05:51,433] [INFO] (monai.deploy.operators.stl_conversion_operator.STLConverter) - Image ndarray shape:(204, 512, 512)\n",
      "\n",
      "Exception occurred in compute method of operator: 'stl_conversion_op'\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/operators/stl_conversion_operator.py\", line 118, in compute\n",
      "\n",
      "    stl_bytes = self._convert(input_image, _output_file)\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/operators/stl_conversion_operator.py\", line 135, in _convert\n",
      "\n",
      "    return self._converter.convert(\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/operators/stl_conversion_operator.py\", line 182, in convert\n",
      "\n",
      "    nda = STLConverter.get_largest_cc(nda)\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/operators/stl_conversion_operator.py\", line 255, in get_largest_cc\n",
      "\n",
      "    labels = label(nda)\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/utils/importutil.py\", line 274, in __call__\n",
      "\n",
      "    raise self._exception\n",
      "\n",
      "  File \"/home/holoscan/.local/lib/python3.10/site-packages/monai/deploy/utils/importutil.py\", line 226, in optional_import\n",
      "\n",
      "    pkg = __import__(module)  # top level module\n",
      "\n",
      "monai.deploy.utils.importutil.OptionalImportError: from skimage.measure import label (No module named 'skimage').\n",
      "\n",
      "\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n",
      "/home/holoscan/.local/lib/python3.10/site-packages/highdicom/valuerep.py:54: UserWarning: The string \"C3N-00198\" is unlikely to represent the intended person name since it contains only a single component. Construct a person name according to the format in described in https://dicom.nema.org/dicom/2013/output/chtml/part05/sect_6.2.html#sect_6.2.1.2, or, in pydicom 2.2.0 or later, use the pydicom.valuerep.PersonName.from_named_components() method to construct the person name correctly. If a single-component name is really intended, add a trailing caret character to disambiguate the name.\n",
      "\n",
      "  warnings.warn(\n",
      "\n",
      "[2024-04-10 22:05:52,708] [INFO] (highdicom.base) - copy Image-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2024-04-10 22:05:52,708] [INFO] (highdicom.base) - copy attributes of module \"Specimen\"\n",
      "\n",
      "[2024-04-10 22:05:52,708] [INFO] (highdicom.base) - copy Patient-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2024-04-10 22:05:52,708] [INFO] (highdicom.base) - copy attributes of module \"Patient\"\n",
      "\n",
      "[2024-04-10 22:05:52,709] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Subject\"\n",
      "\n",
      "[2024-04-10 22:05:52,709] [INFO] (highdicom.base) - copy Study-related attributes from dataset \"1.3.6.1.4.1.14519.5.2.1.7085.2626.936983343951485811186213470191\"\n",
      "\n",
      "[2024-04-10 22:05:52,709] [INFO] (highdicom.base) - copy attributes of module \"General Study\"\n",
      "\n",
      "[2024-04-10 22:05:52,709] [INFO] (highdicom.base) - copy attributes of module \"Patient Study\"\n",
      "\n",
      "[2024-04-10 22:05:52,709] [INFO] (highdicom.base) - copy attributes of module \"Clinical Trial Study\"\n",
      "\n",
      "[info] [greedy_scheduler.cpp:369] Scheduler stopped: Some entities are waiting for execution, but there are no periodic or async entities to get out of the deadlock.\n",
      "\n",
      "[info] [greedy_scheduler.cpp:398] Scheduler finished.\n",
      "\n",
      "[info] [gxf_executor.cpp:1906] Graph execution deactivating. Fragment: \n",
      "\n",
      "[info] [gxf_executor.cpp:1907] Deactivating Graph...\n",
      "\n",
      "[info] [gxf_executor.cpp:1910] Graph execution finished. Fragment: \n",
      "\n",
      "[2024-04-10 22:05:52,805] [INFO] (app.AISpleenSegApp) - End run\n",
      "\n",
      "[2024-04-10 15:05:54,069] [INFO] (common) - Container 'festive_hermann'(1d77a7676232) exited.\n"
     ]
    }
   ],
   "source": [
    "# Clear the output folder and run the MAP. The input is expected to be a folder.\n",
    "!rm -rf $HOLOSCAN_OUTPUT_PATH\n",
    "!monai-deploy run -i $HOLOSCAN_INPUT_PATH -o $HOLOSCAN_OUTPUT_PATH my_app-x64-workstation-dgpu-linux-amd64:1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.826.0.1.3680043.10.511.3.33232544284800485207819891596585914.dcm  stl\n"
     ]
    }
   ],
   "source": [
    "!ls $HOLOSCAN_OUTPUT_PATH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9b4ab1155d0cd1042497eb40fd55b2d15caf4b3c0f9fbfcc7ba4404045d40f12"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
